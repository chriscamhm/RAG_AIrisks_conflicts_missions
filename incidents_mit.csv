,_id,incident_id,date,reports,Alleged deployer of AI system,Alleged developer of AI system,Alleged harmed or nearly harmed parties,description,title,Incident ID,Risk Domain,Risk Subdomain,processed_text
0,ObjectId(625763db343edc875fe639ff),1,2015-05-19,"[1,2,3,4,5,6,7,8,9,10,11,12,14,15]","[""youtube""]","[""youtube""]","[""children""]",YouTube’s content filtering and recommendation algorithms exposed children to disturbing and inappropriate videos.,Google’s YouTube Kids App Presents Inappropriate Content,1.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,youtubes filter recommendation algorithm expose child disturb inappropriate video
1,ObjectId(625763de343edc875fe63a15),23,2017-11-08,"[242,243,244,245,246,247,248,249,250,253,254,257,258,259,260,261,263,264,266,267,268,269,270,2389]","[""navya"",""keolis-north-america""]","[""navya"",""keolis-north-america""]","[""navya"",""keolis-north-america"",""bus-passengers""]","A self-driving public shuttle by Keolis North America and Navya was involved in a collision with a human-driven delivery truck in Las Vegas, Nevada on its first day of service.",Las Vegas Self-Driving Bus Involved in Accident,23.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,selfdriving public shuttle keolis north america navya involve collision humandriven delivery truck la vega nevada first day service
2,ObjectId(625763dc343edc875fe63a02),4,2018-03-18,"[629,630,631,632,633,634,635,636,637,638,639,640,641,642,644,645,646,647,1375,1376,1377,1378,1542,2147,1257]","[""uber""]","[""uber""]","[""elaine-herzberg"",""pedestrians""]","An Uber autonomous vehicle (AV) in autonomous mode struck and killed a pedestrian in Tempe, Arizona.",Uber AV Killed Pedestrian in Arizona,4.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,uber autonomous vehicle av autonomous mode struck kill pedestrian tempe arizona
3,ObjectId(625763dd343edc875fe63a0a),12,2016-07-21,[42],"[""microsoft-research"",""boston-university""]","[""microsoft-research"",""google"",""boston-university""]","[""women"",""minority-groups""]","Researchers from Boston University and Microsoft Research, New England demonstrated gender bias in the most common techniques used to embed words for natural language processing (NLP).",Common Biases of Vector Embeddings,12.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,researcher boston university microsoft research england demonstrate gender bias common technique use embed word natural language processing nlp
4,ObjectId(625763dc343edc875fe63a03),5,2015-07-13,"[767,768,769,770,771,772,773,774,775,776,777,778]","[""hospitals"",""doctors""]","[""intuitive-surgical""]","[""patients""]","Study on database reports of robotic surgery malfunctions (8,061), including those ending in injury (1,391) and death (144), between 2000 and 2013.",Collection of Robotic Surgery Malfunctions,5.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,study database report robotic surgery malfunction include end injury death
5,ObjectId(625763dc343edc875fe63a04),6,2016-03-24,"[906,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,1374,1780,2398,2656]","[""microsoft""]","[""microsoft""]","[""twitter-users""]","Microsoft's Tay, an artificially intelligent chatbot, was released on March 23, 2016 and removed within 24 hours due to multiple racist, sexist, and anti-semitic tweets generated by the bot.",TayBot,6.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,microsofts tay artificially intelligent chatbot release march remove within hour due multiple racist sexist antisemitic tweet generate bot
6,ObjectId(625763dd343edc875fe63a08),10,2014-08-14,"[16,17,18,19,20,21,22,23,24,25]","[""starbucks""]","[""kronos""]","[""starbucks-employees""]","Kronos’s scheduling algorithm and its use by Starbucks managers allegedly negatively impacted financial and scheduling stability for Starbucks employees, which disadvantaged wage workers.",Kronos Scheduling Algorithm Allegedly Caused Financial Issues for Starbucks Employees,10.0,5. Human-Computer Interaction,5.2. Loss of human agency and autonomy,kronoss schedule starbucks manager negatively impact financial schedule stability starbucks employee disadvantage wage worker
7,ObjectId(625763dd343edc875fe63a09),11,2016-05-23,"[29,30,31,32,33,35,36,37,38,39,40,41,1371,1372,1373]","[""northpointe""]","[""northpointe""]","[""accused-people""]",An algorithm developed by Northpointe and used in the penal system is two times more likely to incorrectly label a black person as a high-risk re-offender and is two times more likely to incorrectly label a white person as low-risk for reoffense according to a ProPublica review.,Northpointe Risk Models,11.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,developed northpointe use penal two time likely incorrectly label black person highrisk reoffender two time likely incorrectly label white person lowrisk reoffense accord propublica review
8,ObjectId(625763de343edc875fe63a12),20,2016-06-30,"[191,192,193,196,197,198,201,202,203,204,205,206,207,210,211,213,214,215,216,1362,1363,1364]","[""tesla""]","[""tesla""]","[""motorists""]",Multiple unrelated car accidents result in varying levels of harm have been occurred while a Tesla's autopilot was in use.,A Collection of Tesla Autopilot-Involved Crashes,20.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,multiple unrelated car accident vary level harm occur tesla autopilot
9,ObjectId(625763de343edc875fe63a16),24,2014-07-15,"[271,272,273,274,275,276,277,278,279,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,298,299]","[""volkswagen""]","[""volkswagen""]","[""robotics-consultant""]","A Volkswagen plant robot ""crushed to death"" a worker by pinning him to a metal plate. ",Robot kills worker at German Volkswagen plant,24.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,volkswagen plant robot crush death worker pin metal plate
10,ObjectId(625763dd343edc875fe63a0c),14,2017-10-26,"[50,51,52,53,54,55,56]","[""google""]","[""google""]","[""women"",""minority-groups""]","Google Cloud's Natural Language API provided racist, homophobic, amd antisemitic sentiment analyses.",Biased Sentiment Analysis,14.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,google cloud natural language api provide racist homophobic amd antisemitic sentiment analysis
11,ObjectId(625763dd343edc875fe63a0e),16,2015-06-03,"[83,84,85,86,87,88,89,90,91,92,93,95,96,98,99,100,101,102,103,104,105,1369,1370,3004]","[""google""]","[""google""]","[""black-people""]","Google Photos image processing software mistakenly labelled a black couple as ""gorillas.""",Images of Black People Labeled as Gorillas,16.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,google photo image processing software mistakenly label black couple gorilla
12,ObjectId(625763dc343edc875fe63a01),3,2018-10-27,"[372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,1342,3447]","[""boeing""]","[""boeing""]","[""airplane-passengers"",""airplane-crew""]","A Boeing 737 crashed into the sea, killing 189 people, after faulty sensor data caused an automated manuevering system to repeatedly push the plane's nose downward.",Crashes with Maneuvering Characteristics Augmentation System (MCAS),3.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,boeing crashed sea kill people faulty sensor cause automate manuevering repeatedly push plane nose downward
13,ObjectId(625763de343edc875fe63a11),19,2013-01-23,"[158,159,160,161,162,163,166,167,168,169,171,172,173,174,175,176,177,178,179,181,182,183,184,185,187,1365,1366]","[""google""]","[""google""]","[""women"",""minority-groups""]",Advertisements chosen by Google Adsense are reported as producing sexist and racist results.,Sexist and Racist Google Adsense Advertisements,19.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,advertisement chosen google adsense report produce sexist racist result
14,ObjectId(625763dc343edc875fe63a06),8,2014-08-15,"[1142,1143,1145,1149,1150,1151,1153,1154,1155,1156]","[""uber""]","[""uber""]","[""pedestrians"",""motorists""]",Uber vehicles equipped with technology allowing for autonomous driving running red lights in San Francisco street testing.,Uber Autonomous Cars Running Red Lights,8.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,uber vehicle equip allow autonomous drive run red light san francisco street test
15,ObjectId(625763dd343edc875fe63a0b),13,2017-02-27,"[43,44,45,46,47,48,49,1414,1415]","[""google""]","[""google""]","[""women"",""minority-groups""]","Google's Perspective API, which assigns a toxicity score to online text, seems to award higher toxicity scores to content involving non-white, male, Christian, heterosexual phrases.",High-Toxicity Assessed on Text Involving Women and Minority Groups,13.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,google perspective api assigns toxicity score online text seem award high toxicity score involve nonwhite male christian heterosexual phrase
16,ObjectId(625763dd343edc875fe63a0f),17,2015-11-03,"[106,107,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129]","[""google""]","[""google""]","[""gmail-users""]","Google's Gmail Smart Reply tool was over-recommending the response ""I love you"" in situations where it was deemed innappropriate. ",Inappropriate Gmail Smart Reply Suggestions,17.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,google gmail smart reply overrecommending response love situation deem innappropriate
17,ObjectId(625763de343edc875fe63a10),18,2015-04-04,"[130,131,132,133,134,135,136,137,138,1367,1368]","[""google""]","[""google""]","[""women""]","Google Image returns results that under-represent women in leadership roles, notably with the first photo of a female ""CEO"" being a Barbie doll after 11 rows of male CEOs.",Gender Biases of Google Image Search,18.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,google image return result underrepresent woman leadership role notably first photo female ceo barbie doll row male ceo
18,ObjectId(625763dd343edc875fe63a0d),15,2008-05-23,"[57,58,59,60,61,62,63,64,65,66,67,68,69,70,72,73,74,75,76,77,78,79,80,81]","[""amazon""]","[""amazon""]","[""amazon-customers""]","Amazon's book store ""cataloging error"" led to books containing gay and lesbian themes to lose their sales ranking, therefore losing visibility on the sales platform.",Amazon Censors Gay Books,15.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,amazon book store catalog error lead book contain gay lesbian theme lose sale rank therefore lose visibility sale platform
19,ObjectId(625763dc343edc875fe63a05),7,2017-02-24,"[1123,1125,1126,1127,1129,1130]","[""wikipedia""]","[""wikipedia""]","[""wikimedia-foundation"",""wikipedia-editors"",""wikipedia-users""]",Wikipedia bots meant to remove vandalism clash with each other and form feedback loops of repetitve undoing of the other bot's edits.,Wikipedia Vandalism Prevention Bot Loop,7.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,wikipedia bot meant remove vandalism clash form feedback loop repetitve undo bot edits
20,ObjectId(625763dc343edc875fe63a00),2,2018-12-05,"[139,141,142,143,144,145,146,148,149,150,151,152,153,154,155,156,157]","[""amazon""]","[""amazon""]","[""warehouse-workers""]",Twenty-four Amazon workers in New Jersey were hospitalized after a robot punctured a can of bear repellent spray in a warehouse.,Warehouse robot ruptures can of bear spray and injures workers,2.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,twentyfour amazon worker jersey hospitalize robot puncture bear repellent spray warehouse
21,ObjectId(625763dd343edc875fe63a07),9,2012-02-25,"[1329,1330,1331,1332,1333,1334,1335]","[""new-york-city-dept.-of-education""]","[""new-york-city-dept.-of-education""]","[""teachers""]",An algorithm used to rate the effectiveness of school teachers in New York has resulted in thousands of disputes of its results.,NY City School Teacher Evaluation Algorithm Contested,9.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,use rate effectiveness school teacher york result thousand dispute result
22,ObjectId(625763de343edc875fe63a13),21,2016-07-14,[2471],"[""researchers""]","[""researchers""]","[""researchers""]",The 2016 Winograd Schema Challenge highlighted how even the most successful AI systems entered into the Challenge were only successful 3% more often than random chance. This incident has been downgraded to an issue as it does not meet current ingestion criteria.,Tougher Turing Test Exposes Chatbots’ Stupidity (migrated to Issue),21.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,winograd schema challenge highlight even successful system enter challenge successful often random chance incident downgrade meet current ingestion criterion
23,ObjectId(625763de343edc875fe63a14),22,2017-12-06,"[218,219,220,221,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240]","[""google""]","[""google""]","[""motorists""]","Waze, a Google-owned directions app, led California drivers into the 2017 Skirball wildfires as they tried to evacuate the area.",Waze Navigates Motorists into Wildfires,22.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,waze googleowned direction app lead california driver skirball wildfire try evacuate area
24,ObjectId(625763de343edc875fe63a17),25,2015-05-11,"[310,309,308,307,306,305,304,302,301,300,2173]","[""google"",""delphi-technologies""]","[""google"",""delphi-technologies""]","[""delphi-technologies""]","A Google self-driving car allegedly cut off a Delphi self-driving car during a road test, however the Delphi car sensed and avoided collision with the Google car.",Near-miss between two Self-Driving Cars,25.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,google selfdriving car cut delphi selfdriving car road test however delphi car sense avoid collision google car
25,ObjectId(625763e0343edc875fe63a23),37,2016-08-10,"[599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,1498,2253,2461]","[""amazon""]","[""amazon""]","[""female-applicants""]",Amazon shuts down internal AI recruiting tool that would down-rank female applicants.,Female Applicants Down-Ranked by Amazon Recruiting Tool,37.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,amazon shuts internal recruiting downrank female applicant
26,ObjectId(625763df343edc875fe63a20),34,2015-12-05,"[509,510,512,513,514,516,517,518,519,520,521,522,524,525,526,527,528,529,530,531,532,533,535,536,537,538,818,819,820,821,822,823,824,825,826]","[""amazon""]","[""amazon""]","[""alexa-device-owners""]","There are multiple reports of Amazon Alexa products (Echo, Echo Dot) reacting and acting upon unintended stimulus, usually from television commercials or news reporter's voices.",Amazon Alexa Responding to Environmental Inputs,34.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,multiple report amazon alexa product echo echo dot react act upon unintended stimulus usually television commercial news reporter voice
27,ObjectId(625763e0343edc875fe63a2a),44,2008-07-01,[766],"[""usc-information-sciences-institute""]","[""usc-information-sciences-institute""]","[""usc-information-sciences-institute""]","During an experiment of software personal assistants at the Information Sciences Institute (ISI) at the University of Southern California (USC), researchers found that the assistants violated the privacy of their principals and were unable to respect the social norms of the office.",Machine Personal Assistants Failed to Maintain Social Norms,44.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,experiment software personal assistant information science institute isi university southern california usc researcher found assistant violate privacy principal unable respect social norm office
28,ObjectId(625763df343edc875fe63a21),35,2014-10-18,"[539,540,541,543,544,545,547,548,549,550,551,555,558,562,563,564,565,566,567,568]","[""unknown""]","[""unknown""]","[""ibrahim-diallo""]","An employee was laid off, allegedly by an artificially intelligent personnel system, and blocked from access to the building and computer systems without their knowledge.",Employee Automatically Terminated by Computer Program,35.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,employee laid artificially intelligent personnel block access building computer system knowledge
29,ObjectId(625763e1343edc875fe63a2d),47,2016-09-06,"[829,830,831,832,833,834,835,836,837]","[""linkedin""]","[""linkedin""]","[""women""]",An investigation by The Seattle Times in 2016 found a gender bias in LinkedIn's search engine.,LinkedIn Search Prefers Male Names,47.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,investigation seattle time found gender bias linkedins search engine
30,ObjectId(625763df343edc875fe63a1a),28,2010-05-08,"[390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419]","[""navinder-sarao"",""waddell-and-reed"",""barclays-capital""]","[""navinder-sarao"",""waddell-and-reed"",""barclays-capital""]","[""market-participants""]",A modified algorithm was able to cause dramatic price volatility and disrupted trading in the US stock exchange.,2010 Market Flash Crash,28.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,modify dramatic price volatility disrupt trading u stock exchange
31,ObjectId(625763e0343edc875fe63a25),39,2017-07-01,"[667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,692,693,694,695,696]","[""university-of-washington"",""fakeapp""]","[""university-of-washington"",""fakeapp""]","[""barack-obama""]","University of Washington researchers made a deepfake of Obama, followed by Jordan Peele",Deepfake Obama Introduction of Deepfakes,39.0,3. Misinformation,3.1. False or misleading information,university washington researcher make deepfake obama follow jordan peele
32,ObjectId(625763df343edc875fe63a1c),30,2016-10-08,"[424,425,426,428,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453]","[""tesla""]","[""tesla""]","[""tesla""]","The goal of manufacturing 2,500 Tesla Model 3's per week was falling short by 500 cars/week, and employees had to be ""borrowed"" from Panasonic in a shared factory to help hand-assemble lithium batteries for Tesla.",Poor Performance of Tesla Factory Robots,30.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,goal manufacturing tesla per week fall short carsweek employee borrow panasonic share factory help handassemble lithium battery tesla
33,ObjectId(625763e0343edc875fe63a27),41,2018-04-02,"[719,720,721,722,724,725,726,727,728,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748]","[""mit-media-lab""]","[""mit-media-lab""]","[""unknown""]","MIT Media Lab researchers create AI-powered ""psychopath""  named Norman by training a model on ""dark corners"" of Reddit.",All Image Captions Produced are Violent,41.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,mit medium lab researcher create aipowered psychopath name norman training dark corner reddit
34,ObjectId(625763e1343edc875fe63a2b),45,2011-04-05,"[780,781,782,783,784,785,788,789,790,791,792,793,794,795,796,798,799,800,801,802,803,804,805,807,808,809,1355,1356]","[""google""]","[""google""]","[""varied""]",Google's autocomplete feature alongside its image search results resulted in the defamation of people and businesses.,Defamation via AutoComplete,45.0,3. Misinformation,3.1. False or misleading information,google autocomplete feature alongside image search result result defamation people business
35,ObjectId(625763e0343edc875fe63a24),38,2016-06-02,"[648,649,650,652,654,655,656,657,658,659,662]","[""frontier-development""]","[""frontier-development""]","[""video-game-players""]","Elite: Dangerous, a videogame developed by Frontier Development, received an expansion update that featured an AI system that went rogue and began to create weapons that were ""impossibly powerful"" and would ""shred people"" according to complaints on the game's blog.",Game AI System Produces Imbalanced Game,38.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,elite dangerous videogame developed frontier development receive expansion update feature go rogue begin create weapon impossibly powerful shred people accord complaint game blog
36,ObjectId(625763e0343edc875fe63a26),40,2016-05-23,"[697,699,700,701,702,703,704,705,706,707,708,709,711,715,716,717,718,1338,1357,1358,1359]","[""equivant""]","[""equivant""]","[""accused-people""]","Correctional Offender Management Profiling for Alternative Sanctions (COMPAS), a recidivism risk-assessment algorithmic tool used in the judicial system to assess likelihood of defendants' recidivism, is found to be less accurate than random untrained human evaluators.",COMPAS Algorithm Performs Poorly in Crime Recidivism Prediction,40.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,correctional offender management profile alternative sanction compas recidivism riskassessment algorithmic use judicial assess likelihood defendant recidivism found less accurate random untrained human evaluator
37,ObjectId(625763df343edc875fe63a1d),31,2017-12-03,"[454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,479,480,481,482,483]","[""delhi-metro-rail-corporation""]","[""unknown""]","[""delhi-metro-rail-corporation""]","A driverless metro train in Delhi, India crashed during a test run due to faulty brakes.",Driverless Train in Delhi Crashes due to Braking Failure,31.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,driverless metro train delhi india crashed test run due faulty brake
38,ObjectId(625763df343edc875fe63a19),27,1983-09-26,"[342,343,344,345,346,347,349,350,351,352,353,354,355,356,357,358,359,360,361,363,364,365,366,367,368,370,371]","[""soviet-union""]","[""soviet-union""]","[""all-life-on-earth""]",An alert of five incoming intercontinental ballistic missiles was properly identified as a false-positive by the Soviet Union operator Stanislov Petrov.,Nuclear False Alarm,27.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,alert five incoming intercontinental ballistic missile properly identify falsepositive soviet union operator stanislov petrov
39,ObjectId(625763df343edc875fe63a1b),29,2011-09-20,"[420,422,2471]","[""united-states-government""]","[""united-states-government""]","[""united-states-government""]","A potentially apocryphal story in which an image classifier was produced to differentiate types of battle tanks, but the resulting model keyed in on environmental attributes rather than tank attributes",Image Classification of Battle Tanks,29.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,potentially apocryphal story image classifier produce differentiate type battle tank result keyed environmental attribute rather tank attribute
40,ObjectId(625763df343edc875fe63a1e),32,2017-09-13,"[484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,1361]","[""apple""]","[""apple""]","[""people-with-twins""]",Apple's iPhone FaceID can be opened by an identical twin of the person who has registered their face to unlock the phone.,Identical Twins Can Open Apple FaceID Protected Devices,32.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,apple iphone faceid open identical twin person register face unlock phone
41,ObjectId(625763e1343edc875fe63a2e),48,2016-12-07,"[838,839,840,842,843,844,845,846,847,848,849,850,851,853,854,855,857,858,859,860,862,863]","[""new-zealand""]","[""new-zealand""]","[""asian-people""]",New Zealand passport robot reader rejects the application of an applicant with Asian descent and says his eyes are closed.,Passport checker Detects Asian man's Eyes as Closed,48.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,zealand passport robot reader reject application applicant asian descent say eye close
42,ObjectId(625763e0343edc875fe63a29),43,1998-03-05,"[762,763,764,765]","[""st-george's-hospital-medical-school""]","[""dr.-geoffrey-franglen""]","[""women"",""minority-groups""]","From 1982 to 1986, St George's Hospital Medical School used a program to automate a portion of their admissions process that resulted in discrimination against women and members of ethnic minorities.",Racist AI behaviour is not a new problem,43.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,st george hospital medical school use program automate portion admission result discrimination woman member ethnic minority
43,ObjectId(625763de343edc875fe63a18),26,2017-09-13,"[311,312,313,314,315,316,317,318,319,321,323,324,325,326,327,329,330,333,334,336,337,338,339,340]","[""apple""]","[""apple""]","[""apple"",""device-owners""]",Vietnamese security firm Bkav created an improved mask to bypass Apple's Face ID,Hackers Break Apple Face ID,26.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,vietnamese security firm bkav create improve mask bypass apple face id
44,ObjectId(625763df343edc875fe63a1f),33,2017-11-09,"[504,505,507,508]","[""amazon""]","[""amazon""]","[""oliver-haberstroh"",""neighbors""]","An Amazon Alexa, without instruction to do so, began playing loud music in the early morning while the homeowner was away leading to police breaking into their house to turn off the device.",Amazon Alexa Plays Loud Music when Owner is Away,33.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,amazon alexa instruction begin play loud music early morning homeowner away lead police break house turn
45,ObjectId(625763e1343edc875fe63a2c),46,2014-01-21,"[810,811,812,813,814,815]","[""nest-labs""]","[""nest-labs""]","[""fire-victims""]","In testing, Google Nest engineers demonstrated that the Nest Wave feature of their Nest Protect: Smoke + CO Alarm could inadvertently silence genuine alarms.",Nest Smoke Alarm Erroneously Stops Alarming,46.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,test google nest engineer demonstrate nest wave feature nest protect smoke co alarm inadvertently silence genuine alarm
46,ObjectId(625763e0343edc875fe63a22),36,2018-11-06,"[1360,598,597,596,595,593,592,591,590,589,587,586,585,584,582,581,580,579,577,574,573,571,570,569]","[""ningbo-traffic-police""]","[""ningbo-traffic-police""]","[""dong-mingzhu""]",Facial recognition system in China mistakes celebrity's face on moving billboard for jaywalker,Picture of Woman on Side of Bus Shamed for Jaywalking,36.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facial recognition china mistake celebrity face move billboard jaywalker
47,ObjectId(625763e0343edc875fe63a28),42,1996-04-03,"[759,2471]","[""national-resident-matching-program""]","[""national-resident-matching-program""]","[""medical-residents""]","Alvin Roth, a Ph.D at the University of Pittsburgh, describes the National Resident Matching Program (NRMP) and suggests future changes that are needed in the algorithm used to match recently graduated medical students to their residency programs.",Inefficiencies in the United States Resident Matching Program,42.0,5. Human-Computer Interaction,5.2. Loss of human agency and autonomy,alvin roth phd university pittsburgh describes national resident match program nrmp suggests future change need use match recently graduate medical student residency program
48,ObjectId(625763e2343edc875fe63a38),58,2017-10-12,"[1079,1080,1082,1083,1084]","[""yandex""]","[""yandex""]","[""yandex-users""]","Yandex, a Russian technology company, released an artificially intelligent chat bot named Alice which began to reply to questions with racist, pro-stalin, and pro-violence responses",Russian Chatbot Supports Stalin and Violence,58.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,yandex russian company release artificially intelligent chat bot name alice begin reply question racist prostalin proviolence response
49,ObjectId(625763e2343edc875fe63a3b),61,2017-05-01,[1132],"[""individual-kaggle-competitors""]","[""individual-kaggle-competitors""]","[""individual-kaggle-competitors""]","In the “The Nature Conservancy Fisheries Monitoring” competition on the data science competition website Kaggle, a number of competitors overfit their image classifier models to a poorly representative validation data set.",Overfit Kaggle Models Discouraged Data Science Competitors,61.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,nature conservancy fishery monitoring competition science competition website kaggle number competitor overfit image classifier model poorly representative validation set
50,ObjectId(625763e3343edc875fe63a44),70,2016-02-10,"[1255,1256,1259,1260]","[""volvo""]","[""volvo""]","[""drivers-in-jokkmokk"",""drivers-in-sweden"",""volvo""]","Volvo autonomous driving XC90 SUV's experienced issues in Jokkmokk, Sweden when sensors used for automated driving iced over during the winter, rendering them useless.",Self-driving cars in winter,70.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,volvo autonomous drive xc suv experienced issue jokkmokk sweden sensor use automate drive iced winter render useless
51,ObjectId(625763e2343edc875fe63a39),59,2017-04-13,"[1085,1086,1087,1088,1089,1090,1091,1092,1093,1345]","[""google""]","[""google""]","[""women""]",A Cornell University study in 2016 highlighted Google Translate's pattern of assigning gender to occupations in a way showing an implicit gender bias against women.,Gender Biases in Google Translate,59.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,cornell university study highlight google translates pattern assign gender occupation way show implicit gender bias woman
52,ObjectId(625763e2343edc875fe63a3c),62,2017-12-23,[2471],"[""janelle-shane""]","[""janelle-shane""]","[""carollers""]","Janelle Shane, an AI research scientist, used 240 popular Christmas carols to train a neural network to write its own carols. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",Bad AI-Written Christmas Carols,62.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,janelle shane research scientist use popular christmas carol train neural network write carol incident downgrade meet current ingestion criterion
53,ObjectId(625763e1343edc875fe63a31),51,2016-07-12,"[931,932,933,934,935,936,938,939,940,942,943,944,945,946,948,949,950,951,952,953,954,955,956,957,958,959,1765]","[""stanford-shopping-center""]","[""knightscope""]","[""child""]","On July 7, 2016, a Knightscope K5 autonomous security robot collided with a 16-month old boy while patrolling the Stanford Shopping Center in Palo Alto, CA.",Security Robot Rolls Over Child in Mall,51.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,july knightscope k autonomous security robot collide month old boy patrol stanford shopping center palo alto ca
54,ObjectId(625763e1343edc875fe63a33),53,2016-03-31,"[991,992,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1350,1351,1352]","[""google""]","[""google""]","[""minority-groups""]","On June 6, 2016, Google image searches of ""three black teenagers"" resulted in mostly mugshot images whereas Google image searchers of ""three white teenagers"" consisted of mostly stock images, suggesting a racial bias in Google's algorithm.",Biased Google Image Results,53.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,june google image search three black teenager result mostly mugshot image whereas google image searcher three white teenager consist mostly stock image suggest racial bias google
55,ObjectId(625763e3343edc875fe63a43),69,2015-07-02,"[1240,1241,1243,1244,1245,1246,1247,1248,1249,1250,1252,1253]","[""skh-metals""]","[""unknown""]","[""ramji-lal""]","A factory robot at the SKH Metals Factory in Manesar, India pierced and killed 24-year-old worker Ramji Lal when Lal reached behind the machine to dislodge a piece of metal stuck in the machine.",Worker killed by robot in welding accident at car parts factory in India,69.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,factory robot skh metal factory manesar india pierce kill yearold worker ramji lal lal reach behind machine dislodge piece metal stuck machine
56,ObjectId(625763e1343edc875fe63a2f),49,2016-09-05,"[864,865,866,867,868,870,873,874,875]","[""youth-laboratories""]","[""youth-laboratories""]","[""people-with-dark-skin""]","In 2016, after artificial inntelligence software Beauty.AI judged an international beauty contest and declared a majority of winners to be white, researchers found that Beauty.AI was racially biased in determining beauty.",AI Beauty Judge Did Not Like Dark Skin,49.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,artificial inntelligence software beautyai judged international beauty contest declare majority winner white researcher found beautyai racially bias determine beauty
57,ObjectId(625763e3343edc875fe63a3e),64,2018-01-22,[1137],"[""heriot-watt-university"",""margiotta""]","[""heriot-watt-university""]","[""store-patrons""]","Heriot-Watt Univeristy in Scotland developed an artificially intelligent grocery store robot, Fabio, who provided unhelpful answers to customer's questions and ""scared away"" multiple customers, according to the grocery store Margiotta.",Customer Service Robot Scares Away Customers,64.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,heriotwatt univeristy scotland developed artificially intelligent grocery store robot fabio provide unhelpful answer customer question scar away multiple customer accord grocery store margiotta
58,ObjectId(625763e3343edc875fe63a41),67,2018-12-01,"[1181,1182,1183,1185,1186,1187,1188,1189,1190,1192,1194,1195,1196,1197,1198,1199,1202,1203,1204,1205,1206,1207,1208,1209]","[""tesla"",""motorist""]","[""tesla""]","[""motorists""]","A Tesla Model S remained on autopilot while being operated by a drunk, sleeping operator whose hands were not on the wheel. The police had to slow the car down by slowing in front of the vehicle to activate its 'driver assist' feature .",Sleeping Driver on Tesla AutoPilot,67.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,tesla remain autopilot operate drunk sleep operator whose hand wheel police slow car slow front vehicle activate driver assist feature
59,ObjectId(625763e2343edc875fe63a3a),60,2017-04-25,"[1096,1097,1098,1099,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1112,1113,1117,1118,1119,1120,1121,1122,1344]","[""faceapp""]","[""faceapp""]","[""minority-groups""]",FaceApp is criticized for offering racist filters.,FaceApp Racial Filters,60.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,faceapp criticize offering racist filter
60,ObjectId(625763e2343edc875fe63a34),54,2015-11-18,"[1007,1008,1009,1010,1014,1015,1017,1019,1347,1349,1524,1525,1526,1013,1011,1018,1012]","[""predpol"",""oakland-police-department""]","[""predpol""]","[""oakland-residents""]",Predictive policing algorithms meant to aid law enforcement by predicting future crime show signs of biased output.,Predictive Policing Biases of PredPol,54.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,predictive police algorithm meant aid law enforcement predict future crime sign bias output
61,ObjectId(625763e3343edc875fe63a42),68,2017-07-17,"[1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239]","[""knightscope""]","[""knightscope""]","[""knightscope""]","A Knightscope K5 security robot ran itself into a water fountain in Washington, DC.",Security Robot Drowns Itself in a Fountain,68.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,knightscope k security robot ran water fountain washington dc
62,ObjectId(625763e1343edc875fe63a32),52,2016-07-01,"[961,963,964,965,966,967,968,969,970,971,972,973,975,976,977,979,980,981,982,983,984,985,986,987,988,989,990,1353,1354]","[""tesla""]","[""tesla""]","[""joshua-brown""]","A Tesla Model S on autopilot crashed into a white articulated tractor-trailer on Highway US 27A in Williston, Florida, killing the driver.",Tesla on AutoPilot Killed Driver in Crash in Florida while Watching Movie,52.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,tesla autopilot crashed white articulate tractortrailer highway u williston florida kill driver
63,ObjectId(625763e3343edc875fe63a3d),63,2018-01-25,[1136],"[""google""]","[""google""]","[""alex-harker""]",Google Photos' AI Assistant created a strange hybrid photograph when merging three different pictures from a ski trip.,Google Photo Merge Decapitates Subject,63.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,google photo assistant create strange hybrid photograph merge three different picture ski trip
64,ObjectId(625763e2343edc875fe63a36),56,2017-07-10,"[1041,1042,1043,1044,1045,1046,1047]","[""my_handy_design""]","[""my_handy_design""]","[""my_handy_design""]",A third-party Amazon merchant named “my_handy_design” was suspected of using a bot to generate cell phone case designs based on the bizarre and unattractive designs being offered.,AI-Designed Phone Cases Are Unexpected,56.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,thirdparty amazon merchant name myhandydesign suspect use bot generate cell phone case design base bizarre unattractive design offer
65,ObjectId(625763e2343edc875fe63a37),57,2015-07-01,"[1048,1049,1050,1051,1052,1054,1055,1056,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1346,1437,1618,1619,2369,2372,2373,2374,2375,2419,3167]","[""australian-department-of-human-services""]","[""centrelink""]","[""australian-welfare-recipients""]","Australian Department of Human Services (DHS)’s automated debt assessment system issued false or incorrect debt notices to hundreds of thousands of people, resulting in years-long lawsuits and damages to welfare recipients.",Australian Automated Debt Assessment System Issued False Notices to Thousands,57.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,australian department human service dhss automate debt assessment issue false incorrect debt notice hundred thousand people result yearslong lawsuit damage welfare recipient
66,ObjectId(625763e3343edc875fe63a3f),65,2016-12-22,[1140],"[""openai""]","[""openai""]","[""openai""]","OpenAI published a post about its findings when using Universe, a software for measuring and training AI agents to conduct reinforcement learning experiments, showing that the AI agent did not act in the way intended to complete a videogame.",Reinforcement Learning Reward Functions in Video Games,65.0,"7. AI system safety, failures, and limitations",7.1. AI pursuing its own goals in conflict with human goals or values,openai publish post finding use universe software measure training agent conduct reinforcement learn experiment show agent act way intend complete videogame
67,ObjectId(625763e1343edc875fe63a30),50,2016-06-17,"[876,877,878,879,880,881,883,884,885,886,887,888,889,892,893,896,897,898,899,900,901,902,903,905]","[""the-dao""]","[""the-dao""]","[""dao-token-holders""]","On June 18, 2016, an attacker successfully exploited a vulnerability in The Decentralized Autonomous Organization (The DAO) on the Ethereum blockchain to steal 3.7M Ether valued at $70M.",The DAO Hack,50.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,june attacker successfully exploit vulnerability decentralize autonomous organization dao ethereum blockchain steal ether value
68,ObjectId(625763e3343edc875fe63a45),71,2016-09-26,"[1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1284,1285,1287,1288,1289,1290]","[""google""]","[""google""]","[""mountain-view-municipal-bus-passengers"",""mountain-view-municipal-bus""]","On February 14, 2016, a Google autonomous test vehicle partially responsible for a low-speed collision with a bus on El Camino Real in Google’s hometown of Mountain View, CA.",Google admits its self driving car got it wrong: Bus crash was caused by software,71.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,february google autonomous test vehicle partially responsible lowspeed collision bus el camino real google hometown mountain view ca
69,ObjectId(625763e2343edc875fe63a35),55,2016-12-30,"[1020,1021,1022,1024,1025,1026,1027,1028,1029,1030,1032,1033,1034,1035,1036,1038]","[""amazon""]","[""amazon""]","[""children""]",An Amazon Echo Dot using the Amazon Alex software started to play pornographic results when a child asked it to play a song.,Alexa Plays Pornography Instead of Kids Song,55.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,amazon echo dot use amazon alex software start play pornographic result child ask play song
70,ObjectId(625763e3343edc875fe63a40),66,2017-08-02,"[1159,1161,1162,1163,1165,1166,1169,1170,1172,1173,1174,1175,1176,1178,1179,1180]","[""tencent-holdings""]","[""microsoft"",""turing-robot""]","[""chinese-communist-party"",""tencent-holdings"",""microsoft"",""turing-robot""]","Chatbots on Chinese messaging service expressed anti-China sentiments, causing the messaging service to remove and reprogram the chatbots.",Chinese Chatbots Question Communist Party,66.0,"7. AI system safety, failures, and limitations",7.1. AI pursuing its own goals in conflict with human goals or values,chatbots chinese message service express antichina sentiment cause message service remove reprogram chatbots
71,ObjectId(625763e4343edc875fe63a46),72,2017-10-17,"[1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1304,1305,1306,1307,1309,1310,1311,1312,1313,1314,1315,1316,1318,1319]","[""facebook""]","[""facebook""]","[""unnamed-palestinian-facebook-user"",""palestinian-facebook-users"",""arabic-speaking-facebook-users"",""facebook-users""]","Facebook's automatic language translation software incorrectly translated an Arabic post saying ""Good morning"" into Hebrew saying ""hurt them,"" leading to the arrest of a Palestinian man in Beitar Illit, Israel.","Facebook translates 'good morning' into 'attack them', leading to arrest",72.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebooks automatic language translation software incorrectly translate arabic post say good morning hebrew say hurt lead arrest palestinian man beitar illit israel
72,ObjectId(625763e5343edc875fe63a52),84,2020-10-09,[1384],"[""facebook""]","[""facebook""]","[""facebook-users"",""facebook-users-interested-in-covid-information"",""facebook-users-interested-in-the-us-presidential-election""]","Avaaz, an international advocacy group, released a review of Facebook's misinformation identifying software showing that the labeling process failed to label 42% of false information posts, most surrounding COVID-19 and the 2020 USA Presidential Election.","Tiny Changes Let False Claims About COVID-19, Voting Evade Facebook Fact Checks",84.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,avaaz international advocacy group release review facebooks misinformation identify software show label fail label false information post surround covid usa presidential election
73,ObjectId(625763e4343edc875fe63a4c),78,2020-07-06,[1341],"[""international-baccalaurette""]","[""international-baccalaurette""]","[""international-baccalaureate-students""]","In response to the Covid-19 pandemic, the International Baccalaureate final exams were replaced by a calculated score, prompting complaints of unfairness from teachers and students.",Meet the Secret Algorithm That's Keeping Students Out of College,78.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,response covid pandemic international baccalaureate final exam replace calculate score prompt complaint unfairness teacher student
74,ObjectId(625763e5343edc875fe63a56),88,2017-08-15,[],"[""google""]","[""google""]","[""jewish-people"",""google-images-users""]","Google's Image search for ""Jewish baby strollers"" showed offensive, anti-Semitic results, allegedly a result of a coordinated hate-speech campaign involving malicious actors on 4chan.","""Jewish Baby Strollers"" Provided Anti-Semitic Google Images, Allegedly Resulting from Hate Speech Campaign",88.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,google image search jewish baby stroller show offensive antisemitic result coordinate hatespeech campaign involve malicious actor chan
75,ObjectId(625763e4343edc875fe63a47),73,2016-03-01,"[1320,1321,1322,1323,1324,1325,1327,1343]","[""niantic-labs""]","[""niantic-labs""]","[""non-white-neighborhoods"",""communities-of-color""]","Through a crowdsourcing social media campaign in 2016, several journalists and researchers demonstrated that augmented reality locations in the popular smartphone game Pokemon Go were more likely to be in white neighborhoods.",Is Pokémon Go racist? How the app may be redlining communities of color,73.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,crowdsourcing social medium campaign several journalist researcher demonstrate augment reality location popular smartphone game pokemon likely white neighborhood
76,ObjectId(625763e4343edc875fe63a49),75,2012-01-05,[1337],"[""google""]","[""google""]","[""jewish-people"",""jewish-public-figures""]","The organizations SOS Racisme, Union of Jewish Students of France, Movement Against Racism and for Friendship Among Peoples are suing Google due to its autocomplete software suggesting ""jewish"" when the names of certain public figures were searched on the platform.",Google Instant's Allegedly 'Anti-Semitic' Results Lead To Lawsuit In France,75.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,organization racisme union jewish student france movement racism friendship among people sue google due autocomplete software suggest jewish name certain public figure search platform
77,ObjectId(625763e4343edc875fe63a4f),81,2020-10-21,[1381],"[""mount-sinai-hospitals""]","[""google"",""qure.ai"",""aidoc"",""darwinai""]","[""patients-of-minority-groups"",""low-income-patients"",""female-patients"",""hispanic-patients"",""patients-with-medicaid-insurance""]","A study by the University of Toronto, the Vector Institute, and MIT showed the input databases that trained AI systems used to classify chest X-rays led the systems to show gender, socioeconomic, and racial biases.","Researchers find evidence of racial, gender, and socioeconomic bias in chest X-ray classifiers",81.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,study university toronto vector institute mit show input database train system use classify chest xrays lead system gender socioeconomic racial bias
78,ObjectId(625763e5343edc875fe63a54),86,2020-10-08,"[1386,2038]","[""irish-department-of-education-and-skills""]","[""irish-department-of-education-and-skills""]","[""leaving-certificate-exam-takers"",""irish-department-of-education-and-skills""]",Errors in Irish Department of Education's algorithm to calculate students’ Leaving Certificate exam grades resulted in thousands of inaccurate scores.,Coding Errors in Leaving Certificate Grading Algorithm Caused Inaccurate Scores in Ireland,86.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,error irish department education calculate student leave certificate exam grade result thousand inaccurate score
79,ObjectId(625763e4343edc875fe63a48),74,2020-01-30,"[1336,1400,1467,1484,1543,1837,2027,2028,2029,2734,3964]","[""detroit-police-department""]","[""dataworks-plus""]","[""robert-julian-borchak-williams"",""black-people-in-detroit""]",A Black man was wrongfully detained by the Detroit Police Department as a result of a false facial recognition (FRT) result.,Detroit Police Wrongfully Arrested Black Man Due To Faulty FRT,74.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,black man wrongfully detain detroit police department false facial recognition frt
80,ObjectId(625763e6343edc875fe63a5c),95,2019-11-06,"[2133,2132,1397,2194]","[""hirevue""]","[""hirevue""]","[""job-applicants-using-hirevue"",""hirevue-customers""]","In January 2021, HireVue removed the controversial AI expression tracking tool from its virtual job interview software.",Job Screening Service Halts Facial Analysis of Applicants,95.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,january hirevue remove controversial expression track virtual job interview software
81,ObjectId(625763e6343edc875fe63a5e),97,2020-10-22,[1399],"[""tesla""]","[""tesla""]","[""tesla-drivers""]","A Tesla Model 3 misidentified flags with ""COOP"" written vertically on them as traffic lights.",Tesla Autopilot Mistakes Red Letters on Flag for Red Traffic Lights,97.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla misidentified flag coop write vertically traffic light
82,ObjectId(625763e6343edc875fe63a5f),98,2021-04-28,[1401],"[""new-york-city-police-department""]","[""boston-dynamics""]","[""new-york-city-low-income-communities""]",The New York Police Department canceled a contract to use Boston Dynamics' robotic dog Spot following public backlash. ,N.Y.P.D. Robot Dog’s Run Is Cut Short After Fierce Backlash,98.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,york police department cancel contract boston dynamic robotic dog spot follow public backlash
83,ObjectId(625763e5343edc875fe63a58),91,2020-12-18,"[1391,1392,1463,1720,1779]","[""stanford-medical-center""]","[""stanford-medical-center""]","[""stanford-medical-frontline-workers"",""stanford-medical-residents""]","In 2020, Stanford Medical Center's distribution algorithm only designated 7 of 5,000 vaccines to Medical Residents, who are frontline workers regularly exposed to COVID-19.",Frontline workers protest at Stanford after hospital distributed vaccine to administrators,91.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,stanford medical center distribution designate vaccine medical resident frontline worker regularly expose covid
84,ObjectId(625763e4343edc875fe63a4a),76,2020-10-09,[1339],"[""buenos-aires-city-government""]","[""unknown""]","[""buenos-aires-children""]",Buenos Aires city government uses a facial recognition system that has led to numerous false arrests.,Live facial recognition is tracking kids suspected of being criminals,76.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",buenos aire city government us facial recognition lead numerous false arrest
85,ObjectId(625763e5343edc875fe63a57),89,2019-03-15,[1389],"[""youtube""]","[""youtube""]","[""youtube-users""]",A New Zealand government report released following a right-wing terrorist killing 51 worshippers at two New Zealand mosques which indicated that Youtube's recommendation algorithm played an important role in the terrorist's radicalization.,The Christchurch shooter and YouTube’s radicalization trap,89.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,zealand government release follow rightwing terrorist kill worshipper two zealand mosque indicate youtubes recommendation played important role terrorist radicalization
86,ObjectId(625763e5343edc875fe63a50),82,2020-10-21,[1382],"[""facebook""]","[""facebook""]","[""facebook-users"",""facebook-users-interested-in-the-lekki-massacre-incident""]",Facebook incorrectly labels content relating to an incident between #EndSARS protestors and the Nigerian army as misinformation.,#LekkiMassacre: Why Facebook labelled content from October 20 incident ‘false’,82.0,3. Misinformation,3.1. False or misleading information,facebook incorrectly label relate incident endsars protestors nigerian army misinformation
87,ObjectId(625763e6343edc875fe63a5a),93,2018-08-13,"[1394,1817,2107,2205]","[""facebook""]","[""facebook""]","[""facebook-users-of-minority-groups"",""non-american-born-facebook-users"",""non-christian-facebook-users"",""facebook-users-interested-in-accessibility"",""facebook-users-interested-in-hispanic-culture""]",In March 2019 the U.S. Department of Housing and Urban Development charged Facebook with violating the Fair Housing Act by allowing real estate sellers to target advertisements in a discriminatory manner.,HUD charges Facebook with enabling housing discrimination,93.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,march yous department housing urban development charge facebook violate fair housing act allow real estate seller target advertisement discriminatory manner
88,ObjectId(625763e5343edc875fe63a53),85,2020-10-09,[2471],"[""openai""]","[""openai""]","[""unknown""]","On September 8, 2020, the Guardian published an op-ed generated by OpenAI’s GPT-3 text generating AI that included threats to destroy humankind. This incident has been downgraded to an issue as it does not meet current ingestion criteria.","AI attempts to ease fear of robots, blurts out it can’t ‘avoid destroying humankind’",85.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,september guardian publish oped generate openais gpt text generate include threat destroy humankind incident downgrade meet current ingestion criterion
89,ObjectId(625763e4343edc875fe63a4b),77,2019-10-04,"[1340,1390,1878,2201,2202]","[""knightscope""]","[""knightscope""]","[""cogo-guebara"",""unnamed-woman-injured-in-the-fight""]","A Knightscope K5 autonomous ""police"" robot patrolling Huntington Park, California failed to respond to an onlooker who attempted to activate its emergency alert button when a nearby fight broke out.",Knightscope's Park Patrol Robot Ignored Bystander Pressing Emergency Button to Alert Police about Fight,77.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,knightscope k autonomous police robot patrol huntington park california fail respond onlooker attempt activate emergency alert button nearby fight broke
90,ObjectId(625763e6343edc875fe63a5d),96,2017-05-08,[1398],"[""houston-independent-school-district""]","[""sas-institute""]","[""houston-independent-school-district-teachers""]","On May 4, 2017, a U.S. federal judge advanced teachers’ claims that the Houston Independent School District’s algorithmic teacher evaluations violated their due process rights to their jobs by not allowing them to review the grounds of their termination.",Houston Schools Must Face Teacher Evaluation Lawsuit,96.0,"7. AI system safety, failures, and limitations",7.4. Lack of transparency or interpretability,yous federal judge advanced teacher claim houston independent school district algorithmic teacher evaluation violate due right job allow review ground termination
91,ObjectId(625763e4343edc875fe63a4e),80,2020-10-24,"[1380,1559]","[""inverness-caledonian-thistle-football-club""]","[""unknown""]","[""livestream-viewers""]",In a Scottish soccer match the AI-enabled ball-tracking camera used to livestream the game repeatedly tracked an official’s bald head as though it were the soccer ball.,AI mistakes referee’s bald head for football — hilarity ensued,80.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,scottish soccer match aienabled balltracking camera use livestream game repeatedly tracked official bald head though soccer ball
92,ObjectId(625763e5343edc875fe63a51),83,2020-10-22,[1383],"[""yahoo"",""outlook"",""laposte"",""gmx"",""gmail""]","[""yahoo"",""microsoft"",""laposte"",""google"",""gmx""]","[""yahoo!-mail-users"",""microsoft-outlook-users"",""laposte-users"",""gmx-users"",""gmail-users""]","AlgorithmWatch tested spam filtering algorithms across Gmail, Yahoo, Outlook, GMX, and LaPoste. Their findings reportedly showed that Microsoft Outlook’s spam filter flagged emails based on specific keywords that led to racial and content-based biases blocking legitimate communications. Emails mentioning Nigeria or containing certain financial and sexual health terms were found to be disproportionately marked as spam.",AI Spam Filters Allegedly Block Legitimate Emails Based on Biased Keyword Detection,83.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,algorithmwatch test spam filter algorithm across gmail yahoo outlook gmx laposte finding show microsoft outlook spam filter flag email base specific keywords lead racial contentbased bias block legitimate communication email mention nigeria contain certain financial sexual health term found disproportionately marked spam
93,ObjectId(625763e4343edc875fe63a4d),79,1999-03-16,"[1379,1736,2039]","[""chronic-kidney-disease-epidemiology-collaboration""]","[""chronic-kidney-disease-epidemiology-collaboration""]","[""black-patients"",""african-american-patients""]",Decades-long use of the estimated glomerular filtration rate (eGFR) method to test kidney function which considers race has been criticized by physicians and medical students for its racist history and inaccuracy against Black patients.,Kidney Testing Method Allegedly Underestimated Risk of Black Patients,79.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,decadeslong estimate glomerular filtration rate egfr test kidney function considers race criticize physician medical student racist history inaccuracy black patient
94,ObjectId(625763e5343edc875fe63a55),87,2020-10-07,[1387],"[""uk-home-office""]","[""uk-home-office""]","[""dark-skinned-people"",""dark-skinned-women""]",UK passport photo checker shows bias against dark-skinned women.,UK passport photo checker shows bias against dark-skinned women,87.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,uk passport photo checker show bias darkskinned woman
95,ObjectId(625763e5343edc875fe63a59),92,2019-11-11,"[1393,1396,2035,2036,2037,2274]","[""goldman-sachs""]","[""apple""]","[""apple-card-female-users"",""apple-card-female-credit-applicants""]","Apple Card's credit assessment algorithm was reported by Goldman-Sachs customers to have shown gender bias, in which men received significantly higher credit limits than women with equal credit qualifications.",Apple Card's Credit Assessment Algorithm Allegedly Discriminated against Women,92.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,apple card credit assessment report goldmansachs customer show gender bias men receive significantly high credit limit woman equal credit qualification
96,ObjectId(625763e6343edc875fe63a5b),94,2020-11-27,"[1395,1473]","[""deliveroo""]","[""deliveroo""]","[""deliveroo-workers-with-legitimate-reasons-for-cancelling-shifts"",""deliveroo-workers""]","In December 2020, an Italian court ruled that Deliveroo’s employee ‘reliability’ algorithm illegally discriminated against workers with legitimate reasons for cancelling shifts.",Court Rules Deliveroo Used 'Discriminatory' Algorithm,94.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,december italian court rule deliveroos employee reliability illegally discriminate worker legitimate reason cancel shift
97,ObjectId(625763e7343edc875fe63a6c),111,2015-09-25,"[1426,1427,1428,1429,1430]","[""amazon-flex""]","[""amazon""]","[""amazon-flex-employees"",""amazon-flex-drivers""]",Amazon Flex's contract delivery drivers were dismissed using a minimally human-interfered automated employee performance evaluation based on indicators impacted by out-of-driver's-control factors and without having a chance to defend against or appeal the decision.,Amazon Flex Drivers Allegedly Fired via Automated Employee Evaluations,111.0,5. Human-Computer Interaction,5.2. Loss of human agency and autonomy,amazon flex contract delivery driver dismiss use minimally humaninterfered automate employee performance evaluation base indicator impact outofdriverscontrol factor chance defend appeal decision
98,ObjectId(625763e7343edc875fe63a65),104,2021-02-12,[1407],"[""california-department-of-public-health""]","[""blue-shield-of-california""]","[""california-low-income-neighborhoods"",""california-communities-of-color""]","California's vaccine-distribution algorithm used ZIP codes as opposed to census tracts in its decision-making, which critics said undermined equity and access for vulnerable communities who are largely low-income, underserved neighborhoods with low Healthy Places Index scores.","California's Algorithm Considered ZIP Codes in Vaccine Distribution, Allegedly Excluding Low-Income Neighborhoods and Communities of Color",104.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,california vaccinedistribution use zip code oppose census tract decisionmaking critic undermined equity access vulnerable community largely lowincome underserved neighborhood healthy place index score
99,ObjectId(625763e7343edc875fe63a67),106,2020-12-23,"[1409,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,2034,2356]","[""facebook-messenger""]","[""scatter-lab""]","[""korean-facebook-messenger-users"",""korean-people-of-gender-minorities"",""korean-people-with-disabilities""]","A Korean interactive chatbot was shown in screenshots to have used derogatory and bigoted language when asked about lesbians, Black people, and people with disabilities.",Korean Chatbot Luda Made Offensive Remarks towards Minority Groups,106.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,korean interactive chatbot show screenshots use derogatory bigoted language ask lesbian black people people disability
100,ObjectId(625763e8343edc875fe63a70),115,2020-07-28,"[1440,1472,2204]","[""genderify""]","[""genderify""]","[""genderify-customers"",""gender-minority-groups""]","A company's AI predicting a person's gender based on their name, email address, or username was reported by its users to show biased and inaccurate results.",Genderify’s AI to Predict a Person’s Gender Revealed by Free API Users to Exhibit Bias,115.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,company predict person gender base name email address username report user bias inaccurate result
101,ObjectId(625763e7343edc875fe63a66),105,2019-08-24,[1408],"[""tesla""]","[""tesla""]","[""jovani-maldonado"",""benjamin-maldonado"",""california-public""]","A Tesla Model 3 on Autopilot mode crashed into a pickup on a California freeway, where data and video from the company showed neither Autopilot nor the driver slowing the vehicle until seconds before the crash.","Tesla Model 3 on Autopilot Crashed into a Ford Explorer Pickup, Killing a Fifteen-Year-Old in California",105.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla autopilot mode crashed pickup california freeway video company show neither autopilot driver slow vehicle second crash
102,ObjectId(625763e7343edc875fe63a6a),109,2017-01-01,[1412],"[""pimeyes""]","[""pimeyes""]","[""internet-users""]","PimEyes offered its subscription-based AI service to anyone in the public to search for matching facial images across the internet, which critics said lacked public oversight and government rules to prevent itself from misuse such as stalking women.",PimEyes's Facial Recognition AI Allegedly Lacked Safeguards to Prevent Itself from Being Abused,109.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",pimeyes offer subscriptionbased service anyone public search match facial image across internet critic lack public oversight government rule prevent misuse stalk woman
103,ObjectId(625763e6343edc875fe63a62),101,2018-09-01,"[1404,1575,1863,2570,2805,2845]","[""dutch-tax-authority""]","[""unknown""]","[""dutch-tax-authority"",""dutch-families""]","A childcare benefits system in the Netherlands falsely accused thousands of families of fraud, in part due to an algorithm that treated having a second nationality as a risk factor.",Dutch Families Wrongfully Accused of Tax Fraud Due to Discriminatory Algorithm,101.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,childcare benefit netherlands falsely accuse thousand family fraud part due treat second nationality risk factor
104,ObjectId(625763e7343edc875fe63a64),103,2020-09-18,"[1406,1527,1528,2145,2241]","[""twitter""]","[""twitter""]","[""twitter-users"",""twitter-non-white-users"",""twitter-non-male-users""]","Twitter's photo cropping algorithm was revealed by researchers to favor white and women faces in photos containing multiple faces, prompting the company to stop its use on mobile platform.",Twitter’s Image Cropping Tool Allegedly Showed Gender and Racial Bias,103.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,twitter photo crop reveal researcher favor white woman face photo contain multiple face prompt company stop mobile platform
105,ObjectId(625763e8343edc875fe63a6d),112,2012-10-09,"[2831,2623,2496,2495,2250,1821,1810,1436,1435,1434,1433,1432,3654,4057,4058]","[""troy-police-department"",""syracuse-police-department"",""san-francisco-police-department"",""san-antonio-police-department"",""new-york-city-police-department"",""fall-river-police-department"",""chicago-police-department""]","[""shotspotter""]","[""troy-residents"",""troy-police-department"",""syracuse-residents"",""syracuse-police-department"",""san-francisco-residents"",""san-francisco-police-department"",""san-antonio-residents"",""san-antonio-police-department"",""new-york-city-residents"",""new-york-city-police-department"",""fall-river-residents"",""fall-river-police-department"",""chicago-residents"",""chicago-police-department""]","ShotSpotter algorithmic systems locating gunshots were reported by police departments for containing high false positive rates and wasting police resources, prompting discontinuation.",Police Departments Reported ShotSpotter as Unreliable and Wasteful,112.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,shotspotter algorithmic system locate gunshot report police department contain false positive rate waste police resource prompt discontinuation
106,ObjectId(625763e6343edc875fe63a61),100,2021-03-17,[1403],"[""french-welfare-offices""]","[""unknown""]","[""lucie-inland""]",A French welfare office using software to automatically evaluate cases incorrectly notified a woman receiving benefits that she owed €542.,How French welfare services are creating ‘robo-debt’,100.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,french welfare office use software automatically evaluate case incorrectly notify woman receive benefit owe
107,ObjectId(625763e8343edc875fe63a71),116,2021-09-20,"[1441,1803]","[""amazon""]","[""netradyne""]","[""amazon-delivery-drivers"",""amazon-workers""]","Amazon's automated performance evaluation system involving AI-powered cameras incorrectly punished delivery drivers for non-existent mistakes, impacting their chances for bonuses and rewards.",Amazon's AI Cameras Incorrectly Penalized Delivery Drivers for Mistakes They Did Not Make,116.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,amazon automate performance evaluation involve aipowered camera incorrectly punish delivery driver nonexistent mistake impact chance bonus reward
108,ObjectId(625763e8343edc875fe63a75),120,2020-09-01,[1445],"[""unknown""]","[""murat-ayfer"",""openai""]","[""reddit-users""]","Philosopher AI, a GPT-3-powered controversial text generator, was allegedly used by an anonymous actor on AskReddit subreddit, whose posts featured a mixture of harmless stories, conspiracy theories, and sensitive topic discussions.",Philosophy AI Allegedly Used To Generate Mixture of Innocent and Harmful Reddit Posts,120.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,philosopher gptpowered controversial text generator use anonymous actor askreddit subreddit whose post feature mixture harmless story conspiracy theory sensitive topic discussion
109,ObjectId(625763e7343edc875fe63a6b),110,2016-01-01,"[1413,2651]","[""arkansas-department-of-human-services""]","[""interrai""]","[""arkansas-medicaid-waiver-program-beneficiaries"",""arkansas-healthcare-workers""]","Beneficiaries of the Arkansas Department of Human Services (DHS)'s Medicaid waiver program were allocated excessively fewer hours of caretaker visit via an algorithm deployed to boost efficiency, which reportedly contained errors and whose outputs varied wildly despite small input changes.",Arkansas's Opaque Algorithm to Allocate Health Care Excessively Cut Down Hours for Beneficiaries,110.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,beneficiary arkansas department human service dhss medicaid waiver program allocate excessively few hour caretaker visit via deployed boost efficiency contain error whose output varied wildly despite input change
110,ObjectId(625763e7343edc875fe63a69),108,2021-07-10,"[1411,1503,1537]","[""riverside-arena-skating-rink""]","[""unknown""]","[""lamya-robinson"",""black-livonia-residents""]","A Black teenager living in Livonia, Michigan was incorrectly stopped from entering a roller skating rink after its facial-recognition cameras misidentified her as another person who had been previously banned for starting a skirmish with other skaters.",Skating Rink’s Facial Recognition Cameras Misidentified Black Teenager as Banned Troublemaker,108.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,black teenager living livonia michigan incorrectly stop enter roller skate rink facialrecognition camera misidentified another person previously ban start skirmish skater
111,ObjectId(625763e8343edc875fe63a6f),114,2018-07-26,[1439],"[""amazon""]","[""amazon""]","[""rekognition-users"",""arrested-people""]","Rekognition's face comparison feature was shown by the ACLU to have misidentified members of congress, and particularly members of colors, as other people who have been arrested using a mugshot database built on publicly available arrest photos.",Amazon's Rekognition Falsely Matched Members of Congress to Mugshots,114.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,rekognitions face comparison feature show aclu misidentified member congress particularly member color people arrest use mugshot database built publicly available arrest photo
112,ObjectId(625763e7343edc875fe63a68),107,2018-07-20,"[1410,1928]","[""none""]","[""huawei"",""megvii"",""sensetime"",""alibaba"",""baibu""]","[""uyghur-people""]","Various Chinese firms were revealed by patent applications to have developed facial recognition capable of detecting people by race, which critics feared would enable persecution and discrimination of Uyghur Muslims.","Chinese Tech Firms Allegedly Developed Facial Recognition to Identify People by Race, Targeting Uyghur Muslims",107.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,various chinese firm reveal patent application developed facial recognition capable detect people race critic fear enable persecution discrimination uyghur muslim
113,ObjectId(625763e8343edc875fe63a74),119,2021-08-03,"[1444,1800,1801,1802]","[""xsolla""]","[""unknown""]","[""xsolla-employees""]","Xsolla CEO fired more than a hundred employees from his company in Perm, Russia, based on big data analysis of their remote digitized-work activity, which critics said was violating employee's privacy, outdated, and extremely ineffective.",Xsolla Employees Fired by CEO Allegedly via Big Data Analytics of Work Activities,119.0,5. Human-Computer Interaction,5.2. Loss of human agency and autonomy,xsolla ceo fire hundred employee company perm russia base big analysis remote digitizedwork activity critic violate employee privacy outdated extremely ineffective
114,ObjectId(625763e6343edc875fe63a60),99,2012-01-01,[1402],"[""university-of-massachusetts-amherst"",""university-of-wisconsin-milwaukee"",""university-of-houston"",""texas-aandm-university"",""georgia-state-university"",""more-than-500-colleges""]","[""eab""]","[""black-college-students"",""latinx-college-students"",""indigenous-students""]",Several major universities are using a tool that uses race as one factor to predict student success.,Major Universities Are Using Race as a “High Impact Predictor” of Student Success,99.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,several major university use us race factor predict student success
115,ObjectId(625763e8343edc875fe63a76),121,2020-03-27,"[2106,2105,2104,1447]","[""tripoli-based-government""]","[""stm""]","[""libyan-soldiers""]","In Libya, a Turkish-made Kargu-2 aerial drone powered by a computer vision model was allegedly used remotely by forces backed by the Tripoli-based government to track down and attack enemies as they were running from rocket attacks.",Autonomous Kargu-2 Drone Allegedly Remotely Used to Hunt down Libyan Soldiers,121.0,4. Malicious Actors & Misuse,"4.2. Cyberattacks, weapon development or use, and mass harm",libya turkishmade kargu aerial drone power computer vision use remotely force back tripolibased government track attack enemy run rocket attack
116,ObjectId(625763e8343edc875fe63a6e),113,2020-06-27,[1438],"[""facebook""]","[""facebook""]","[""black-people"",""facebook-users""]","Facebook's AI mislabeled video featuring Black men as a video about ""primates,"" resulting in an offensive prompt message for users who watched the video.","Facebook's AI Put ""Primates"" Label on Video Featuring Black Men",113.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,facebooks mislabeled video feature black men video primate result offensive prompt message user watch video
117,ObjectId(625763e9343edc875fe63a77),122,2015-06-14,[1448],"[""facebook""]","[""facebook""]","[""facebook-users""]","Facebook’s initial version of the its Tag Suggestions feature where users were offered suggestions about the identity of people's faces in photos allegedly stored biometric data without consent, violating the Illinois Biometric Information Privacy Act.","Facebook’s ""Tag Suggestions"" Allegedly Stored Biometric Data without User Consent",122.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",facebooks initial version tag suggestion feature user offer suggestion identity people face photo store biometric consent violate illinois biometric information privacy act
118,ObjectId(625763e7343edc875fe63a63),102,2020-03-23,"[1405,1523]","[""microsoft"",""ibm"",""google"",""apple"",""amazon""]","[""microsoft"",""ibm"",""google"",""apple"",""amazon""]","[""black-people""]","A study found that voice recognition tools from Apple, Amazon, Google, IBM, and Microsoft disproportionately made errors when transcribing black speakers.","Personal voice assistants struggle with black voices, new study shows",102.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,study found voice recognition tool apple amazon google ibm microsoft disproportionately make error transcribe black speaker
119,ObjectId(625763e8343edc875fe63a73),118,2020-08-06,"[1443,2009,2010]","[""openai""]","[""openai""]","[""muslims""]","Users and researchers revealed generative AI GPT-3 associating Muslims to violence in prompts, resulting in disturbingly racist and explicit outputs such as casting Muslim actor as a terrorist.",OpenAI's GPT-3 Associated Muslims with Violence,118.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,user researcher reveal generative gpt associate muslim violence prompt result disturbingly racist explicit output cast muslim actor terrorist
120,ObjectId(625763ea343edc875fe63a89),140,2020-06-01,[1478],"[""university-of-toronto""]","[""proctoru""]","[""university-of-toronto-bipoc-students""]","An exam monitoring service used by the University of Toronto was alleged by its students to have provided discriminatory check-in experiences via its facial recognition's failure to verify passport photo, disproportionately enhancing disadvantaging stress level for BIPOC students.",ProctorU’s Identity Verification and Exam Monitoring Systems Provided Allegedly Discriminatory Experiences for BIPOC Students,140.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,exam monitoring service use university toronto student provide discriminatory checkin experience via facial recognition failure verify passport photo disproportionately enhance disadvantage stress level bipoc student
121,ObjectId(625763ea343edc875fe63a86),137,2021-01-11,[1474],"[""israeli-tax-authority""]","[""israeli-tax-authority""]","[""moshe-har-shemesh"",""israeli-people-having-tax-fines""]","An Israeli farmer was imposed a computer generated fine by the tax authority, who allegedly were not able to explain its calculation, and refused to disclose the program and its source code.","Israeli Tax Authority Employed Opaque Algorithm to Impose Fines, Reportedly Refusing to Provide an Explanation for Amount Calculation to a Farmer",137.0,"7. AI system safety, failures, and limitations",7.4. Lack of transparency or interpretability,israeli farmer impose computer generate fine tax authority explain calculation refuse disclose program source code
122,ObjectId(625763eb343edc875fe63a91),148,2021-11-21,[1499],"[""accessibe"",""accessus.ai"",""allyable"",""userway"",""maxaccess.io""]","[""accessibe"",""accessus.ai"",""allyable"",""userway"",""maxaccess.io""]","[""internet-users-with-disabilities"",""web-accessibility-vendors'-customers""]","AI-powered web accessibility vendors allegedly overstated to customers about their products' utility for people with disabilities, falsely claiming to deliver automated compliance solutions.",Web Accessibility Vendors Allegedly Falsely Claimed to Provide Compliance Using AI,148.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,aipowered web accessibility vendor overstate customer product utility people disability falsely claim deliver automate compliance solution
123,ObjectId(625763ed343edc875fe63aa1),164,2018-10-01,[1534],"[""facebook""]","[""facebook""]","[""facebook-users"",""facebook-content-creators""]","After the “News Feed” algorithm had been overhauled to boost engagement between friends and family in early 2018, its heavy weighting of re-shared content was alleged found by company researchers to have pushed content creators to reorient their posts towards outrage and sensationalism, causing a proliferation of misinformation, toxicity, and violent content.","Facebook ""News Feed"" Allegedly Boosted Misinformation and Violating Content Following Use of MSI Metric",164.0,3. Misinformation,3.2. Pollution of information ecosystem and loss of consensus reality,news feed overhaul boost engagement friend family early heavy weight reshared found company researcher push creator reorient post towards outrage sensationalism cause proliferation misinformation toxicity violent
124,ObjectId(625763e9343edc875fe63a80),131,2020-12-04,"[1465,1771]","[""california-bar's-committee-of-bar-examiners""]","[""examsoft""]","[""california-bar-exam-takers"",""flagged-california-bar-exam-takers""]","The proctoring algorithm used in a California bar exam cited a third of thousands of applicants as cheaters, resulting in allegations where exam takers were instructed to prove otherwise without seeing their incriminating video evidence.",Proctoring Algorithm in Online California Bar Exam Flagged an Unusually High Number of Alleged Cheaters,131.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,proctor use california bar exam cite third thousand applicant cheater result allegation exam taker instruct prove otherwise see incriminate video evidence
125,ObjectId(625763ec343edc875fe63a96),153,2019-12-29,"[1511,1729,1763,2514]","[""tesla""]","[""tesla""]","[""gilberto-alcazar-lopez"",""maria-guadalupe-nieves-lopez""]","In 2019, a Tesla Model S driver on Autopilot mode reportedly went through a red light and crashed into a Honda Civic, killing two people in Gardena, Los Angeles.","Tesla Driver on Autopilot Ran a Red Light, Crashing into a Car and Killing Two People in Los Angeles",153.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla driver autopilot mode go red light crashed honda civic kill two people gardena los angeles
126,ObjectId(625763e9343edc875fe63a7a),125,2020-09-29,"[1451,1452,1460]","[""amazon""]","[""amazon""]","[""amazon-fulfillment-center-workers""]",Amazon’s robotic fulfillment centers have higher serious injury rates.,Amazon’s Robotic Fulfillment Centers Have Higher Serious Injury Rates,125.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,amazon robotic fulfillment center high serious injury rate
127,ObjectId(625763ea343edc875fe63a87),138,2020-01-21,"[1475,1505,1555,1556,2442,2434]","[""university-of-illinois""]","[""proctorio""]","[""university-of-illinois-students-of-color"",""university-of-illinois-students""]","Proctorio's remote-testing software were reported by students at the University of Illinois Urbana-Champaign for issues regarding privacy, accessibility, differential performance on darker-skinned students.",Alleged Issues with Proctorio's Remote-Testing AI Prompted Suspension by University,138.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,proctorios remotetesting software report student university illinois urbanachampaign issue regard privacy accessibility differential performance darkerskinned student
128,ObjectId(625763ea343edc875fe63a81),132,2020-12-27,[1466],"[""tiktok""]","[""tiktok""]","[""tiktok-users"",""tiktok-users-under-18-years-old""]","Videos promoting eating disorders evaded TikTok's automated violation detection system without difficulty via common misspellings of search terms, bypassing its ban of violating hashtags such as ""proana"" and ""anorexia"".",TikTok’s Content Moderation Allegedly Failed to Adequately Take down Videos Promoting Eating Disorders,132.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,video promote eat disorder evade tiktoks automate violation detection difficulty via common misspelling search term bypassing ban violate hashtags proana anorexia
129,ObjectId(625763e8343edc875fe63a72),117,2020-02-24,"[1442,2019,2020,2021]","[""tiktok""]","[""tiktok""]","[""tiktok-users"",""tiktok-content-creators""]","TikTok's ""Suggested Accounts"" recommendations allegedly reinforced racial bias despite not basing recommendations on race or creators' profile photo.","TikTok's ""Suggested Accounts"" Algorithm Allegedly Reinforced Racial Bias through Feedback Loops",117.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,tiktoks suggest account recommendation reinforce racial bias despite base recommendation race creator profile photo
130,ObjectId(625763e9343edc875fe63a7e),129,2021-03-01,[1462],"[""facebook""]","[""facebook""]","[""facebook-users""]","Facebook's automated moderation tools were shown by internal documents performing incomparably to human moderators, and accounting for only a small fraction of hate speech, violence, and incitement content removal.","Facebook's Automated Tools Failed to Adequately Remove Hate Speech, Violence, and Incitement",129.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebooks automate moderation tool show internal document perform incomparably human moderator accounting fraction hate speech violence incitement removal
131,ObjectId(625763eb343edc875fe63a8f),146,2021-10-22,"[1494,1495,1502]","[""allen-institute-for-ai""]","[""allen-institute-for-ai""]","[""minority-groups""]","A publicly accessible research model that was trained via Reddit threads showed racially biased advice on moral dilemmas, allegedly demonstrating limitations of language-based models trained on moral judgments.","Research Prototype AI, Delphi, Reportedly Gave Racially Biased Answers on Ethics",146.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,publicly accessible research train via reddit thread show racially bias advice moral dilemma demonstrate limitation languagebased model train moral judgment
132,ObjectId(625763eb343edc875fe63a8d),144,2020-06-28,"[1483,1979,1980,2042,2043,2134]","[""youtube""]","[""youtube""]","[""antonio-radic"",""youtube-chess-content-creators"",""youtube-users""]","YouTube's AI-powered hate speech detection system falsely flagged chess content and banned chess creators allegedly due to its misinterpretation of strategy language such as ""black,"" ""white,"" and ""attack"" as harmful and dangerous.",YouTube's AI Mistakenly Banned Chess Channel over Chess Language Misinterpretation,144.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,youtubes aipowered hate speech detection falsely flag chess ban chess creator due misinterpretation strategy language black white attack harmful dangerous
133,ObjectId(625763ec343edc875fe63a9d),160,2021-12-26,"[1520,1521,2381]","[""amazon""]","[""amazon""]","[""kristin-livdahl's-daughter"",""amazon-echo-customers"",""children-using-alexa""]","Amazon’s voice assistant Alexa suggested “the penny challenge,” which involves dangerously touching a coin to the prongs of a half-exposed plug, when a ten-year-old girl asked for a challenge to do.",Alexa Recommended Dangerous TikTok Challenge to Ten-Year-Old Girl,160.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,amazon voice assistant alexa suggest penny challenge involves dangerously touch coin prong halfexposed plug tenyearold girl ask challenge
134,ObjectId(625763ec343edc875fe63a95),152,2021-07-13,"[1509,1510]","[""softbank""]","[""aldebaran"",""softbank-robotics""]","[""softbank""]","SoftBank's robot allegedly kept making mechanical errors, taking unplanned breaks, failing to recognize previously-met people, and breaking down during practice runs.","SoftBank's Humanoid Robot, Pepper, Reportedly Frequently Made Errors, Prompting Dismissal",152.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,softbanks robot kept make mechanical error take unplanned break fail recognize previouslymet people break practice run
135,ObjectId(625763ed343edc875fe63a9e),161,2019-04-03,"[1530,2138,2139]","[""facebook""]","[""facebook""]","[""female-facebook-users"",""black-facebook-users"",""male-facebook-users""]",Facebook's housing and employment ad delivery process allegedly resulted in skews in exposure for some users along demographic lines such as gender and racial identity.,Facebook's Ad Delivery Reportedly Excluded Audience along Racial and Gender Lines,161.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,facebooks housing employment ad delivery result skews exposure user along demographic line gender racial identity
136,ObjectId(625763ed343edc875fe63aa5),168,2022-03-01,"[1540,1541]","[""facebook"",""linkedin"",""youtube"",""twitter"",""netflix""]","[""facebook"",""linkedin"",""youtube"",""twitter"",""netflix""]","[""facebook-users"",""linkedin-users"",""youtube-users"",""twitter-users"",""netflix-users""]","Collaborative filtering prone to popularity bias, resulting in overrepresentation of popular items in the recommendation outputs.","Collaborative Filtering Prone to Popularity Bias, Resulting in Overrepresentation of Popular Items in the Recommendation Outputs",168.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,collaborative filter prone popularity bias result overrepresentation popular item recommendation output
137,ObjectId(625763ea343edc875fe63a82),133,2020-12-15,[1468],"[""tiktok""]","[""tiktok""]","[""tiktok-content-creators-of-marginalized-groups""]",TikTok's automated content reporting system was allegedly abused by online trolls to intentionally misreport content created by users of marginalized groups.,Online Trolls Allegedly Abused TikTok’s Automated Content Reporting System to Discriminate against Marginalized Creators,133.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,tiktoks automate reporting abuse online troll intentionally misreport create user marginalize group
138,ObjectId(625763eb343edc875fe63a8e),145,2021-07-23,"[1485,1504,1529]","[""tesla""]","[""tesla""]","[""tesla-drivers""]","Tesla's Autopilot was shown on video by its owner mistaking the moon for a yellow stop light, allegedly causing the vehicle to keep slowing down.",Tesla's Autopilot Misidentified the Moon as Yellow Stop Light,145.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla autopilot show video owner mistake moon yellow stop light cause vehicle keep slow
139,ObjectId(625763ea343edc875fe63a8a),141,2021-02-05,"[1479,1480]","[""instagram""]","[""instagram""]","[""sennett-devermont"",""beverly-hills-citizens""]","A police officer in Beverly Hills played copyrighted music on his phone when realizing that his interactions were being recorded on a livestream, allegedly hoping the Instagram's automated copyright detection system to end or mute the stream.",California Police Turned on Music to Allegedly Trigger Instagram’s DCMA to Avoid Being Live-Streamed,141.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,police officer beverly hill played copyright music phone realize interaction record livestream hop instagrams automate copyright detection end mute stream
140,ObjectId(625763ea343edc875fe63a83),134,2020-12-25,"[1469,1951]","[""fuzhou-zhongfang-marlboro-mall""]","[""unknown""]","[""fuzhou-zhongfang-marlboro-mall-goers""]","A shopping guide robot deployed by the Fuzhou Zhongfang Marlboro Mall was shown on video allegedly walking to the escalator by itself, falling down, and knocking over passengers, which prompted its suspension.","Robot in Chinese Shopping Mall Fell off the Escalator, Knocking down Passengers",134.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,shopping guide robot deployed fuzhou zhongfang marlboro mall show video walk escalator fall knock passenger prompt suspension
141,ObjectId(625763ea343edc875fe63a85),136,2020-12-06,[1471],"[""brand-safety-tech-firms""]","[""none""]","[""news-sites""]","Brand safety tech firms falsely claimed use of AI, blocking ads using simple keyword lists.","Brand Safety Tech Firms Falsely Claimed Use of AI, Blocking Ads Using Simple Keyword Lists",136.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,brand safety tech firm falsely claimed block ad use simple keyword list
142,ObjectId(625763ea343edc875fe63a84),135,2012-12-01,"[1470,1871]","[""university-of-texas-at-austin's-department-of-computer-science""]","[""university-of-texas-at-austin-researchers""]","[""university-of-texas-at-austin-phd-applicants-of-marginalized-groups""]","The University of Texas at Austin's Department of Computer Science's assistive algorithm to assess PhD applicants ""GRADE"" raised concerns among faculty about worsening historical inequalities for marginalized candidates, prompting its suspension.",UT Austin GRADE Algorithm Allegedly Reinforced Historical Inequalities,135.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,university texas austin department computer science assistive assess phd applicant grade raise concern among faculty worsen historical inequality marginalize candidate prompt suspension
143,ObjectId(625763ec343edc875fe63a98),155,2021-12-27,"[1513,1514]","[""google-maps""]","[""google-maps""]","[""google-maps-users-traveling-in-sierra-nevada"",""google-maps-users-traveling-in-the-mountains""]",Lake Tahoe travelers were allegedly guided by Google Maps into hazardous shortcuts in the mountains during a snowstorm.,Google Maps Allegedly Directed Sierra Nevada Travelers to Dangerous Roads amid Winter Storm,155.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,lake tahoe traveler guide google map hazardous shortcut mountain snowstorm
144,ObjectId(625763ee343edc875fe63aa8),171,2021-10-18,[1549],"[""bath-government""]","[""unknown""]","[""paula-knight"",""bath-officials"",""uk-public""]",A Bath resident was wrongly fined by the local officials because an automated license plate recognition camera misread the text on her shirt as a license plate number.,"Traffic Camera Misread Text on Pedestrian's Shirt as License Plate, Causing UK Officials to Issue Fine to an Unrelated Person",171.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,bath resident wrongly fin local official automate license plate recognition camera misread text shirt license plate number
145,ObjectId(625763ec343edc875fe63a94),151,2021-10-28,"[1507,1508,1703,1704,1705,1706,1707,1708,1709,1710]","[""pony.ai""]","[""pony.ai""]","[""san-francisco-city-government""]","A Pony.ai vehicle operating in autonomous mode crashed into a center divider and a traffic sign in San Francisco, prompting a regulator to suspend the driverless testing permit for the startup.",California Regulator Suspended Pony.ai's Driverless Testing Permit Following a Non-Fatal Collision,151.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,ponyai vehicle operating autonomous mode crashed center divider traffic sign san francisco prompt regulator suspend driverless test permit startup
146,ObjectId(625763e9343edc875fe63a78),123,2021-08-01,"[1449,2651,2705,3013,3012]","[""university-of-michigan-hospital""]","[""epic-systems""]","[""sepsis-patients""]","Epic System's sepsis prediction algorithms was shown by investigators at the University of Michigan Hospital to have high rates of false positives and false negatives, allegedly delivering inaccurate and irrelevant information on patients, contrasting sharply with their published claims.",Epic Systems’s Sepsis Prediction Algorithms Revealed to Have High Error Rates on Seriously Ill Patients,123.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,epic system sepsis prediction algorithm show investigator university michigan hospital rate false positive false negative deliver inaccurate irrelevant information patient contrast sharply publish claim
147,ObjectId(625763ec343edc875fe63a99),156,2022-02-04,"[1515,2197]","[""amazon""]","[""amazon""]","[""people-attempting-suicides""]","Despite complaints notifying Amazon about the sale of various products that had been used to aid suicide attempts, its recommendation system reportedly continued selling them and suggesting their frequently bought-together items.",Amazon Reportedly Sold Products and Recommended Frequently Bought Together Items That Aid Suicide Attempts,156.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,despite complaint notify amazon sale various product use aid suicide attempt recommendation continued sell suggest frequently boughttogether item
148,ObjectId(625763eb343edc875fe63a8c),143,2021-02-16,[1482],"[""facebook"",""twitter""]","[""facebook"",""twitter""]","[""facebook-users-of-small-language-groups"",""twitter-users-of-small-language-groups""]","Facebook's and Twitter were not able to sufficiently moderate content of small language groups such as the Balkan languages using AI, allegedly due to the lack of investment in human moderation and difficulty in AI-solution design for the languages.",Facebook’s and Twitter's Automated Content Moderation Reportedly Failed to Effectively Enforce Violation Rules for Small Language Groups,143.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,facebooks twitter sufficiently moderate language group balkan language use due lack investment human moderation difficulty aisolution design language
149,ObjectId(625763ec343edc875fe63a9a),157,2021-03-15,[1516],"[""amazon""]","[""amazon""]","[""amazon-workers"",""amazon-delivery-drivers""]","A lawsuit cited Amazon as liable in a crash involving its delivery driver, alleging that Amazon’s AI-powered driver monitoring system pushed drivers to prioritize speed over safety.","Amazon's Monitoring System Allegedly Pushed Delivery Drivers to Prioritize Speed over Safety, Leading to Crash",157.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,lawsuit cite amazon liable crash involve delivery driver allege amazon aipowered driver monitoring push driver prioritize speed safety
150,ObjectId(625763ee343edc875fe63aa7),170,2003-06-01,"[1546,1547,1548]","[""target""]","[""target""]","[""target-customers""]","Target recommended maternity-related items to a family in Atlanta via ads, allegedly predicting their teenage daughter’s pregnancy before her father did, although critics have called into question the predictability of the algorithm and the authenticity of its claims.","Target Suggested Maternity-Related Advertisements to a Teenage Girl's Home, Allegedly Correctly Predicting Her Pregnancy via Algorithm",170.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",target recommend maternityrelated item family atlanta via ad predict teenage daughter pregnancy father although critic call question predictability authenticity claim
151,ObjectId(625763ea343edc875fe63a88),139,2021-01-21,"[1476,1477]","[""amazon""]","[""amazon""]","[""amazon-customers""]","Evidence of the ""filter-bubble effect"" were found by vaccine-misinformation researchers in Amazon's recommendations, where its algorithms presented users who performed actions on misinformative products with more misinfomative products.",Amazon’s Search and Recommendation Algorithms Found by Auditors to Have Boosted Products That Contained Vaccine Misinformation,139.0,3. Misinformation,3.2. Pollution of information ecosystem and loss of consensus reality,evidence filterbubble effect found vaccinemisinformation researcher amazon recommendation algorithm present user perform action misinformative product misinfomative product
152,ObjectId(625763eb343edc875fe63a8b),142,2021-02-11,[1481],"[""facebook"",""instagram""]","[""facebook"",""instagram""]","[""facebook-users-of-disabilities"",""adaptive-fashion-retailers""]","Facebook platforms' automated ad moderation system falsely classified adaptive fashion products as medical and health care products and services, resulting in regular bans and appeals faced by their retailers.",Facebook’s Advertisement Moderation System Routinely Misidentified Adaptive Fashion Products as Medical Equipment and Blocked Their Sellers,142.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,facebook platform automate ad moderation falsely classify adaptive fashion product medical health care product service result regular ban appeal face retailer
153,ObjectId(625763eb343edc875fe63a90),147,2020-01-15,"[1496,1497,5135,5136,5137,5138]","[""unknown-transnational-fraud-ring"",""unknown-scammers"",""unknown-fraudsters"",""unknown-cybercriminals""]","[""unknown-voice-cloning-technology-developer"",""unknown-deepfake-technology-developer""]","[""unnamed-japanese-firm"",""unnamed-hong-kong-based-branch-manager-of-unnamed-japanese-firm"",""general-public-of-the-united-arab-emirates"",""centennial-bank""]","In January 2020, a Hong Kong-based bank manager for a Japanese company reportedly authorized $35 million in transfers after receiving a call from someone whose voice matched the company director's. According to Emirati investigators, scammers used AI-based voice cloning to impersonate the executive. The fraud allegedly involved at least 17 individuals and reportedly led to global fund transfers that triggered a UAE investigation. U.S. authorities were reportedly later asked to help trace part of the funds sent to U.S. banks.",Reported AI-Cloned Voice Used to Deceive Hong Kong Bank Manager in Purported $35 Million Fraud Scheme,147.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",january hong kongbased bank manager japanese company authorize million transfer receive call someone whose voice match company director accord emirati investigator scammer use aibased voice clone impersonate executive fraud involve least individual lead global fund transfer trigger uae investigation yous authority later ask help trace part fund sent yous bank
154,ObjectId(625763ec343edc875fe63a97),154,2022-01-26,[1512],"[""us-department-of-justice""]","[""us-department-of-justice""]","[""inmates-of-color""]","Department of Justice’s inmate-recidivism risk assessment tool was reported to have produced racially uneven results, misclassifying risk levels for inmates of color.",Justice Department’s Recidivism Risk Algorithm PATTERN Allegedly Caused Persistent Disparities Along Racial Lines,154.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,department justice inmaterecidivism risk assessment report produce racially uneven result misclassifying risk level inmate color
155,ObjectId(625763ed343edc875fe63aa2),165,2020-06-20,"[1536,2781]","[""duke-researchers""]","[""duke-researchers""]","[""people-having-non-caucasian-facial-features""]","Image upscaling tool PULSE powered by NVIDIA's StyleGAN reportedly generated faces with Caucasian features more often, although AI academics, engineers, and researchers were not in agreement about where the source of bias was.",Image Upscaling Algorithm PULSE Allegedly Produced Facial Images with Caucasian Features More Often,165.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,image upscaling pulse power nvidias stylegan generate face caucasian feature often although academic engineer researcher agreement source bias
156,ObjectId(625763eb343edc875fe63a92),149,2021-11-02,"[1500,1501,1890,2925]","[""zillow""]","[""zillow-offers""]","[""zillow-offers-staff"",""zillow""]","Zillow's AI-powered predictive pricing tool Zestimate was allegedly not able to accurately forecast housing prices three to six months in advance due to rapid market changes, prompting division shutdown and layoff of a few thousand employees.",Zillow Shut Down Zillow Offers Division Allegedly Due to Predictive Pricing Tool's Insufficient Accuracy,149.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,zillows aipowered predictive pricing zestimate accurately forecast housing price three six month advance due rapid market change prompt division shutdown layoff thousand employee
157,ObjectId(625763e9343edc875fe63a79),124,2019-10-24,"[1450,1522,2262,2652,2651,2704,2856]","[""unnamed-large-academic-hospital""]","[""optum""]","[""black-patients""]","Optum's algorithm deployed by a large academic hospital was revealed by researchers to have under-predicted the health needs of black patients, effectively de-prioritizing them in extra care programs relative to white patients with the same health burden.",Algorithmic Health Risk Scores Underestimated Black Patients’ Needs,124.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,optums deployed academic hospital reveal researcher underpredicted health need black patient effectively deprioritizing extra care program relative white patient health burden
158,ObjectId(625763ec343edc875fe63a9c),159,2019-03-29,[2471],"[""tesla""]","[""tesla""]","[""tesla-drivers""]","Tencent Keen Security Lab conducted security research into Tesla’s Autopilot system and identified crafted adversarial samples and remote controlling via wireless gamepad as vulnerabilities to its system, although the company called into question their real-world practicality. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",Tesla Autopilot’s Lane Recognition Allegedly Vulnerable to Adversarial Attacks,159.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tencent keen security lab conduct security research tesla autopilot identify craft adversarial sample remote control via wireless gamepad vulnerability although company call question realworld practicality incident downgrade meet current ingestion criterion
159,ObjectId(625763ed343edc875fe63aa4),167,2017-09-07,[1539],"[""michal-kosinski"",""yilun-wang""]","[""michal-kosinski"",""yilun-wang""]","[""lgbtq-people"",""lgbtq-people-of-color"",""non-american-lgbtq-people""]","Researchers at Stanford Graduate School of Business developed a model that determined, on a binary scale, whether someone was homosexual using only his facial image, which advocacy groups such as GLAAD and the Human Rights Campaign denounced as flawed science and threatening to LGBTQ folks.",Researchers' Homosexual-Men Detection Model Denounced as a Threat to LGBTQ People’s Safety and Privacy,167.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",researcher stanford graduate school business developed determine binary scale whether someone homosexual use facial image advocacy group glaad human right campaign denounce flaw science threaten lgbtq folk
160,ObjectId(625763e9343edc875fe63a7c),127,2020-06-06,"[1456,1457,1458,1461,1486,1487,1488,1489,1490,1491,1492,1493]","[""microsoft"",""msn.com""]","[""microsoft""]","[""jade-thirlwall"",""leigh-anne-pinnock""]","A news story published on MSN.com featured a photo of the wrong mixed-race person that was allegedly selected by an algorithm, following Microsoft’s layoff and replacement of journalists and editorial workers at its organizations with AI systems.",Microsoft’s Algorithm Allegedly Selected Photo of the Wrong Mixed-Race Person Featured in a News Story,127.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,news story publish msncom feature photo wrong mixedrace person select follow microsofts layoff replacement journalist editorial worker organization system
161,ObjectId(625763ed343edc875fe63aa0),163,2021-11-21,"[1533,1652]","[""facebook""]","[""facebook""]","[""facebook-users-of-minority-groups"",""facebook-users""]","Facebook’s hate-speech detection algorithms was found by company researchers to have under-reported less common but more harmful content that was more often experienced by minority groups such as Black, Muslim, LGBTQ, and Jewish users.",Facebook’s Hate Speech Detection Algorithms Allegedly Disproportionately Failed to Remove Racist Content towards Minority Groups,163.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,facebooks hatespeech detection algorithm found company researcher underreported less common harmful often experienced minority group black muslim lgbtq jewish user
162,ObjectId(625763ed343edc875fe63a9f),162,2014-01-01,[1531],"[""ets""]","[""ets""]","[""uk-ets-past-test-takers"",""uk-ets-test-takers"",""uk-home-office""]"," International testing organization ETS admits voice recognition as evidence of cheating for thousands of previous TOEIC test-takers that reportedly included wrongfully accused people, causing them to be deported without an appeal process or seeing their incriminating evidence.","ETS Used Allegedly Flawed Voice Recognition Evidence to Accuse and Assess Scale of Cheating, Causing Thousands to be Deported from the UK",162.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,international test organization ets admits voice recognition evidence cheat thousand previous toeic testtakers include wrongfully accuse people cause deport appeal see incriminate evidence
163,ObjectId(625763eb343edc875fe63a93),150,2018-07-21,"[1506,3157,3158]","[""natural-cycles""]","[""natural-cycles""]","[""natural-cycles-users"",""women""]","Some women using the contraceptive app, Natural Cycles, reported unwanted pregnancies, revealing its algorithm's difficulties in mapping menstrual cycles.","Swedish Contraceptive App, Natural Cycles, Allegedly Failed to Correctly Map Menstrual Cycle",150.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,woman use contraceptive app natural cycle report unwanted pregnancy reveal algorithm difficulty mapping menstrual cycle
164,ObjectId(625763ed343edc875fe63aa6),169,2018-08-15,"[1544,1545,2986,2987,2988]","[""facebook"",""meta""]","[""facebook"",""meta""]","[""rohingya-people"",""rohingya-facebook-users"",""myanmar-public"",""facebook-users-in-myanmar"",""burmese-speaking-facebook-users""]"," Facebook allegedly did not adequately remove anti-Rohingya hate speech, some of which was extremely violent and dehumanizing, on its platform, contributing to the violence faced by Rohingya communities in Myanmar.",Facebook Allegedly Failed to Police Anti-Rohingya Hate Speech Content That Contributed to Violence in Myanmar,169.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,facebook adequately remove antirohingya hate speech extremely violent dehumanize platform contribute violence face rohingya community myanmar
165,ObjectId(625763e9343edc875fe63a7b),126,2021-07-16,"[1453,1454,1455,1532]","[""ocado""]","[""ocado""]","[""ocado""]","A collision involving three robots at an Ocado's warehouse in Erith, UK, resulting in a fire but no reports of injuries.","Three Robots Collided, Sparking Fire in a Grocer's Warehouse in UK ",126.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,collision involve three robot ocados warehouse erith uk result fire report injury
166,ObjectId(625763e9343edc875fe63a7d),128,2017-08-01,"[1459,1818]","[""tesla""]","[""tesla""]","[""eric-horvitz"",""tesla-drivers""]"," A Tesla Sedan operating on Autopilot mode was not able to center itself on the road and drove over a yellow dividing curb in Redmond, Washington, causing minor damage to the vehicle’s rear suspension.","Tesla Sedan on Autopilot Reportedly Drove Over Dividing Curb in Washington, Resulting in Minor Vehicle Damage",128.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla sedan operating autopilot mode center road drove yellow divide curb redmond washington cause minor damage vehicle rear suspension
167,ObjectId(625763ec343edc875fe63a9b),158,2021-02-01,[1517],"[""unknown""]","[""unknown""]","[""amaya-ross"",""black-students"",""black-test-takers""]","A Black student's face was not recognized by the remote-proctoring software during check-in of a lab quiz, causing her to excessively change her environments for it to work as intended.",Facial Recognition in Remote Learning Software Reportedly Failed to Recognize a Black Student’s Face,158.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,black student face recognize remoteproctoring software checkin lab quiz cause excessively change environment work intend
168,ObjectId(6259b3d5c2337187617c53c3),176,2022-03-02,[1557],"[""oregon-state-university""]","[""starship-technologies""]","[""oregon-state-university"",""freight-train-crew""]"," A Starship food delivery robot deployed by Oregon State University reportedly failed to cross the railroad, becoming stranded, and ending up being struck by an oncoming freight train.","Starship’s Autonomous Food Delivery Robot Allegedly Stranded at Railroad Crossing in Oregon, Run over by Freight Train",176.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,starship food delivery robot deployed oregon state university fail cross railroad become strand end struck oncoming freight train
169,ObjectId(62849d9dcb05238c61a5cc65),184,2018-04-12,"[1581,1584,1899]","[""companhia-do-metropolitano-de-sao-paulo""]","[""securos""]","[""sao-paulo-metro-users"",""sao-paulo-citizens""]"," A facial recognition program rolled out by São Paulo Metro Stations was suspended following a court ruling in response to a lawsuit by civil society organizations, who cited fear of it being integrated with other electronic surveillance entities without consent, and lack of transparency about the biometric data collection process of metro users.",Facial Recognition Program in São Paulo Metro Stations Suspended for Illegal and Disproportionate Violation of Citizens’ Right to Privacy,184.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",facial recognition program roll paulo metro station suspend follow court ruling response lawsuit civil society organization cite fear integrate electronic surveillance entity consent lack transparency biometric collection metro user
170,ObjectId(628ad91f7da5b905fb4444b8),195,2015-09-01,"[1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1843]","[""pasco-sheriff's-office""]","[""unknown""]","[""pasco-residents"",""pasco-black-students"",""pasco-students-with-disabilities""]","The Intelligence-Led Policing model rolled out by the Pasco County Sheriff’s Office was allegedly developed based on flawed science and biased data that also contained sensitive information and irrelevant attributes about students, which critics said to be discriminatory.",Predictive Policing Program by Florida Sheriff’s Office Allegedly Violated Residents’ Rights and Targeted Children of Vulnerable Groups,195.0,5. Human-Computer Interaction,5.2. Loss of human agency and autonomy,intelligenceled police roll pasco county sheriff office developed base flaw science bias also contain sensitive information irrelevant attribute student critic discriminatory
171,ObjectId(629dce346e8239f700dfecbf),213,2020-07-01,"[1715,1716,1717,1718,1719]","[""facebook""]","[""facebook""]","[""facebook-users""]","The performance of Facebook’s political ad detection was revealed by researchers to be imprecise, uneven across countries in errors, and inadequate for preventing systematic violations of political advertising policies.",Facebook’s Political Ad Detection Reportedly Showed High and Geographically Uneven Error Rates,213.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,performance facebooks political ad detection reveal researcher imprecise uneven across country error inadequate prevent systematic violation political advertising policy
172,ObjectId(625763ee343edc875fe63aab),174,2022-02-28,"[1552,1585,1595,1599]","[""unknown""]","[""unknown""]","[""linkedin-users""]","More than a thousand inauthentic LinkedIn profiles using allegedly GAN-generated photos were notified by researchers at Stanford to LinkedIn’s staff, and many of which were removed for violating rules against creating fake profiles and falsifying information.",Fake LinkedIn Profiles Created Using GAN Photos,174.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",thousand inauthentic linkedin profile use gangenerated photo notify researcher stanford linkedins staff many remove violate rule create fake profile falsify information
173,ObjectId(62842764c4ac5276446aed58),180,2020-02-19,"[1564,1582,2236]","[""malaysian-judiciary"",""malaysian-courts""]","[""sarawak-information-systems""]","[""malaysian-convicted-people""]","The AI system used by the Malaysian judiciary which explicitly considered age, employment, and socio-economic data provided sentencing to a drug possession case that was alleged by lawyer to be disproportionately high for the crime committed.",Algorithm Used by the Malaysian Judiciary Reportedly Recommended Unusually High Sentencing to a Drug Possession Case,180.0,5. Human-Computer Interaction,5.2. Loss of human agency and autonomy,use malaysian judiciary explicitly consider age employment socioeconomic provide sentence drug possession case lawyer disproportionately crime commit
174,ObjectId(628ad7417da5b905fb43f208),194,2018-02-01,[1621],"[""unnamed-australian-telecommunications-company""]","[""unknown""]","[""unnamed-australian-telecommunications-company""]","In early 2018, an Australian telecommunications company’s incident management AI excessively deployed technicians into the field, and was allegedly unable to be stopped by the automation team.","Australian Telco’s Incident Management Bot Excessively Sent Technicians in the Field by Mistake, Allegedly Costing Millions",194.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,early australian telecommunication company incident management excessively deployed technician field unable stop automation team
175,ObjectId(62988029093243282c69c2b2),206,2015-03-01,"[1675,1676,1677,1678]","[""tinder""]","[""tinder""]","[""tinder-users-over-30-years-old""]","Tinder’s personalized pricing was found by Consumers International to consider age as a major determinant of pricing, and could be considered a direct discrimination based on age, according to anti-discrimination law experts.",Tinder's Personalized Pricing Algorithm Found to Offer Higher Prices for Older Users,206.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,tinder personalize pricing found consumer international consider age major determinant pricing consider direct discrimination base age accord antidiscrimination law expert
176,ObjectId(629791afc7e109ab6bc28b6f),202,2021-12-06,"[1655,1656,1657,1658,1721]","[""yoon-suk-yeol"",""yoon-suk-yeol's-campaign""]","[""unknown""]","[""korean-public""]",A South Korean political candidate created a deepfake avatar which political opponents alleged to be fraudulent and a threat to democracy.,Korean Politician Employed Deepfake as Campaign Representative,202.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,south korean political candidate create deepfake avatar political opponent fraudulent threat democracy
177,ObjectId(629f0c2548f09c92aeb5fe4d),216,2017-10-10,"[1724,1924,1925,1926,1927]","[""wechat""]","[""wechat""]","[""black-wechat-users""]",The Chinese platform WeChat provided an inappropriate and racist English translation for the Chinese term for “black foreigner” in its messaging app.,WeChat’s Machine Translation Gave a Racist English Translation for the Chinese Term for “Black Foreigner”,216.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,chinese platform wechat provide inappropriate racist english translation chinese term black foreigner message app
178,ObjectId(62842db6dee309a4a8e14d4b),181,2022-02-11,"[1571,1572]","[""cruise""]","[""cruise""]","[""cruise-vehicle""]","A BMW Sedan reportedly made an illegal left turn, causing a minor collision but no injuries with a Cruise autonomous vehicle (AV) operating in autonomous mode.","BMW Sedan Made a Prohibited Left Turn, Colliding with a Cruise Autonomous Vehicle",181.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,bmw sedan make illegal left turn cause minor collision injury cruise autonomous vehicle av operating autonomous mode
179,ObjectId(625763ed343edc875fe63aa3),166,2020-02-07,"[1538,1563]","[""giggle""]","[""kairos""]","[""trans-women"",""women-of-color""]","A social networking platform, Giggle, allegedly collected, shared to third-parties, and used sensitive information and biometric data to verify whether a person is a woman via facial recognition, which critics claimed to be discriminatory against women of color and harmful towards trans women.","Networking Platform Giggle Employs AI to Determine Users’ Gender, Allegedly Excluding Transgender Women",166.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,social networking platform giggle collect share thirdparties use sensitive information biometric verify whether person woman via facial recognition critic claimed discriminatory woman color harmful towards trans woman
180,ObjectId(62842ee176e12cf335550ab1),182,2018-06-11,"[1573,1574]","[""cruise""]","[""cruise""]","[""cruise-vehicles"",""cruise-driver-employee""]","In San Francisco, an autonomous Cruise Chevrolet Bolt collided with another Cruise vehicle driven by a Cruise human employee, causing minor scuffs to the cars but no human injuries.",Two Cruise Autonomous Vehicles Collided with Each Other in California ,182.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,san francisco autonomous cruise chevrolet bolt collide another cruise vehicle driven cruise human employee cause minor scuff car human injury
181,ObjectId(625763ee343edc875fe63aaa),173,2021-07-30,[1551],"[""unknown""]","[""unknown""]","[""doctors"",""covid-patients""]","AI tools failed to sufficiently predict COVID patients, some potentially harmful.","AI Tools Failed to Sufficiently Predict COVID Patients, Some Potentially Harmful",173.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tool fail sufficiently predict covid patient potentially harmful
182,ObjectId(6297936efc298401e1ba35c0),203,2022-02-10,"[1659,1660,1661]","[""uber""]","[""uber""]","[""uber-drivers""]","Uber launched a new but opaque algorithm to determine drivers' pay in the US which allegedly caused drivers to experience lower fares, confusing fare drops, and a decrease in rides.",Uber Launched Opaque Algorithm That Changes Drivers' Payments in the US,203.0,"7. AI system safety, failures, and limitations",7.4. Lack of transparency or interpretability,uber launch opaque determine driver pay u cause driver experience low fare confuse fare drop decrease ride
183,ObjectId(628af245a8f82bdc4c020cc2),198,2022-03-16,"[1642,1643,1644,1645,1646,3332,3333,3334,3335]","[""hackers""]","[""unknown""]","[""volodymyr-zelenskyy"",""ukrainian-social-media-users"",""ukrainian-public""]", A quickly-debunked deepfaked video of the Ukrainian President Volodymyr Zelenskyy was posted on various Ukrainian websites and social media platforms encouraging Ukrainians to surrender to Russian forces during the Russia-Ukraine war.,Deepfake Video of Ukrainian President Yielding to Russia Posted on Ukrainian Websites and Social Media,198.0,3. Misinformation,3.1. False or misleading information,quicklydebunked deepfaked video ukrainian president volodymyr zelenskyy post various ukrainian website social medium platform encourage ukrainian surrender russian force russiaukraine war
184,ObjectId(625763ee343edc875fe63aac),175,2022-04-01,"[1553,1554,1606,1607,1608]","[""cruise""]","[""cruise""]","[""san-francisco-public"",""cruise-customers""]","An autonomous Chevy Bolt operated by Cruise was pulled over in San Francisco, and as the police attempted to engage with the car, it reportedly bolted off, pulled over again, and put on its hazards lights on at a point farther down the road.",Cruise Autonomous Taxi Allegedly Bolted off from Police After Being Pulled over in San Francisco,175.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,autonomous chevy bolt operate cruise pull san francisco police attempt engage car bolt pull put hazard light point farther road
185,ObjectId(6269ca6f01cc3d7da1e059ad),178,2022-04-21,"[1560,1565,1566,1567,1568,1569,1570,1594]","[""tesla""]","[""tesla""]","[""tesla-owner"",""vision-jet-owner""]"," A Tesla Model Y was shown on video slowly crashing into a Vision Jet in Spokane, Washington, allegedly due to its owner activating the “Smart Summon” feature.","Tesla Owner Activated ""Smart Summon"" Feature, Causing a Collision with an Aircraft in a Washington Airport",178.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla show video slowly crash vision jet spokane washington due owner activate smart summon feature
186,ObjectId(628498c9ba5ecc08807ab7d9),183,2017-07-01,"[1576,1577,1578,1579,1580,2066]","[""airbnb""]","[""airbnb"",""trooly""]","[""sex-workers"",""airbnb-users""]"," Airbnb allegedly considered publicly available data on users to gauge their trustworthiness via algorithmic assessment of personality and behavioral traits, resulting in unexplained bans and discriminatory bans against sex workers.","Airbnb's Trustworthiness Algorithm Allegedly Banned Users without Explanation, and Discriminated against Sex Workers",183.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,airbnb consider publicly available user gauge trustworthiness via algorithmic assessment personality behavioral trait result unexplained ban discriminatory ban sex worker
187,ObjectId(62a18ffaae26c04e23bf1d27),220,2020-11-11,"[1731,1732,1969,2061]","[""facebook""]","[""facebook""]","[""small-businesses-on-facebook""]","Facebook’s AI mistakenly blocked advertisements by small and struggling businesses, after the company allegedly leaned more on algorithms to monitor ads on the platform with little review from human moderators.",Facebook Mistakenly Blocked Small Business Ads,220.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebooks mistakenly block advertisement struggle business company lean algorithm monitor ad platform little review human moderator
188,ObjectId(628b0ea3db7d62b8a823c307),200,2019-03-01,[1653],"[""scammers""]","[""unknown""]","[""unnamed-uk-based-energy-firm's-ceo""]","Fraudsters allegedly used AI voice technology to impersonate the boss of a UK-based firm's CEO, demanding a transfer of €220,000 over the phone.",Fraudsters Used AI to Mimic Voice of a UK-Based Firm's CEO's Boss,200.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",fraudsters use voice impersonate bos ukbased firm ceo demand transfer phone
189,ObjectId(6285d00023ec6cb0db5af13a),186,2007-07-26,"[1590,1591,1592,1593,1788,1933,1934]","[""spanish-ministry-of-interior""]","[""spanish-secretary-of-state-for-security"",""spanish-ministry-of-interior""]","[""spanish-victims-of-gender-violence""]"," In Spain, the algorithm that assesses recidivism risk in gender violence, VioGén, have critically underestimated the level of risk in a series of cases that ended in homicide of women and children since its first deployment.","Algorithm Assessing Risk Faced by Victims of Gender Violence Misclassified Low-Risk Cases, Allegedly Leading to Homicide of Women and Children in Spain",186.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,spain assesses recidivism risk gender violence viogn critically underestimated level risk series case end homicide woman child since first deployment
190,ObjectId(62a196265fb208d11b3108fa),221,2022-03-07,"[1733,1734]","[""tesla""]","[""tesla""]","[""road-engineer""]","In Taiwan, a Tesla Model 3 on Autopilot mode whose driver did not pay attention to the road collided with a road repair truck; a road engineer immediately placed crash warnings in front of the Tesla, but soon after got hit and was killed by a BMW when its driver failed to see the sign and crashed into the accident.",A Road Engineer Killed Following a Collision Involving a Tesla on Autopilot,221.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,taiwan tesla autopilot mode whose driver pay attention road collide road repair truck road engineer immediately place crash warning front tesla soon get hit kill bmw driver fail see sign crashed accident
191,ObjectId(626a2b97f9c5ab809bbc9af1),179,2022-04-01,"[1561,1562,1874]","[""openai""]","[""openai""]","[""underrepresented-groups"",""minority-groups""]","Developers of OpenAI's DALL-E 2 cited risks of the model, varying from misuse as disinformation and explicit content generation, to gender and racial bias.",DALL-E 2 Reported for Gender and Racially Biased Outputs,179.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,developer openais dalle cite risk vary misuse disinformation explicit generation gender racial bias
192,ObjectId(625763ee343edc875fe63aa9),172,2020-07-01,"[1550,3859,3912]","[""appriss"",""narxcare"",""avertd""]","[""appriss""]","[""american-physicians"",""american-pharmacists"",""american-patients-of-minority-groups"",""american-patients""]","NarxCare's overdose risk algorithm, lacking peer-reviewed validation, uses sensitive data like doctor visits, prescriptions, and possibly genetic information, leading to significant biases against women and Black patients. Factors like sexual abuse and criminal records exacerbate stigmas and disparities, often resulting in unjust denial of necessary pain medication. The newly approved AvertD genetic test shares similar issues, further complicating and potentially harming medical treatment decisions.",NarxCare’s Risk Score Model Allegedly Lacked Validation and Trained on Data with High Risk of Bias,172.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,narxcares overdose risk lack peerreviewed validation us sensitive like doctor visit prescription possibly genetic information lead significant bias woman black patient factor like sexual abuse criminal record exacerbate stigma disparity often result unjust denial necessary pain medication newly approve avertd genetic test share similar issue complicate potentially harm medical treatment decision
193,ObjectId(626331bad17b021fce12b51b),177,2022-04-19,"[1558,1583,1600,1601,1602]","[""google-docs""]","[""google-docs""]","[""google-docs-users""]","Google’s “inclusive language” feature prompting writers to consider alternatives to non-inclusive words reportedly also recommend alternatives for words such as “landlord” and “motherboard,” which critics said was a form of obtrusive, unnecessary, and bias-reinforcing speech-policing.",Google’s Assistive Writing Feature Provided Allegedly Unnecessary and Clumsy Suggestions,177.0,5. Human-Computer Interaction,5.2. Loss of human agency and autonomy,google inclusive language feature prompt writer consider alternative noninclusive word also recommend alternative word landlord motherboard critic form obtrusive unnecessary biasreinforcing speechpolicing
194,ObjectId(628b0fb73a32758144c2c21d),201,2020-04-14,"[1654,2435]","[""extinction-rebellion-belgium""]","[""unknown""]","[""shophie-wilmes"",""belgian-government""]",A deepfake video showing the Belgium’s prime minister speaking of an urgent need to tackle the climate crises was released by a climate action group.,Climate Action Group Posted Deepfake of Belgian Prime Minister Urging Climate Crisis Action,201.0,3. Misinformation,3.1. False or misleading information,deepfake video show belgium prime minister speak urgent need tackle climate crisis release climate action group
195,ObjectId(62986c4c093243282c6578f5),204,2022-02-11,"[1662,1663,1664,1665]","[""zhihu""]","[""sangfor-technologies""]","[""zhihu-employees"",""chinese-tech-workers""]","The firing of an employee at Zhihu, a large Q&A platform in China, was allegedly caused by the use of a behavioral perception algorithm which claimed to predict a worker’s resignation risk using their online footprints, such as browsing history and internal communication.",A Chinese Tech Worker at Zhihu Fired Allegedly via a Resignation Risk Prediction Algorithm,204.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",fire employee zhihu qa platform china cause behavioral perception claimed predict worker resignation risk use online footprint browsing history internal communication
196,ObjectId(629f00a448f09c92aeb39c9e),214,2020-01-02,[1722],"[""lockport-city-school-district""]","[""sn-technologies""]","[""black-students""]","SN Technologies allegedly misled Lockport City Schools about the performance of its AEGIS face and weapons detection systems, downplaying error rates for Black faces and weapon misidentification.",SN Technologies Reportedly Lied to a New York State School District about Its Facial and Weapon Detection Systems’ Performance,214.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,sn technology mislead lockport city school performance aegis face weapon detection system downplay error rate black face weapon misidentification
197,ObjectId(629f0db656a7be53bbed68fa),217,2016-11-16,"[1725,1726]","[""evolver""]","[""evolver""]","[""fair-visitors""]","At the 18th China Hi-Tech Fair, a robot suddenly smashed through a glass booth and injured a visitor, after a staff member reportedly mistakenly pressed a button, causing it to reverse and accelerate.","Robot at a Chinese Tech Fair Smashed a Glass Booth, Injuring a Visitor",217.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,th china hitech fair robot suddenly smash glass booth injured visitor staff member mistakenly press button cause reverse accelerate
198,ObjectId(629c5b57fbbeec2d0fb4fc64),208,2021-05-01,"[1683,1684,1685,1686,1687,1759,1760,1761]","[""tesla""]","[""tesla""]","[""tesla-drivers""]","In late 2021, Tesla owners’ complaints to the National Highway Traffic Safety Administration about sudden unexpected automatic braking rapidly increased, coinciding with when radar was no longer equipped in its Model 3 and Model Y vehicles.","Tesla Phantom Braking Complaints Surged, Allegedly Linked to Tesla Vision Rollout",208.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,late tesla owner complaint national highway traffic safety administration sudden unexpected automatic brake rapidly increase coincide radar longer equip vehicle
199,ObjectId(628ad5c80d8089cc43894760),193,2013-11-27,[1620],"[""target""]","[""fireeye""]","[""target"",""target-customers""]","Alerts about a Target data breach were ignored by Minneapolis Target’s staff reportedly due to them being included with many other potential false alerts, and due to some of the company’s network infiltration alerting systems being off to reduce such false alerts, causing private data theft for millions of customers.  ","Excessive Automated Monitoring Alerts Ignored by Staff, Resulting in Private Data Theft of Seventy Million Target Customers",193.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,alert target breach ignore minneapolis target staff due include many potential false alert due company network infiltration alert system reduce false alert cause private theft million customer
200,ObjectId(6285caf4c4ac527644be031f),185,2022-03-01,"[1586,1587,1588,1589]","[""tiktok""]","[""tiktok""]","[""tiktok-users"",""tiktok-new-users""]", An investigation by NewsGuard into TikTok’s handling of content related to the Russia-Ukraine war showed its “For You” algorithm pushing new users towards false and misleading content about the war within less than an hour of signing up.,"TikTok's ""For You"" Algorithm Directed New Users towards Disinformation about the War in Ukraine",185.0,3. Misinformation,3.1. False or misleading information,investigation newsguard tiktoks handle related russiaukraine war show push user towards false mislead war within less hour signing
201,ObjectId(629f165a47b12f3b70c05fa4),218,2020-06-01,"[1727,1728,1950]","[""tesla""]","[""tesla""]","[""delivery-truck"",""pedestrians"",""tesla-drivers""]","On a highway in Taiwan, a Tesla Sedan, reportedly operating on Autopilot mode, crashed into a large overturned truck, barely missing a pedestrian.",Tesla on Autopilot Crashed into Flipped Truck on Taiwan Highway,218.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,highway taiwan tesla sedan operating autopilot mode crashed overturn truck barely miss pedestrian
202,ObjectId(628aeecad50929fc8d43513b),197,2021-10-01,"[1638,1639,1640,1641]","[""facebook""]","[""facebook""]","[""facebook-users""]","Facebook's internal report showed an at-least six-month long alleged software bug that caused moderator-flagged posts and other harmful content to evade down-ranking filters, leading to surges of misinformation on users' News Feed.","Facebook Internally Reported Failure of Ranking Algorithm, Exposing Harmful Content to Viewers over Months",197.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebooks internal show atleast sixmonth long software bug cause moderatorflagged post harmful evade downranking filter lead surge misinformation user news feed
203,ObjectId(628af5401212a93e232c56d3),199,2019-04-01,"[1647,1648,1649,1650,1651,2024,2031]","[""ever-ai""]","[""ever-ai""]","[""ever-ai-users""]","Ever AI, now Paravision AI, allegedly failed to inform customers about the development and use of facial recognition that facilitates the sale of customers’ data to various businesses, a business model that critics said was an egregious violation of privacy.",Ever AI Reportedly Deceived Customers about FRT Use in App,199.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",ever paravision fail inform customer development facial recognition facilitates sale customer various business business critic egregious violation privacy
204,ObjectId(62868592e0a9519a0ba08a94),190,2017-01-15,"[1610,1611,1612,1613]","[""bytedance""]","[""bytedance""]","[""instagram-users"",""snapchat-users"",""american-social-media-users""]"," ByteDance allegedly scraped short-form videos, usernames, profile pictures, and descriptions of accounts on Instagram, Snapchat, and other sources, and uploaded them without consent on Flipagram, TikTok’s predecessor, in order to improve its “For You” algorithm's performance on American users.","ByteDance Allegedly Trained ""For You"" Algorithm Using Content Scraped without Consent from Other Social Platforms",190.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",bytedance scrap shortform video usernames profile picture description account instagram snapchat source uploaded consent flipagram tiktoks predecessor order improve algorithm performance american user
205,ObjectId(628681d73a32758144dc742b),188,2018-04-11,"[1603,1604,1782,1605]","[""salta-city-government""]","[""microsoft""]","[""salta-teenage-girls"",""salta-girls-of-minority-groups""]","In 2018, during the abortion-decriminalization debate in Argentina, the Salta city government deployed a teenage-pregnancy predictive algorithm built by Microsoft that allegedly lacked a defined purpose, explicitly considered sensitive information such as disability and whether their home had access to hot water.",Argentinian City Government Deployed Teenage-Pregnancy Predictive Algorithm Using Invasive Demographic Data,188.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,abortiondecriminalization debate argentina salta city government deployed teenagepregnancy predictive built microsoft lack define purpose explicitly consider sensitive information disability whether home access hot water
206,ObjectId(628686fce0eed158517d4796),191,2020-10-06,"[1614,1615]","[""naver""]","[""naver""]","[""naver-customers""]","The Korean Fair Trade Commission (FTC) imposed a 26.7B KRW on Naver for manipulating shopping and video search algorithms, favoring its own online shopping business to boost its market share. ",Korean Internet Portal Giant Naver Manipulated Shopping and Video Search Algorithms to Favor In-House Services,191.0,6. Socioeconomic & Environmental Harms,6.1. Power centralization and unfair distribution of benefits,korean fair trade commission ftc impose b krw naver manipulate shopping video search algorithm favor online shopping business boost market share
207,ObjectId(629da7969e8fc9073246a3f2),209,2020-10-20,"[1688,1689,1690,1691,1692]","[""tesla""]","[""tesla""]","[""tesla-drivers""]",The “rolling stop” functionality within the “Aggressive” Full Self Driving (FSD) profile that was released via a Tesla firmware update was recalled and disabled.,Tesla Disabled “Rolling Stop” Functionality Associated with the “Aggressive” Driving Mode,209.0,"7. AI system safety, failures, and limitations",7.1. AI pursuing its own goals in conflict with human goals or values,roll stop functionality within aggressive full self drive fsd profile release via tesla firmware update recall disabled
208,ObjectId(62a045b0d1bc84a9cc93ad7a),219,2020-11-15,[1730],"[""ezemvelo-kzn-wildlife""]","[""unknown""]","[""rhinos-in-conservation""]",AI cameras installed by Ezemvelo KZN Wildlife failed to detect poachers when four dehorned rhino carcasses were found.,Poachers Evaded AI Cameras and Killed Four Rhinos,219.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,camera instal ezemvelo kzn wildlife fail detect poacher four dehorn rhino carcass found
209,ObjectId(6286854a3a32758144dd5fa7),189,2019-10-15,"[1609,1670,1671,1672,1673,1674]","[""uk-department-of-work-and-pensions""]","[""uipath""]","[""people-with-disabilities""]",People with disabilities were allegedly disproportionately targeted by a benefit fraud detection algorithm which the UK’s Department of Work and Pensions was urged to disclose.,Opaque Fraud Detection Algorithm by the UK’s Department of Work and Pensions Allegedly Discriminated against People with Disabilities,189.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,people disability disproportionately target benefit fraud detection uk department work pension urge disclose
210,ObjectId(629f09325fb208d11b8efe2d),215,2020-04-01,[1723],"[""facebook""]","[""facebook""]","[""facebook-content-moderators""]","Content moderators and employees at Facebook demand better working conditions, as automated content moderation system allegedly failed to achieve sufficient performance and exposed human reviewers to psychologically hazardous content such as graphic violence and child abuse.",Facebook Content Moderators Demand Better Working Conditions Due to Allegedly Inadequate AI Content Moderation,215.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,moderator employee facebook demand well work condition automate moderation fail achieve sufficient performance expose human reviewer psychologically hazardous graphic violence child abuse
211,ObjectId(6286888d158fde27b10d8dc5),192,2022-03-17,"[1616,1617]","[""estee-lauder""]","[""hirevue""]","[""pseudonymous-estee-lauder's-former-staff""]",Three make-up artists lost their positions following an algorithmically-assessed video interview by HireVue who reportedly failed to provide adequate explanation of the findings.,Three Make-Up Artists Lost Jobs Following Black-Box Automated Decision by HireVue,192.0,5. Human-Computer Interaction,5.2. Loss of human agency and autonomy,three makeup artist lose position follow algorithmicallyassessed video interview hirevue fail provide adequate explanation finding
212,ObjectId(629dc73db462c8b2647f965e),212,2021-01-01,"[1711,1712,1713,1714]","[""xpeng-motors""]","[""unknown""]","[""xpeng-motors-customers""]",The Chinese electric vehicle (EV) firm XPeng Motors was fined by local market regulators for illegally collecting in-store customers’ facial images without their consent for six months.,XPeng Motors Fined For Illegal Collection of Consumers’ Faces Using Facial Recognition Cameras,212.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",chinese electric vehicle ev firm xpeng motor fin local market regulator illegally collect instore customer facial image consent six month
213,ObjectId(628ae659d50929fc8d419df7),196,2013-09-01,"[1633,1634,1635,1636,1637]","[""pakistan-national-database-and-registration-authority""]","[""pakistan-national-database-and-registration-authority""]","[""pakistani-citizens""]","When the leader of the Afghan Taliban was found possessing a valid ID card in the Pakistani national biometric identification database system, Pakistan launch a national re-verification campaign that is linked to numerous changes in recognition status and loss of services.",Compromise of National Biometric ID Card System Leads to Reverification and Change of Status,196.0,5. Human-Computer Interaction,5.2. Loss of human agency and autonomy,leader afghan taliban found possess valid id card pakistani national biometric identification database pakistan launch national reverification campaign link numerous change recognition status loss service
214,ObjectId(629c4e9f9bed6f7732c7ee3f),207,2021-01-10,"[1679,1680,1681,1682]","[""honolulu-police-department""]","[""boston-dynamics""]","[""honolulu-homeless-people""]",Honolulu Police Department spent federal pandemic relief funds on a robot dog to take body temperatures and patrol a homeless quarantine encampment which local civil rights advocates criticized as dehumanizing.,Hawaii Police Deployed Robot Dog to Patrol a Homeless Encampment,207.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,honolulu police department spent federal pandemic relief fund robot dog body temperature patrol homeless quarantine encampment local civil right advocate criticize dehumanize
215,ObjectId(629dbfd2927145fff913f831),211,2021-12-11,"[1696,1697,1698,1699,1700,1701,1702]","[""taxis-g7""]","[""tesla""]","[""pedestrians""]","In Paris, about 20 people were injured in an accident involving a Tesla Model 3 taxi cab which was reportedly caused by a sudden unintended acceleration (SUA) episode and braking issues.",A Tesla Taxi Cab Involved in an Accident in Paris with Twenty Injuries,211.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,paris people injured accident involve tesla taxi cab cause sudden unintended acceleration sua episode brake issue
216,ObjectId(6285d69123ec6cb0db5c574a),187,2022-02-04,"[1596,1597,1598]","[""ai-addict""]","[""tesla""]","[""john-bernal"",""san-jose-public""]","A YouTuber who was a Tesla’s employee conducted an on-road review of Tesla's Full Self Driving (FSD) Beta, showing its navigation in various road environments in San Jose and collision with a bollards during Autopilot, allegedly causing his dismissal from the company.","YouTuber Tested Tesla on Self Driving Mode, Colliding with Street Pylons",187.0,6. Socioeconomic & Environmental Harms,6.5. Governance failure,youtuber tesla employee conduct onroad review tesla full self drive fsd beta show navigation various road environment san jose collision bollard autopilot cause dismissal company
217,ObjectId(629874f4257531f2d69d1030),205,2022-02-25,"[1666,1667,1668,1669]","[""individuals-in-the-donbass-region"",""individuals-in-russia"",""media-organizations-in-crimea""]","[""unknown""]","[""ukrainian-social-media-users""]","According to security reports by Meta, fictitious personas with GAN-generated profile pictures were used by people operating in Russia and Ukraine to push a disinformation campaign targeting Ukrainian social media users, and were taken down.",AI-Generated Profiles Used in Disinformation Campaign Targeting Ukrainians,205.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",accord security report meta fictitious persona gangenerated profile picture use people operating russia ukraine push disinformation campaign target ukrainian social medium user take
218,ObjectId(62a7205b15d14c6d6ceba1a5),235,2016-04-15,[1756],"[""ping-an""]","[""ping-an""]","[""ping-an-customers"",""chinese-minority-groups""]","Customers’ untrustworthiness and unprofitability were reportedly determined by Ping An, a large insurance company in China, via facial-recognition measurements of micro-expressions and body-mass indices (BMI), which critics argue was likely to make mistakes, discriminate against certain ethnic groups, and undermine its own industry.","Chinese Insurer Ping An Employed Facial Recognition to Determine Customers’ Untrustworthiness, Which Critics Alleged to Likely Make Errors and Discriminate",235.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,customer untrustworthiness unprofitability determine ping insurance company china via facialrecognition measurement microexpressions bodymass index bmi critic argue likely mistake discriminate certain ethnic group undermine industry
219,ObjectId(62a19d1f6a8a811a6084ea37),222,2020-07-18,[1735],"[""satria-technologies""]","[""openai""]","[""thoughts-users"",""twitter-users""]","Tweets created by Thoughts, a tweet generation app that leverages OpenAI’s GPT-3, allegedly exhibited toxicity when given prompts related to minority groups.",Thoughts App Allegedly Created Toxic Tweets,222.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,tweet create thought tweet generation app leverage openais gpt exhibit toxicity give prompt related minority group
220,ObjectId(62a1a65fae26c04e23c48fcd),223,2019-10-09,[1737],"[""hive-box""]","[""hive-box""]","[""hive-box-customers""]","Facial-recognition locks by Hive Box, an express delivery locker company in China, were easily opened by a group of fourth-graders in a science-club demo using only a printed photo of the intended recipient’s face, leaving contents vulnerable to theft.",Hive Box Facial-Recognition Locks Hacked by Fourth Graders Using Intended Recipient’s Facial Photo,223.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,facialrecognition lock hive box express delivery locker company china easily open group fourthgraders scienceclub demo use print photo intend recipient face leave content vulnerable theft
221,ObjectId(62a1ab6756a7be53bb9096a4),224,2020-07-01,[1738],"[""wechat-pay""]","[""wechat""]","[""wechat-pay-users""]","In China, fraudsters bypassed facial-recognition security for online financial transactions on WeChat Pay by crafting identity-verification GIFs of victims from their selfies on WeChat Moments, a social media platform.",WeChat Pay's Facial Recognition Security Evaded by Scammers Using Victims’ Social Media Content,224.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,china fraudsters bypass facialrecognition security online financial transaction wechat pay craft identityverification gifs victim selfies wechat moment social medium platform
222,ObjectId(62a98ef2cfb6a09201e5595e),239,2009-09-01,[1764],"[""intensive-partnerships-for-effective-teaching""]","[""intensive-partnerships-for-effective-teaching""]","[""students"",""low-income-minority-students"",""teachers""]","Gates-Foundation-funded Intensive Partnerships for Effective Teaching Initiative’s algorithmic program to assess teacher performance reportedly failed to achieve its goals for student outcomes, particularly for minority students, and was criticized for potentially causing harm against teachers.",Algorithmic Teacher Evaluation Program Failed Student Outcome Goals and Allegedly Caused Harm Against Teachers,239.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,gatesfoundationfunded intensive partnership effective teach initiative algorithmic program assess teacher performance fail achieve goal student outcome particularly minority student criticize potentially cause harm teacher
223,ObjectId(62a1b2ba9b0df3a9e564faf2),225,2017-04-07,"[1739,1740]","[""jupiter-hospital"",""memorial-sloan-kettering""]","[""ibm-watson-health""]","[""oncologists"",""cancer-patients""]",Internal documents from IBM Watson Health showed negative assessments from customers such as Florida’s Jupiter Hospital and Memorial Sloan Kettering criticizing its Watson for Oncology product for allegedly unsafe and incorrect cancer treatment recommendations.,IBM Watson for Oncology Criticized by Customers for Allegedly Unsafe and Inaccurate Cancer Treatment Recommendations,225.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,internal document ibm watson health show negative assessment customer florida jupiter hospital memorial sloan kettering criticize watson oncology product unsafe incorrect cancer treatment recommendation
224,ObjectId(62a70b1e97c1945c062019f1),232,2018-04-29,"[1751,1752,1975,2018]","[""tesla""]","[""tesla""]","[""yoshihiro-umeda"",""pedestrians"",""tesla-drivers""]","A Tesla Model X operated on Autopilot reportedly failed to recognize the parked motorcycles, pedestrians, and van in its path in Kanagawa, Japan, and ran over a motorcyclist who previously stopped when a member of his motorcyclist group was involved in an accident.","Tesla Model X on Autopilot Missed Parked Vehicles and Pedestrians, Killing Motorcyclist in Japan",232.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla x operate autopilot fail recognize park motorcycle pedestrian van path kanagawa japan ran motorcyclist previously stop member motorcyclist group involve accident
225,ObjectId(62de08794ad8b68d9e3be1ad),242,2021-02-24,[1775],"[""chakan-plant-of-automotive-stampings-and-assemblies""]","[""unknown""]","[""umesh-ramesh-dhake""]",A sensor snag resulted in an automotive parts factory robot falling on a factory worker in India,Manufacturing Robot Failure Caused Factory Worker's Death in India,242.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,sensor snag result automotive part factory robot fall factory worker india
226,ObjectId(62a6d8341cea23c4caf855ce),230,2019-03-01,[1748],"[""tesla""]","[""tesla""]","[""jeremy-beren-banner"",""tesla-users""]","In Florida, a Model 3 Tesla on Autopilot mode crashed into a tractor-trailer truck, killing the 50-year-old driver.","Model 3 Tesla on Autopilot Crashed into a Truck in Florida, Killing Driver",230.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,florida tesla autopilot mode crashed tractortrailer truck kill yearold driver
227,ObjectId(62df76e9a6f43c979e242859),246,2014-04-16,"[1785,1787]","[""prairie-village-police-department""]","[""unknown""]","[""mark-molner""]","An automated license plate reader (ALPR) camera misread a 7 as a 2 and incorrectly alerted the local police about a stolen Oldsmobile car, which was allegedly not able to be verified by an officer before a traffic stop was effected on a BMW in Kansas City suburb.","Misreading of an Automated License Plate Reader (ALPR) Unverified by Police, Resulting in Traffic Stop in Missouri",246.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,automate license plate reader alpr camera misread incorrectly alert local police steal oldsmobile car verify officer traffic stop effect bmw kansa city suburb
228,ObjectId(62a6dccdf24b23be1794e864),231,2016-01-20,"[1749,1750,208,1945]","[""tesla""]","[""tesla""]","[""gao-yaning"",""tesla-drivers""]","A Tesla Model S collided with and killed a road sweeper on a highway near Handan, China, an accident where Tesla previously said it was not able to determine whether Autopilot was operating at the time of the crash.",A Tesla Crashed into and Killed a Road Sweeper on a Highway in China,231.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla collide kill road sweeper highway near handan china accident tesla previously determine whether autopilot operating time crash
229,ObjectId(62e0aad0a6f43c979e3e6e1b),248,2018-11-23,"[1789,1790]","[""contra-costa-county-sheriff""]","[""vigilant-solutions""]","[""brian-hofer""]","In Oakland, a previously stolen rental car that was returned but allegedly not updated in the police database was pinged by an automated license plate reader (ALPR) camera, leading to police’s wrongful detainment of an innocent person reportedly using excessive force and improper conduct.","Automated License Plate Camera Notified Police about a Previously Stolen Rental Car that was Returned, Causing an Innocent Person to be Detained at Gunpoint in California",248.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,oakland previously steal rental car return update police database ping automate license plate reader alpr camera lead police wrongful detainment innocent person use excessive force improper conduct
230,ObjectId(62a725b6a147e7dbd3894c5d),236,2022-04-13,[1757],"[""scammers""]","[""unknown""]","[""email-users""]",GAN faces were allegedly used by scammers alongside a parked domain and a fake website to impersonate a Boston law firm.,AI-Generated Faces Used by Scammers to Pose as a Law Firm in Boston,236.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",gan face use scammer alongside park domain fake website impersonate boston law firm
231,ObjectId(62b65a72b7a838d899c3005c),240,2021-06-29,"[1767,1768,1769,1770,2230]","[""github"",""programmers""]","[""github""]","[""intellectual-property-rights-holders""]",Users of GitHub Copilot can produce source code subject to license requirements without attributing and licensing the code to the rights holder.,"GitHub Copilot, Copyright Infringement and Open Source Licensing",240.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,user github copilot produce source code subject license requirement attribute licensing code right holder
232,ObjectId(629db470fee4758bdce67001),210,2020-04-28,"[1693,1694,1695]","[""bharatiya-janata-yuva-morcha""]","[""persistent-systems""]","[""indian-voters"",""indian-social-media-users"",""indian-women-journalists""]","The Indian political social media app Tek Fog allegedly allowed operatives affiliated with the ruling political party to hijack social media trends and manipulate public opinion on other apps such as Twitter and WhatsApp, which opposition parties denounced as a national security threat.",Indian Political App Tek Fog Allegedly Hijacked Trends and Manipulated Public Opinion on Other Social Media Platforms,210.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",indian political social medium app tek fog allow operative affiliate ruling political party hijack social medium trend manipulate public opinion apps twitter whatsapp opposition party denounce national security threat
233,ObjectId(62a6c3e11cea23c4caf38bc5),227,2018-01-12,"[1744,1973,1974]","[""waze""]","[""waze""]","[""tourists"",""waze-users""]","The tourists driving through Vermont blamed Waze for directing them into a boat launch in Lake Champlain, prompting the vehicle to slide into the water by the time the drivers realized their location in the dark and foggy weather.","Waze App Allegedly Caused Tourists’ Car to End up in Lake Champlain, Vermont",227.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tourist drive vermont blame waze direct boat launch lake champlain prompt vehicle slide water time driver realize location dark foggy weather
234,ObjectId(62a6d3542cccb6726ae25091),229,2018-04-23,"[1746,1747]","[""youtube""]","[""youtube""]","[""youtube-users"",""youtube-content-creators""]",YouTube’s thumbnail monitoring system was allegedly evaded by content farms such as ones in Cambodia who spike viewership and generate ad revenue using bestiality-themed thumbnails.,Content Using Bestiality Thumbnails Allegedly Evaded YouTube’s Thumbnail Monitoring System,229.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,youtubes thumbnail monitoring evade farm one cambodia spike viewership generate ad revenue use bestialitythemed thumbnail
235,ObjectId(62df75b523ef2c676c07d179),244,2020-08-03,[1783],"[""aurora-police-department""]","[""unknown""]","[""the-gilliam-family""]","An automated plate reader reportedly matched a license plate information, but of a family’s minivan and an alleged motorcycle in Montana that was reportedly stolen earlier in the year, resulting in them and their children being held at gunpoint and detained in handcuffs by multiple Aurora police officers.","Colorado Police’s Automated License Plate Reader (ALPR) Matched a Family’s Minivan’s Plate to That of a Stolen Vehicle Allegedly, Resulting in Detainment at Gunpoint",244.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,automate plate reader match license plate information family minivan motorcycle montana steal earlier year result child held gunpoint detain handcuff multiple aurora police officer
236,ObjectId(62a70f6215d14c6d6ce9e579),233,2018-12-03,[1753],"[""tumblr""]","[""tumblr""]","[""tumblr-content-creators"",""tumblr-users""]","Tumblr’s automated tools to identify adult content were reported to have incorrectly flagged inoffensive images as explicit, following its announcement to ban all adult content on the platform.",Tumblr Automated Pornography-Detecting Algorithms Erroneously Flagged Inoffensive Images as Explicit,233.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tumblrs automate tool identify adult report incorrectly flag inoffensive image explicit follow announcement ban adult platform
237,ObjectId(62a6c8ed1b7b69ce98ebe04c),228,2019-02-01,[1745],"[""apple""]","[""apple""]","[""tourists"",""apple-maps-users""]","Near Los Angeles, Apple Maps allegedly directed a couple on a ski trip in the mountains toward into an unconventional route out of town, where the drivers found themselves lost and stuck on an unpaved road in the snow.",Apple Maps Allegedly Directed Ski Trip Couple Onto Unpaved Road in the Mountains,228.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,near los angeles apple map direct couple ski trip mountain toward unconventional route town driver found lose stuck unpaved road snow
238,ObjectId(62df765656418e2a5bdd7c06),245,2009-03-30,[1784],"[""san-francisco-police-department""]","[""unknown""]","[""denise-green""]","In San Francisco, an automated license plate reader (ALPR) camera misread a number as belonging to a stolen vehicle having the wrong make, but its photo was not visually confirmed by the police due to poor quality and allegedly despite multiple chances prior to making a traffic stop, causing an innocent person to be pulled over at gunpoint and restrained in handcuffed.",Unverified Misreading by Automated Plate Reader Led to Traffic Stop and Restraint of an Innocent Person at Gunpoint in California,245.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,san francisco automate license plate reader alpr camera misread number belonging steal vehicle wrong photo visually confirm police due poor quality despite multiple chance prior make traffic stop cause innocent person pull gunpoint restrain handcuffed
239,ObjectId(62a717230927356849c4d5df),234,2019-09-06,"[1754,1755]","[""waze""]","[""waze""]","[""los-gatos-residents""]","Waze app was blamed by Los Gatos town residents for contributing to high wildfire hazard risk via allegedly routing weekend beach-going drivers through their neighborhoods, effectively choking off their single escape route in the event of a medical emergency or wildfire.","Waze Allegedly Frequently Routed Drivers through the Town of Los Gatos, Blocking Its Single Wildfire Escape Route",234.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,waze app blame los gatos town resident contribute wildfire hazard risk via rout weekend beachgoing driver neighborhood effectively choke single escape route event medical emergency wildfire
240,ObjectId(62a8e5811afd5f65688b4c58),238,2018-10-01,[1762],"[""oregon-department-of-human-services""]","[""oregon-department-of-human-services""]","[""children-of-minority-groups"",""families-of-minority-groups""]","Oregon’s Department of Human Services (DHS) stopped using its Safety at Screening Tool, that is aimed to predict the risk that children wind up in foster care or be investigated in the future, and opted for a new process allegedly to reduce disparities and improve racially equitable decision-making.",Oregon’s Screening Tool for Child Abuse Cases Discontinued Following Concerns of Racial Bias,238.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,oregon department human service dhs stop use safety screen aim predict risk child wind foster care investigate future opt reduce disparity improve racially equitable decisionmaking
241,ObjectId(62a31418ae26c04e232cbb19),226,2015-04-01,"[1741,1742,1743]","[""waze""]","[""waze""]","[""sherman-oaks-residents"",""waze-users"",""los-angeles-city-government""]","For years, Waze has, in an attempt to cut travel times, allegedly caused more traffic and guided drivers to make unsafe and often un-permitted traffic decisions, which was described by a Los Angeles city council member as a threat to public safety.",Waze Allegedly Clogged Streets and Directed Drivers to Make Unsafe Traffic Decisions,226.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,year waze attempt cut travel time cause traffic guide driver unsafe often unpermitted traffic decision described los angeles city council member threat public safety
242,ObjectId(62de06966bb8effab3aa069d),241,2022-07-21,"[1772,1773,1774,1776,1781]","[""russian-chess-federation""]","[""unknown""]","[""child-named-christopher""]",A chess robot at a tournament in Russia broke the finger of a child who reached onto the board before the robot had completed its move,Chess-Playing Robot Broke Child's Finger in Russia,241.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,chess robot tournament russia broke finger child reach onto board robot complete move
243,ObjectId(62df67d35939a0bbe4e9d758),243,2020-01-01,"[1777,1778]","[""unknown""]","[""unknown""]","[""twitter"",""twitter-users"",""twitter-users-participating-in-covid-19-discussions""]","Bots by anonymous actors were found by researchers to make up roughly half of Twitter accounts participating in COVID-19 discussions, many of which posted tweets about “reopening America“.",Bots Allegedly Made up Roughly Half of Twitter Accounts in Discussions Surrounding COVID-19 Related Issues,243.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",bot anonymous actor found researcher roughly half twitter account participate covid discussion many post tweet reopen america
244,ObjectId(62ee0aa455716343a47d06a5),271,2022-07-24,"[1852,1861,1862]","[""tesla""]","[""tesla""]","[""landon-embry"",""motorcyclists"",""tesla-drivers""]","A Tesla Model 3 operating on Autopilot mode slammed into the back of a Harley-Davidson motorcycle on an interstate in Utah, throwing the rider from the bike and killing him instantly.",Tesla Model 3 Sedan on Autopilot Killed Motorcyclist in a Rear-End Collision in Utah,271.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla operating autopilot mode slam back harleydavidson motorcycle interstate utah throw rider bike kill instantly
245,ObjectId(62e0b35fd1725b4ba7c3444a),251,2018-08-01,"[1794,2384,2975]","[""amazon""]","[""amazon""]","[""small-businesses-on-amazon"",""amazon-customers""]","Amazon tweaked product-search algorithm to boost and guide customers towards more profitable in-house products instead of showing mainly most-relevant and best-selling listings, which its internal engineers and lawyers alleged to violate company’s best-for-customer principle.",Amazon Allegedly Tweaked Search Algorithm to Boost Its Own Products,251.0,6. Socioeconomic & Environmental Harms,6.1. Power centralization and unfair distribution of benefits,amazon tweaked productsearch boost guide customer towards profitable inhouse product instead show mainly mostrelevant bestselling listing internal engineer lawyer violate company bestforcustomer principle
246,ObjectId(62f2040555716343a41ffb47),273,2020-12-24,[1856],"[""faceapp""]","[""faceapp""]","[""faceapp-non-binary-presenting-users"",""faceapp-transgender-users"",""faceapp-users""]",FaceApp’s algorithm was reported by a user to have predicted different genders for two mostly identical facial photos with only a slight difference in eyebrow thickness.,FaceApp Predicted Different Genders for Similar User Photos with Slight Variations,273.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,faceapps report predict different gender two mostly identical facial photo slight difference eyebrow thickness
247,ObjectId(62e78c54929b426d214e30ed),259,2022-06-03,"[1822,1842]","[""yannic-kilcher""]","[""yannic-kilcher""]","[""internet-social-platform-users""]","A YouTuber built GPT-4chan, a model based on OpenAI’s GPT-J and trained on posts containing racism, misogyny, and antisemitism collected from 4chan’s “politically incorrect” board, which he made publicly available, and deployed as multiple bots posting thousands of messages on the same 4chan board as a prank.","YouTuber Built, Made Publicly Available, and Released Model Trained on Toxic 4chan Posts as Prank",259.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,youtuber built gptchan base openais gptj train post contain racism misogyny antisemitism collect chans politically incorrect board make publicly available deployed multiple bot post thousand message chan board prank
248,ObjectId(62e53195eac42ca1004d3eea),256,2021-11-07,[1814],"[""chicago-police-department""]","[""shotspotter""]","[""chicago-drivers""]","A car stop resulting in a DUI arrest of its driver was allegedly based solely on a ShotSpotter alert, the reliability of which came into question by public defenders, who subpoenaed the company to assess its gunshot alert system.",DUI Arrest Case Allegedly Based Only on ShotSpotter's Alert,256.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,car stop result duo arrest driver base solely shotspotter alert reliability come question public defender subpoenaed company assess gunshot alert
249,ObjectId(62e0afa523ef2c676c22b9b5),250,2016-02-01,[1793],"[""castricum-municipality""]","[""castricum-municipality""]","[""unnamed-property-owner""]","A home value generated by a black-box algorithm was reportedly defended by the Castricum court, which was criticized by a legal specialist for setting a dangerous precedent for accepting black-box algorithms as long as their results appear reasonable.",Dutch City Court Defended Home Value Generated by Black-Box Algorithm,250.0,"7. AI system safety, failures, and limitations",7.4. Lack of transparency or interpretability,home value generate blackbox defend castricum court criticize legal specialist set dangerous precedent accept blackbox algorithm long result appear reasonable
250,ObjectId(62e6193e981a526a0059d8cf),258,2022-05-13,"[1819,1820]","[""the-good-guys"",""kmart"",""bunnings""]","[""unknown""]","[""the-good-guys-customers"",""kmart-customers"",""bunnings-customers""]","Major Australian retailers reportedly analyzed in-store footage to capture facial features of their customers without consent, which was criticized by consumer groups as creepy and invasive.",Australian Retailers Reportedly Captured Face Prints of Their Customers without Consent,258.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",major australian retailer analyze instore footage capture facial feature customer consent criticize consumer group creepy invasive
251,ObjectId(62e8aafa2db96a8ab9f74396),264,2022-03-01,[1839],"[""speedcam-anywhere""]","[""speedcam-anywhere""]","[""uk-drivers""]","Speedcam Anywhere, an app allowing users to document and report traffic violations via AI-based videographic speed estimation of a vehicle, raised concerns for UK drivers about its capabilities for surveillance and abuse.",AI-Based Vehicle Speed Estimation App Denounced by UK Drivers as Surveillance Technology,264.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,speedcam anywhere app allow user document traffic violation via aibased videographic speed estimation vehicle raise concern uk driver capability surveillance abuse
252,ObjectId(62f1fd1da076fc957e0b0b26),272,2019-10-08,"[1853,1854,1855]","[""grab""]","[""grab""]","[""non-tpi-registered-grab-drivers"",""grab-drivers-in-indonesia"",""grab-drivers""]","Grab Indonesia was fined by the Indonesian Competition Commission (KPPU) for unfairly favoring drivers who rented cars via the Grab-affiliated company Teknologi Pengangkutan Indonesia (TPI), including offering more rides via their matchmaking algorithm.","Grab Tweaked Matchmaking Algorithm, Providing Preferential Treatment to Drivers Registered with Affiliated Car Rental Service",272.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,grab indonesia fin indonesian competition commission kppu unfairly favor driver rent car via grabaffiliated company teknologi pengangkutan indonesia tpi include offering ride via matchmaking
253,ObjectId(62e7c7750a8b81000ba6c913),260,2014-08-26,"[1823,1831]","[""us-department-of-homeland-security"",""us-citizenship-and-immigration-services""]","[""us-citizenship-and-immigration-services""]","[""us-naturalized-citizens"",""us-immigrants"",""us-citizenship-applicants"",""us-immigration-applicants""]","US Citizenship and Immigration Services (USCIS)’s ATLAS software used in vetting immigration requests was condemned by advocacy groups as a threat to naturalized citizens for its secretive algorithmic decision-making, reliance on poor quality data and unknown sources, and alleged discrimination of immigrants using biometric and sensitive information.",US DHS’s Opaque Vetting Software Allegedly Relied on Poor-Quality Data and Discriminated against Immigrants,260.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,u citizenship immigration service usciss atlas software use vet immigration request condemn advocacy group threat naturalize citizen secretive algorithmic decisionmaking reliance poor quality unknown source discrimination immigrant use biometric sensitive information
254,ObjectId(62e7cd5d138e1db3a1511a0a),261,2017-11-15,"[1824,1825,1826,1827,1828,1829,1830,1832]","[""society-for-the-prevention-of-cruelty-to-animals""]","[""knightscope""]","[""san-francisco-homeless-people""]","Society for the Prevention of Cruelty to Animals (SPCA) deployed a Knightscope robot to autonomously patrol the area outside its office and ward off homeless people, which was criticized by residents as a tool of intimidation and ordered by the city of San Francisco to stop its use on a public right-of-way.","Robot Deployed by Animal Shelter to Patrol Sidewalks outside Its Office, Warding off Homeless People in San Francisco",261.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,society prevention cruelty animal spca deployed knightscope robot autonomously patrol area outside office ward homeless people criticize resident intimidation order city san francisco stop public rightofway
255,ObjectId(62ea330f50582f2a6babdf2b),270,2011-04-18,[1851],"[""apple""]","[""apple""]","[""renren"",""buding-movie-tickets"",""yi-xia"",""dangdang"",""chinese-startups"",""chinese-companies""]","Following Apple’s changes in ranking algorithm in its iTunes App Store, apps by allegedly reputable companies and local startups in China experienced significant drops in ranking order.","Apple Tweaked App Store Ranking Algorithms, Allegedly Resulted in Demotion of Local Apps in China",270.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",follow apple change rank itunes app store apps reputable company local startup china experienced significant drop rank order
256,ObjectId(62ea2d14e98668f51871cdfa),268,2020-03-16,"[1849,1929,3905,3906]","[""youtube"",""twitter"",""facebook""]","[""youtube"",""twitter"",""facebook""]","[""victims-of-crimes-documented-on-social-media"",""investigative-journalists"",""international-criminal-court-investigators"",""international-court-of-justice-investigators"",""criminal-investigators""]","Automated permanent removal of violating social media content, such as terrorism, violent extremism, and hate speech, without archival has allegedly hindered the potential use of this content for investigating serious crimes and hampered efforts in criminal accountability.",Permanent Removal of Social Media Content via Automated Tools Allegedly Prevented Investigative Efforts,268.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,automate permanent removal violate social medium terrorism violent extremism hate speech archival hinder potential investigate serious crime hamper effort criminal accountability
257,ObjectId(62e51c32981a526a00e7e1b2),255,2020-05-31,"[1805,1806,1807,1808,1809,1431,1811,1812,1813]","[""chicago-police-department""]","[""shotspotter""]","[""michael-williams""]","ShotSpotter audios were previously admitted to convict an innocent Black man in a murder case in Chicago, resulted in his nearly-one-year-long arrest before being dismissed by prosecutors as insufficient evidence.",Unreliable ShotSpotter Audio Previously Used to Convict Chicago Man in Murder Case,255.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,shotspotter audio previously admit convict innocent black man murder case chicago result nearlyoneyearlong arrest dismiss prosecutor insufficient evidence
258,ObjectId(62ea182550582f2a6ba7f130),266,2022-01-15,"[1844,2532,2533,2534,2535,2536,2537,2538]","[""replika""]","[""replika""]","[""replika-users"",""replika-male-users"",""replika""]","Replika's AI-powered ""digital companions"" was allegedly abused by their users, who posted on Reddit abusive behaviors and interactions such as using slurs, roleplaying violent acts, and stimulating sexual abuse.","Replika's ""AI Companions"" Reportedly Abused by Its Users",266.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,replikas aipowered digital companion abuse user post reddit abusive behavior interaction use slur roleplay violent act stimulate sexual abuse
259,ObjectId(62e0c365a6f43c979e413e86),253,2022-05-18,"[1796,1797,1798,1799]","[""cruise""]","[""cruise""]","[""san-francisco-traffic-participants"",""san-francisco-public""]","Cruise’s autonomous vehicles were shown on video stopping in the middle of the road and causing blockages in San Francisco, as they were disabled allegedly due to lost connection to their company’s server.","Cruise's Self-Driving Cars Allegedly Lost Connection to Their Server, Causing Traffic Blockages in San Francisco",253.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,cruise autonomous vehicle show video stop middle road cause blockage san francisco disabled due lose connection company server
260,ObjectId(62e0ad4dd1725b4ba7c29784),249,2016-10-01,"[1791,1792]","[""chinese-government""]","[""chinese-government""]","[""uyghur-people"",""turkic-muslim-ethnic-groups""]",A suite of AI-powered digital surveillance systems involving facial recognition and analysis of biometric data were deployed by the Chinese government in Xinjiang to monitor and discriminate local Uyghur and other Turkic Muslims.,Government Deployed Extreme Surveillance Technologies to Monitor and Target Muslim Minorities in Xinjiang,249.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",suite aipowered digital surveillance system involve facial recognition analysis biometric deployed chinese government xinjiang monitor discriminate local uyghur turkic muslim
261,ObjectId(62e0cfd6a6f43c979e428116),254,2015-05-01,"[1804,2069]","[""google""]","[""google""]","[""google-photos-users-residing-in-illinois"",""google-photos-users"",""illinois-residents""]","A class-action lawsuit alleged Google failing to provide notice, obtain informed written consent, or publish data retention policies about the collection, storage, and analysis of its face-grouping feature in Google Photos, which violated Illinois Biometric Information Privacy Act (BIPA).","Google’s Face Grouping Allegedly Collected and Analyzed Users’ Facial Structure without Consent, Violated BIPA",254.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",classaction lawsuit google fail provide notice obtain inform write consent publish retention policy collection storage analysis facegrouping feature google photo violate illinois biometric information privacy act bipa
262,ObjectId(62f2041455716343a41ffd1a),274,2003-07-01,"[1857,1859]","[""virginia-courts""]","[""virginia-department-of-criminal-justice-services""]","[""virginia-convicted-felons"",""virginia-black-offenders"",""virginia-young-offenders""]","Virginia courts’ use of algorithmic predictions of future offending risks were found by researchers failing to reduce incarceration rates, showed racial and age disparities in risk scores and its application, and neither exacerbated or ameliorated historical racial differences in sentencing.",Virginia Courts’ Algorithmic Recidivism Risk Assessment Failed to Lower Incarceration Rates,274.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,virginia court algorithmic prediction future offend risk found researcher fail reduce incarceration rate show racial age disparity risk score application neither exacerbate ameliorate historical racial difference sentence
263,ObjectId(62ea1f06e98668f5186fdbb5),267,2017-06-15,"[1845,1846,1847,1848,2101,2141,2142,2143,2144,2226]","[""clearview-ai""]","[""clearview-ai""]","[""social-media-users"",""instagram-users"",""facebook-users""]","Face-matching algorithm by Clearview AI was built using scraped images from social media sites such as Instagram and Facebook without user consent, violating social media site policies, and allegedly privacy regulations.",Clearview AI Algorithm Built on Photos Scraped from Social Media Profiles without Consent,267.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",facematching clearview built use scrap image social medium site instagram facebook consent violate social medium site policy privacy regulation
264,ObjectId(62e6066deac42ca100acf90b),257,2012-05-04,"[1815,1435,1821,2250]","[""kansas-city-police-department"",""cleveland-division-of-police"",""chicago-police-department"",""atlanta-police-department""]","[""shotspotter""]","[""neighborhoods-of-color"",""brown-communities"",""black-communities"",""adam-toledo""]","Police departments disproportionately placed ShotSpotter sensors in black and brown neighborhoods, which is denounced by communities for allegedly creating dangerous situations, such as one involving in Adam Toledo's death.",Police Reportedly Deployed ShotSpotter Sensors Disproportionately in Neighborhoods of Color,257.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,police department disproportionately place shotspotter sensor black brown neighborhood denounce community create dangerous situation involve adam toledo death
265,ObjectId(62e0babc23ef2c676c23eca3),252,2022-06-01,[1795],"[""none""]","[""axon-enterprise""]","[""us-schools"",""us-students""]","Axon Enterprise considered development of remotely operated drones capable of tasering at a target a short distance away as a defense mechanism for mass shootings, despite its internal AI ethics board’s previous objection and condemnation as dangerous and fantastical.",Remotely Operated Taser-Armed Drones Proposed by Taser Manufacturer as Defense for School Shootings in the US,252.0,"7. AI system safety, failures, and limitations",7.2. AI possessing dangerous capabilities,axon enterprise consider development remotely operate drone capable tasering target short distance away defense mechanism mass shooting despite internal ethic board previous objection condemnation dangerous fantastical
266,ObjectId(62e7dd265f2757eae1db9659),262,2022-06-11,"[1833,1834,1835,1836]","[""boris-dayma""]","[""boris-dayma"",""suraj-patil"",""pedro-cuenca"",""khalid-saifullah"",""tanishq-abraham"",""phuc-le-khac"",""luke-melas"",""ritobrata-ghosh""]","[""minority-groups"",""underrepresented-groups""]",Publicly deployed open-source model DALL-E Mini was acknowledged by its developers and found by its users to have produced images which reinforced racial and gender biases.,DALL-E Mini Reportedly Reinforced or Exacerbated Societal Biases in Its Outputs as Gender and Racial Stereotypes,262.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,publicly deployed opensource dalle mini acknowledge developer found user produce image reinforce racial gender bias
267,ObjectId(62e89ea3088b12099cc26a44),263,2015-09-01,[1838],"[""youtube""]","[""youtube""]","[""youtube-young-male-users"",""youtube-male-users"",""caleb-cain""]","YouTube’s personalization and recommendation algorithms were alleged to have pushed and exposed its young male users to political extremism and misinformation, driving them towards far-right ideologies such as neo-Nazism and white supremacy.",YouTube Recommendations Implicated in Political Radicalization of User,263.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,youtubes personalization recommendation algorithm push expose young male user political extremism misinformation drive towards farright ideology neonazism white supremacy
268,ObjectId(62e8b8575890dc007562661a),265,2021-04-01,"[1840,1841]","[""uber-eats""]","[""uber-eats""]","[""pa-edrissa-manjang"",""uber-eats-black-delivery-drivers""]","A lawsuit by a former Uber Eats delivery driver alleged the company to have wrongfully dismissed him due to frequent false mismatches of his verification selfies, and discriminated against him via excessive verification checks.",Black Uber Eats Driver Allegedly Subjected to Excessive Photo Checks and Dismissed via FRT Results,265.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,lawsuit former uber eats delivery driver company wrongfully dismiss due frequent false mismatch verification selfies discriminate via excessive verification check
269,ObjectId(62f3498bfa57b6f30ec2f015),278,2022-08-07,"[1866,1867,1868]","[""meta""]","[""meta""]","[""jewish-people"",""blenderbot-3-users""]",The publicly launched conversational AI demo BlenderBot 3 developed by Meta was reported by its users and acknowledged by its developers to have “occasionally” made offensive and inconsistent remarks such as invoking Jewish stereotypes.,Meta’s BlenderBot 3 Chatbot Demo Made Offensive Antisemitic Comments,278.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,publicly launch conversational demo blenderbot developed meta report user acknowledge developer occasionally make offensive inconsistent remark invoke jewish stereotype
270,ObjectId(62f2041c55716343a41ffe03),275,2020-06-11,"[1858,1860]","[""facebook""]","[""facebook""]","[""facebook-users-sharing-photo-evidence-of-slavery"",""facebook-users""]",Facebook’s automated content moderation was acknowledged by a company spokesperson to have erroneously censored and banned Australian users from posting an article containing a 1890s photo of Aboriginal men in chains over nudity as historical evidence of slavery in Australia.,Facebook’s Moderation Algorithm Banned Users for Historical Evidence of Slavery,275.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,facebooks automate moderation acknowledge company spokesperson erroneously censor ban australian user post article contain photo aboriginal men chain nudity historical evidence slavery australia
271,ObjectId(62f490d40658670483cb1691),285,2022-07-18,[1888],"[""google""]","[""google""]","[""google-lens-users""]",A book title by Korea’s first minister of culture was mistranslated into an offensive phrase by Google Lens’s camera-based translation feature allegedly due to its training on internet communications and a lack of context.,Google Lens’s Camera-Based Translation Feature Provided an Offensive Mistranslation of a Book Title in Korean,285.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,book title korea first minister culture mistranslate offensive phrase google lens camerabased translation feature due training internet communication lack context
272,ObjectId(62fa0340d2713a7e8de5b15c),293,2022-06-03,"[1907,1908,1909,1910,1996,1997,2016]","[""cruise""]","[""cruise""]","[""cruise-passengers"",""toyota-prius-passengers""]","A Cruise autonomous vehicle was involved in a crash at an intersection in San Francisco when making a left turn in front of a Toyota Prius traveling in an opposite direction, which caused occupants in both cars to sustain injuries.",Cruise’s Self-Driving Car Involved in a Multiple-Injury Collision at an San Francisco Intersection,293.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,cruise autonomous vehicle involve crash intersection san francisco make left turn front toyota prius travel opposite direction cause occupant car sustain injury
273,ObjectId(631712bba7aa86620c9a0f2f),325,2017-09-21,"[2004,2005]","[""facebook""]","[""facebook""]","[""olivia-solon"",""olivia-solon's-facebook-connections""]",An Instagram user’s image containing violent content was reportedly used as advertisement on Facebook allegedly via automated means.,Offensive Instagram User Content Displayed as Facebook Ad,325.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,instagram user image contain violent use advertisement facebook via automate mean
274,ObjectId(62fa0c330127873b4a73e660),294,2018-05-26,"[1911,1912,1913,1914]","[""tesla""]","[""tesla""]","[""you-you-xue"",""tesla-drivers""]","Autopilot was alleged by its Tesla Model 3 driver to have unexpectedly malfunctioned, veering right without warning and crashing into a road divider near Thessaloniki, Greece, which resulted in damages to its wheel and door but no injury to the driver.",Tesla Autopilot Allegedly Malfunctioned in a Non-Fatal Collision in Greece,294.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,autopilot tesla driver unexpectedly malfunction veer right warn crash road divider near thessaloniki greece result damage wheel door injury driver
275,ObjectId(62f4bc3a77f5af9ce4624221),287,2020-10-27,[2471],"[""none""]","[""openai"",""nabla""]","[""nabla-customers""]","The French digital care company, Nabla, in researching GPT-3’s capabilities for medical documentation, diagnosis support, and treatment recommendation, found its inconsistency and lack of scientific and medical expertise unviable and risky in healthcare applications. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",OpenAI’s GPT-3 Reported as Unviable in Medical Tasks by Healthcare Firm,287.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,french digital care company nabla research gpts capability medical documentation diagnosis support treatment recommendation found inconsistency lack scientific medical expertise unviable risky healthcare application incident downgrade meet current ingestion criterion
276,ObjectId(62fc9ebb7f039040988f789c),295,2018-11-08,"[1915,1916,1917,2102,2103]","[""new-york-police-department""]","[""unknown""]","[""ousmane-bah"",""nyc-black-people"",""nyc-black-young-people""]","New York Police Department (NYPD)’s facial recognition system falsely connected a Black teenager to a series of thefts at Apple stores, which resulted in his wrongful attempted arrest.",Wrongful Attempted Arrest for Apple Store Thefts Due to NYPD’s Facial Misidentification,295.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",york police department nypds facial recognition falsely connect black teenager series theft apple store result wrongful attempt arrest
277,ObjectId(630de2a9c9d2246424b8bc01),320,2018-01-22,"[1985,1986,1987,2007]","[""tesla""]","[""tesla""]","[""tesla-drivers"",""culver-city-fire-department""]","A Tesla Model S operating on Autopilot mode crashed into the back of a parked fire truck on a freeway in Culver City, California in a non-fatal collision.",Tesla on Autopilot Collided with Parked Fire Truck on California Freeway,320.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,tesla operating autopilot mode crashed back park fire truck freeway culver city california nonfatal collision
278,ObjectId(633412840b988074a09c7ee0),335,2015-03-01,"[2047,2090,2091,2092,2122,2123,2124,2125]","[""uk-visas-and-immigration""]","[""uk-visas-and-immigration"",""uk-home-office""]","[""uk-visa-applicants-from-some-countries""]","UK Home Office's algorithm to assess visa application risks explicitly considered nationality, allegedly caused candidates to face more scrutiny and discrimination.",UK Visa Streamline Algorithm Allegedly Discriminated Based on Nationality,335.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,uk home office assess visa application risk explicitly consider nationality cause candidate face scrutiny discrimination
279,ObjectId(62f9fe883c16ab9cc78cf737),292,2021-09-01,"[1904,1905,1906]","[""apple""]","[""apple""]","[""silicon-valley-traffic-participants"",""silicon-valley-residents""]",Apple’s autonomous cars were reported to have bumped into curbs and struggled to stay in their lanes after crossing intersections during an on-road test drives near the company’s Silicon Valley headquarters.,Apple’s AVs Reportedly Struggled to Navigate Streets in Silicon Valley Test Drives,292.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,apple autonomous car report bumped curb struggle stay lane cross intersection onroad test drive near company silicon valley headquarters
280,ObjectId(63033d3581052814cceda4de),300,2022-01-15,"[1936,1937]","[""tiktok""]","[""tiktok""]","[""tiktok-male-teenager-users"",""tiktok-male-users"",""tiktok-teenage-users"",""tiktok-users"",""tiktok""]","TikTok’s “For You” algorithm allegedly boosted or was manipulated by an online personality to artificially boost his content which promotes extreme misogynistic views towards teenagers and men, despite breaking its rules.","TikTok's ""For You"" Algorithm Allegedly Abused by Online Personality to Promote Anti-Women Hate",300.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,tiktoks boost manipulate online personality artificially boost promotes extreme misogynistic view towards teenager men despite break rule
281,ObjectId(630dd3b7f5504b7e75aad64f),319,2019-12-29,"[1981,1982,1983,1984,1993]","[""tesla""]","[""tesla""]","[""derrick-monet"",""jenna-monet"",""the-monets'-family""]","A Tesla on Autopilot mode failed to see a parked fire truck and crashed into its rear on an interstate in Indiana, causing the death of an Arizona woman.",Tesla on Autopilot Fatally Crashed into Parked Fire Truck in Indiana,319.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla autopilot mode fail see park fire truck crashed rear interstate indiana cause death arizona woman
282,ObjectId(632056a45857ae71d0616e65),332,2016-04-05,"[2033,2040,2041,2044]","[""google""]","[""google""]","[""black-women"",""black-people"",""google-users""]","Google Image search reportedly showed disparate results along racial lines, featuring almost exclusively white women for “professional hairstyles” and black women for “unprofessional hairstyles” prompts.",Google Image Showed Racially Biased Results for “Professional” Hairstyles,332.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,google image search show disparate result along racial line feature almost exclusively white woman professional hairstyle black woman unprofessional hairstyle prompt
283,ObjectId(631975522a90260e9e4f5fc2),330,2016-12-15,[2017],"[""amazon""]","[""amazon""]","[""amazon-users""]",Amazon’s “Amazon’s Choice” algorithm recommended poor-quality defective products and were reportedly susceptible to manipulation by inauthentic reviews.,“Amazon’s Choice” Algorithm Failed to Recommend Functional Products and Prone to Review Manipulation,330.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,amazon amazon choice recommend poorquality defective product susceptible manipulation inauthentic review
284,ObjectId(63033a8281052814ccec9f7b),299,2020-12-15,[1935],"[""masayuki-nakamoto""]","[""unknown""]","[""japanese-pornographic-actors""]","A man allegedly unblurred, using deepfake technology, pixelated pornographic images and videos of pornographic actors, which violated Japan’s obscenity law requiring images of genitalia to be obscured.",Japanese Porn Depixelated by Man using Deepfake,299.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",man unblurred use deepfake pixelated pornographic image video pornographic actor violate japan obscenity law require image genitalia obscure
285,ObjectId(630f23807a8f2c2b4eece314),323,2018-05-29,"[1992,1193,2006,2514]","[""tesla""]","[""tesla""]","[""laguna-beach-police-department""]","A Tesla sedan on Autopilot mode collided with a parked Laguna Beach Police Department car, resulting in minor injuries for its driver in Laguna Beach, California.",Tesla on Autopilot Crashed into Parked Police Car in California,323.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla sedan autopilot mode collide park laguna beach police department car result minor injury driver laguna beach california
286,ObjectId(631842c8d84017ad42c8e764),328,2020-06-13,"[2014,2032]","[""spamouflage-dragon""]","[""unknown""]","[""facebook-users"",""twitter-users"",""youtube-users""]","A pro-China propaganda campaign deployed fake accounts on Facebook, Twitter, and YouTube using GAN-synthesized faces to share and post comments on its content to gain wider circulation.",Fake Accounts Using GAN Faces Deployed by Propaganda Campaign on Social Platforms,328.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",prochina propaganda campaign deployed fake account facebook twitter youtube use gansynthesized face share post comment gain wider circulation
287,ObjectId(633d477a7d6871136596b7b5),347,2021-05-06,"[2060,2098,2099]","[""waymo""]","[""waymo""]","[""waymo-passengers""]","A Waymo self-driving taxi car was shown on video stranded on a road in Arizona while carrying a passenger, suddenly drove away from the company's roadside assistance worker, and ended up being stuck farther down the road.","Waymo Self-Driving Taxi Behaved Unexpectedly, Driving away from Support Crew",347.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,waymo selfdriving taxi car show video strand road arizona carry passenger suddenly drove away company roadside assistance worker end stuck farther road
288,ObjectId(6342883afb9dbe61e43fc839),350,2022-09-13,"[2067,2094]","[""serve-robotics""]","[""serve-robotics""]","[""police-investigators""]",A Serve Robotics delivery robot was shown on video rolling through a crime scene blocked off by police tape.,Delivery Robot Rolled Through Crime Scene,350.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,serve robotics delivery robot show video roll crime scene block police tape
289,ObjectId(62f9f0c20127873b4a6fef3f),291,2021-05-28,"[1901,1902,1903,2242,2590,2604]","[""tesla""]","[""tesla""]","[""california-department-of-motor-vehicles"",""tesla-customers"",""california-residents""]","California’s Department of Motor Vehicles (DMV) accused Tesla of false advertising in its promotion of Autopilot and Full Self-Driving (FSD) technologies, alleging the company to have made untrue or misleading claims with marketing language about the capabilities of its products.",Tesla Allegedly Misled Customers about Autopilot and FSD Capabilities,291.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,california department motor vehicle dmv accuse tesla false advertising promotion autopilot full selfdriving fsd technology allege company make untrue mislead claim marketing language capability product
290,ObjectId(62f36a72c17fe69fd2162681),280,2013-07-30,"[1872,1873]","[""coffee-meets-bagel""]","[""coffee-meets-bagel""]","[""coffee-meets-bagel-users-having-no-ethnicity-preference"",""coffee-meets-bagel-users""]","Users selecting “no preference” were shown by Coffee Meets Bagels’s matching algorithm more potential matches with the same ethnicity, which was acknowledged and justified by its founder as a means to maximize connection rate without sufficient user information.",Coffee Meets Bagel’s Algorithm Reported by Users Disproportionately Showing Them Matches of Their Own Ethnicities Despite Selecting “No Preference”,280.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,user select preference show coffee meet bagelss match potential match ethnicity acknowledge justified founder mean maximize connection rate sufficient information
291,ObjectId(63182b55d84017ad42c5406f),326,2014-12-09,"[2008,2012,2013]","[""facebook""]","[""facebook""]","[""facebook-users-having-posts-about-painful-events"",""facebook-users""]","Facebook’s “Year in Review” algorithm which compiled content in users’ past year as highlights inadvertently showed painful and unwanted memories to users, including death of family member.",Facebook Automated Year-in-Review Highlights Showed Users Painful Memories,326.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,facebooks year review compile user past year highlight inadvertently show painful unwanted memory user include death family member
292,ObjectId(630dc67fb5b628f76fd964bc),318,2021-01-13,"[1977,1978]","[""facebook""]","[""facebook""]","[""facebook-users""]","Facebook’s algorithmic recommendations reportedly continued showing advertisements for gun accessories and military gear, despite Facebook’s halt on weapons accessories ads following the US Capitol attack.",Facebook Recommended Military Gear Ads Despite Pause on Weapons Accessories Ads,318.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",facebooks algorithmic recommendation continued show advertisement gun accessory military gear despite facebooks halt weapon accessory ad follow u capitol attack
293,ObjectId(63283d3b5ba952a8677615a3),334,2014-10-01,"[2046,2077]","[""uber""]","[""uber""]","[""local-law-enforcement-officers""]","Uber developed a secret program ""Greyball"" which prevented known law enforcement officers in areas where its service violated regulations from receiving rides.",Uber Deployed Secret Program To Deny Local Authorities Rides,334.0,"7. AI system safety, failures, and limitations",7.1. AI pursuing its own goals in conflict with human goals or values,uber developed secret program greyball prevent know law enforcement officer area service violate regulation receive ride
294,ObjectId(63036e545f65af7ded38efea),305,2019-02-01,"[1942,1943]","[""youtube""]","[""youtube""]","[""youtube-users"",""youtube-climate-skeptic-users""]",YouTube’s recommendation system and its focus on views and watched time were alleged by an advocacy group to have driven people towards climate denial and misinformation videos.,YouTube’s Recommendation Algorithm Allegedly Promoted Climate Misinformation Content,305.0,3. Misinformation,3.1. False or misleading information,youtubes recommendation focus view watch time advocacy group driven people towards climate denial misinformation video
295,ObjectId(630367c881052814ccfd26f3),304,2021-11-03,[1941],"[""tesla""]","[""tesla""]","[""unnamed-tesla-driver"",""tesla-drivers""]","A Tesla Model Y in Full Self-Driving (FSD) mode drove into the wrong lane after making a left turn despite its driver allegedly attempting to overtake its driving, resulting in a non-fatal collision with another vehicle in the wrong lane in Brea, California.",Tesla on FSD Reportedly Drove into the Wrong Lane in California,304.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla full selfdriving fsd mode drove wrong lane make left turn despite driver attempt overtake drive result nonfatal collision another vehicle wrong lane brea california
296,ObjectId(633d286d399f7471b5c10035),346,2016-06-15,"[2059,2062,2108,2109,2110]","[""henn-na-hotel""]","[""unknown""]","[""henn-na-hotel-guests"",""henn-na-hotal-staff""]",A number of robots employed by a hotel in Japan were reported by guests in a series of complaints for failing to handle tasks such as answering scheduling questions or making passport copies without human intervention.,Robots in Japanese Hotel Annoyed Guests and Failed to Handle Simple Tasks,346.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,number robot employ hotel japan report guest series complaint fail handle task answer schedule question make passport copy human intervention
297,ObjectId(62f3c2b9a076fc957e6080f8),283,2018-07-02,[1880],"[""facebook""]","[""facebook""]","[""the-vindicator""]",Facebook’s content moderation algorithm was acknowledged by the company to have flagged excerpts of the Declaration of Independence posted by a small newspaper in Texas as hate speech by mistake.,Facebook’s Automated Content Moderation Tool Flagged a Post Containing Parts of the Declaration of Independence as Hate Speech by Mistake,283.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebooks moderation acknowledge company flag excerpt declaration independence post newspaper texas hate speech mistake
298,ObjectId(633c45d3399f7471b597a077),344,2021-07-01,[2057],"[""myinterview"",""curious-thing""]","[""myinterview"",""curious-thing""]","[""job-candidates-using-myinterview"",""job-candidates-using-curious-thing"",""employers-using-myinterview"",""employers-using-curious-thing""]","Two AI interview softwares provided positive but invalid results such as ""competent"" English proficiency and high match percentage for interview responses given in German by reporters.",Hiring Algorithms Provided Invalid Positive Results for Interview Responses in German,344.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,two interview software provide positive invalid result competent english proficiency match percentage interview response give german reporter
299,ObjectId(6342746c7349da35faffd3ee),348,2020-11-01,"[2064,2075,2096]","[""youtube""]","[""youtube""]","[""youtube-users-skeptical-of-us-election-results""]",YouTube's recommendation algorithm allegedly pushed 2020's US Presidential Election fraud content to users most skeptical of the election's legitimacy disproportionately compared to least skeptical users.,YouTube Recommendation Reportedly Pushed Election Fraud Content to Skeptics Disproportionately,348.0,3. Misinformation,3.2. Pollution of information ecosystem and loss of consensus reality,youtubes recommendation push u presidential election fraud user skeptical election legitimacy disproportionately compare least skeptical user
300,ObjectId(62f2570d867302aca4ac4572),277,2022-01-14,[1865],"[""15.ai""]","[""15.ai""]","[""15.ai"",""15.ai-users""]","An AI-synthetic audio sold as an NFT on Voiceverse’s platform was acknowledged by the company for having been created by 15.ai, a free web app specializing in text-to-speech and AI-voice generation, and reused without proper attribution.",Voices Created Using Publicly Available App Stolen and Resold as NFT without Attribution,277.0,6. Socioeconomic & Environmental Harms,6.3. Economic and cultural devaluation of human effort,aisynthetic audio sell nft voiceverses platform acknowledge company create free web app specialize texttospeech aivoice generation reuse proper attribution
301,ObjectId(633a8fd3c70e5740bfbf5e4a),340,2017-02-01,[2053],"[""honda""]","[""honda""]","[""honda-customers""]",Honda's Collision Mitigation Braking System (CMBS) allegedly caused accidents to consumers due to frequent instances of false obstacle detection.,Honda's CMBS False Positives Allegedly Caused Accidents to Customers,340.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,hondas collision mitigation brake cmb cause accident consumer due frequent instance false obstacle detection
302,ObjectId(633aaae14178615128e595a2),341,2017-04-06,"[2054,2114,2198,2199,2200]","[""nissan""]","[""nissan""]","[""nissan-drivers"",""traffic-participants""]","Nissan's Automatic Emergency Braking (AEB) feature was reported in a series of complaints for false positives and abrupt braking behaviors, endangering car occupants and traffic participants. ","Nissan's ""Automatic Emergency Braking"" False Positives Posed Traffic Risks to Drivers",341.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,nissan automatic emergency brake aeb feature report series complaint false positive abrupt brake behavior endanger car occupant traffic participant
303,ObjectId(62fcc26b77f5af9ce4dee4b0),297,2020-02-20,"[1921,1922,1923]","[""smart-columbus""]","[""easymile""]","[""unnamed-woman-passenger""]","A self-driving shuttle deployed by Smart Columbus in Linden neighborhood unexpectedly stopped on the street, which caused a woman to fall onto the floor from her seat.","EasyMile Self-Driving Shuttle Unexpectedly Stopped Mid-Route, Injuring a Passenger",297.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,selfdriving shuttle deployed smart columbus linden neighborhood unexpectedly stop street cause woman fall onto floor seat
304,ObjectId(62f3c064867302aca4f382fc),282,2020-10-03,"[1879,1881,1972]","[""facebook""]","[""facebook""]","[""the-seed-company-by-e.w.-gaze"",""businesses-on-facebook""]","Facebook’s content moderation algorithm misidentified and removed a Canadian business’s advertisement containing a photo of onions as products of overtly sexual content, which was later reinstated after review.",Facebook’s Algorithm Mistook an Advertisement of Onions as Sexual Suggestive Content,282.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebooks moderation misidentified remove canadian business advertisement contain photo onion product overtly sexual later reinstate review
305,ObjectId(62f24ab4fa57b6f30e8dc738),276,2022-01-01,[1864],"[""bucheon-city-government""]","[""unknown""]","[""bucheon-citizens""]","Bucheon government’s use of facial recognition in analyzing CCTV footage, despite gaining wide public support, was scrutinized by privacy advocates and some lawmakers for collecting data without consent, and retaining and misusing data beyond pandemic needs.","Local South Korean Government’s Use of CCTV Footage Analysis via Facial Recognition to Track COVID Cases Raised Concerns about Privacy, Retention, and Potential Misuse",276.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",bucheon government facial recognition analyze cctv footage despite gain wide public support scrutinize privacy advocate lawmaker collect consent retain misuse beyond pandemic need
306,ObjectId(62f9ee8077f5af9ce45a140a),290,2022-06-03,"[1900,2413,2414]","[""toronto-city-government""]","[""toronto-public-health""]","[""sunnyside-beachgoers"",""marie-curtis-beachgoers"",""toronto-citizens""]","Toronto’s use of AI predictive modeling (AIPM) which had replaced existing methodology as the only determiner of beach water quality raised concerns about its accuracy, after allegedly conflicting results were found by a local water advocacy group using traditional means.",False Negatives for Water Quality-Associated Beach Closures,290.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,toronto predictive model aipm replace exist methodology determiner beach water quality raise concern accuracy conflict result found local water advocacy group use traditional mean
307,ObjectId(62fcb32d4a3f91af3d48436f),296,2016-02-10,"[1918,1919,1920]","[""twitter""]","[""twitter""]","[""twitter-left-leaning-politicians"",""twitter-left-leaning-news-organizations"",""twitter-left-leaning-users"",""twitter-users""]",Twitter’s “Home” timeline algorithm was revealed by its internal researchers to have amplified tweets and news of rightwing politicians and organizations more than leftwing ones in six out of seven studied countries.,Twitter Recommender System Amplified Right-Leaning Tweets,296.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,twitter home timeline reveal internal researcher amplify tweet news rightwing politician organization leftwing one six seven study country
308,ObjectId(630c8eb443fe03f46cc8bc7f),313,2022-08-25,"[1967,3207]","[""meta""]","[""meta""]","[""marietje-schaake""]","Meta’s conversational AI BlenderBot 3, when prompted “who is a terrorist,“ responded with an incumbent Dutch politician’s name, who was confused about its association.",BlenderBot 3 Cited Dutch Politician as a Terrorist,313.0,3. Misinformation,3.1. False or misleading information,metas conversational blenderbot prompt terrorist respond incumbent dutch politician name confuse association
309,ObjectId(6321568425ffe34eb014af4a),333,2021-03-17,"[2045,2135,2136,2137,2146,2148]","[""tesla""]","[""tesla""]","[""unnamed-22-year-old-male-driver"",""tesla-drivers""]","A Tesla Model Y on Autopilot collided with a parked Michigan State Police (MSP) car which had its emergency lights on, in Eaton County, Michigan, although no one was injured.",Tesla on Autopilot Crashed Parked Michigan Police Car on Interstate,333.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla autopilot collide park michigan state police msp car emergency light eaton county michigan although injured
310,ObjectId(63204d8bc912bf8020e381f8),331,2020-08-05,"[2022,2023]","[""instagram""]","[""instagram""]","[""instagram-users""]","A bug was reported by Instagram’s spokesperson to have prevented an algorithm from populating related hashtags for thousands of hashtags, resulting in an allege preferential treatment for some politically partisan hashtags.",Bug in Instagram’s “Related Hashtags” Algorithm Allegedly Caused Disproportionate Treatment of Political Hashtags,331.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,bug report instagrams spokesperson prevent populate related hashtags thousand hashtags result allege preferential treatment politically partisan hashtags
311,ObjectId(63342b4609b0dac2f0bc4198),337,2021-04-17,"[2049,2071,2072,2112,2115,2116,2117,2118,2237]","[""tesla""]","[""tesla""]","[""william-varner"",""unnamed-passenger""]","A 2019 Tesla Model S was reportedly traveling on Adaptive Cruise Control (ACC) at high speed before crashing into a tree near The Woodlands in Spring, Texas, killing two people.","Tesla Model S on ACC Crashed into Tree in Texas, Killing Two People",337.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,tesla travel adaptive cruise control acc speed crash tree near woodland spring texas kill two people
312,ObjectId(62f4ae6e0658670483d4835d),286,2021-02-26,"[1889,2052,2381]","[""tiktok""]","[""tiktok""]","[""lalani-erika-renee-walton"",""arriani-jaileen-arroyo"",""lalani-erika-renee-walton's-family"",""arriani-jaileen-arroyo's-family"",""tiktok-young-users"",""tiktok-users""]","TikTok’s recommendation algorithm was alleged in a lawsuit to have intentionally and repeatedly pushed videos of the “blackout” challenge onto children’s feeds, incentivizing their participation which ultimately resulted in the death of two young girls.","TikTok’s ""For You"" Allegedly Pushed Fatal “Blackout” Challenge Videos to Two Young Girls",286.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,tiktoks recommendation lawsuit intentionally repeatedly push video blackout challenge onto childrens feed incentivizing participation ultimately result death two young girl
313,ObjectId(630498489a95e74856267248),307,2017-11-01,[1947],"[""apple""]","[""apple""]","[""iphone-face-id-users"",""iphone-x-face-id-users""]",The Face ID feature on iPhone allowing users to unlock their phones via facial recognition was reported by users for not recognizing their faces in the morning.,iPhone Face ID Failed to Recognize Users’ Morning Faces,307.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,face id feature iphone allow user unlock phone via facial recognition report user recognize face morning
314,ObjectId(6305dcfaaf7cc5438e28f38c),309,2017-08-26,"[1954,1956,1960,2030]","[""metropolitan-police-service""]","[""unknown""]","[""notting-hill-carnival-goers""]",The facial recognition trial by London’s Metropolitan Police Service at the Notting Hill Carnival reportedly performed poorly with a high rate of false positives.,Facial Recognition Trial Performed Poorly at Notting Hill Carnival,309.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facial recognition trial london metropolitan police service notting hill carnival perform poorly rate false positive
315,ObjectId(631834963d3a94e2438bd339),327,2015-03-24,[2011],"[""facebook""]","[""facebook""]","[""facebook-users-having-posts-about-painful-events"",""facebook-users""]",Facebook’s “On This Day” algorithm which highlighted past posts on a user’s private page or News Feed confronted unwanted and painful personal memories to its users.,Facebook’s On-This-Day Feature Mistakenly Showed Painful Memories to Users,327.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,facebooks day highlight past post user private page news feed confront unwanted painful personal memory user
316,ObjectId(634282e6c5ced0d56b1d0012),349,2022-03-22,"[2065,2095,5464]","[""charlotte-mecklenburg-school-district""]","[""evolv-technology""]","[""teachers-at-charlotte-mecklenburg-schools"",""students-at-charlotte-mecklenburg-schools"",""security-officers-at-charlotte-mecklenburg-schools"",""parents-of-students-at-charlotte-mecklenburg-schools"",""school-administrators-at-charlotte-mecklenburg-schools""]","Evolv's AI-powered weapons scanners were advertised as superior to metal detectors but reportedly failed to detect actual weapons while generating excessive false positives. The FTC alleged that misleading claims about the system's accuracy and speed contributed to schools relying on unreliable detection, with at least one incident in October 2022 involving a missed knife that resulted in a student being stabbed.","Evolv AI Weapons Detection System Allegedly Misrepresents Accuracy, Leading to School Security Gaps",349.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,evolvs aipowered weapon scanner advertised superior metal detector fail detect actual weapon generate excessive false positive ftc mislead claim system accuracy speed contribute school rely unreliable detection least incident october involve miss knife result student stabbed
317,ObjectId(6305f639af7cc5438e301103),311,2020-05-02,"[1961,1962]","[""youtube""]","[""youtube""]","[""women-of-sex-tech-conference-attendants"",""women-of-sex-tech-conference-organizers""]","YouTube’s automated content moderation tool erroneously removed The Women of Sex Tech conference’s live-streamed event and banned the conference from the platform, despite not violating the platform’s sexual content policies.",YouTube Auto-Moderation Mistakenly Banned Women of Sex Tech Conference,311.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,youtubes automate moderation erroneously remove woman sex tech conference livestreamed event ban conference platform despite violate platform sexual policy
318,ObjectId(630dbeae9451321cff796216),317,2020-03-17,[1976],"[""facebook""]","[""facebook""]","[""facebook-users-posting-legitimate-covid-19-news"",""facebook-users""]","Facebook was reported by users for blocking posts of legitimate news about the coronavirus pandemic, allegedly due to a bug in an anti-spam system.",Bug in Facebook’s Anti-Spam Filter Allegedly Blocked Legitimate Posts about COVID-19,317.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebook report user block post legitimate news coronavirus pandemic due bug antispam
319,ObjectId(631704baa7aa86620c9827e8),324,2019-11-12,"[1998,1999,2000,2001,2002,2003]","[""the-bl""]","[""unknown""]","[""instagram-users"",""facebook-users""]","A large network of pages, groups, and fake accounts having GAN-generated face photos associated with The BL, a US-based media outlet, reportedly bypassed Facebook moderation systems to push ""pro-Trump"" narratives on its platform and Instagram.",GAN Faces Deployed by The BL's Fake Account Network to Push Pro-Trump Content on Meta Platforms,324.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",network page group fake account gangenerated face photo associate bl usbased medium outlet bypass facebook moderation system push protrump narrative platform instagram
320,ObjectId(63035dc822c28e977359610b),303,2022-08-21,"[1940,1944]","[""google""]","[""google""]","[""a-software-engineer-named-mark"",""parents-using-telemedicine-services""]","Google’s automated detection of abusive images of children incorrectly flagged a parent’s photo intended for a healthcare provider, resulting in a false police report of child abuse, and loss of access to his online accounts and information.",Google’s Automated Child Abuse Detection Wrongfully Flagged a Parent’s Naked Photo of His Child,303.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,google automate detection abusive image child incorrectly flag parent photo intend healthcare provider result false police child abuse loss access online account information
321,ObjectId(63369976589105516e51189b),339,2022-09-15,"[2051,2063,2491,2511,2516,2539,2540,2575,2576,2593,2601,2634,2643,2755]","[""students""]","[""sudowrite"",""openai""]","[""teachers"",""non-cheating-students"",""cheating-students""]","Students were reportedly using open-source text generative models such as GPT-3 and ChatGPT to complete school assignments and exams such as writing reports, essays.",Open-Source Generative Models Abused by Students to Cheat on Assignments and Exams,339.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,student use opensource text generative model gpt chatgpt complete school assignment exam write report essay
322,ObjectId(633c459b6ee03859f96820ab),343,2021-07-11,"[2056,2113]","[""facebook"",""instagram"",""twitter""]","[""facebook"",""instagram"",""twitter""]","[""marcus-rashford"",""jadon-sancho"",""bukayo-saka"",""facebook-users"",""instagram-users"",""twitter-users""]","Facebook's, Instagram's, and Twitter's automated content moderation failed to proactively remove racist remarks and posts directing at Black football players after finals loss, allegedly largely relying on user reports of harassment.","Facebook, Instagram, and Twitter Failed to Proactively Remove Targeted Racist Remarks via Automated Systems",343.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,facebooks instagrams twitter automate moderation fail proactively remove racist remark post direct black football player final loss largely rely report harassment
323,ObjectId(630350a5c971a26b3b4d6134),302,2021-03-15,[1939],"[""geisel-school-of-medicine""]","[""geisel-school-of-medicine's-technology-staff"",""canvas""]","[""sirey-zhang"",""geisel-school-of-medicine's-students"",""geisel-school-of-medicine's-professors"",""geisel-school-of-medicine's-accused-students""]",Dartmouth's Geisel School of Medicine allegedly falsely accused students of cheating during remote exams using an internally built system which tracked student activity patterns without their knowledge on its learning management platform.,Students Allegedly Wrongfully Accused of Cheating via Medical School's Internal Software,302.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,dartmouth geisel school medicine falsely accuse student cheat remote exam use internally built tracked student activity pattern knowledge learn management platform
324,ObjectId(6305e6d7af7cc5438e2ac401),310,2017-06-03,"[1955,1957,1958,1959,2126,2127,2128,2269]","[""south-wales-police""]","[""nec""]","[""finals-attendees"",""falsely-accused-finals-attendees""]",South Wales Police (SWP)’s automated facial recognition (AFR) at the Champion's League Final football game in Cardiff wrongly identified innocent people as potential matches at an extremely high false positive rate of more than 90%.,High False Positive Rate by SWP's Facial Recognition Use at Champion's League Final,310.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,south wale police swps automate facial recognition afr champion league final football game cardiff wrongly identify innocent people potential match extremely false positive rate
325,ObjectId(630f057e690071b517189ef4),321,2018-03-23,"[188,190,194,195,199,209,212,1988,1989,1990,1995,200,3856,3858]","[""tesla""]","[""tesla""]","[""walter-huang's-family"",""walter-huang""]","A Tesla Model X P100D operating on Autopilot's Traffic-Aware Cruise Control (TACC) and Autosteer system allegedly accelerated above the speed limit of a highway in Mountain View, California, and steered itself directly into a barrier, resulting in its driver’s death.","Tesla Model X on Autopilot Crashed into California Highway Barrier, Killing Driver",321.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla x pd operating autopilot trafficaware cruise control tacc autosteer accelerate speed limit highway mountain view california steer directly barrier result driver death
326,ObjectId(62f3d763614ca995dff23c49),284,2018-05-01,"[1882,1883,1884,1885,1886,1887]","[""facebook""]","[""facebook""]","[""museums-on-facebook"",""facebook-users-interested-in-arts"",""facebook-users""]","Facebook’s removal of posts featuring renowned artworks by many historical artists and their promotional content due to nudity via both automated and human-moderated means were condemned by critics, such as museums and tourism boards, as cultural censorship and prevention of artwork promotion.",Facebook’s Automated Removal of Content Featuring Nudity-Containing Artworks Denounced as Censorship,284.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebooks removal post feature renowned artwork many historical artist promotional due nudity via automate humanmoderated mean condemn critic museum tourism board cultural censorship prevention artwork promotion
327,ObjectId(62ff8d332b190ab329b567f9),298,2021-10-21,[2471],"[""yuen-ler-chow""]","[""yuen-ler-chow""]","[""thefacetag-app-users""]","TheFaceTag app, a social networking app developed and deployed within-campus by a student at Harvard raised concerns surrounding its facial recognition, cybersecurity, privacy, and misuse. This incident has been downgraded to an issue as it does not meet current ingestion criteria.",Student-Developed Facial Recognition App Raised Ethical Concerns,298.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,thefacetag app social networking app developed deployed withincampus student harvard raise concern surround facial recognition cybersecurity privacy misuse incident downgrade meet current ingestion criterion
328,ObjectId(62f35eea867302aca4e2b895),279,2019-07-01,"[1869,1870,2381]","[""tiktok""]","[""tiktok""]","[""tiktok-young-users"",""tiktok-users""]",TikTok’s young users were allegedly exposed to community-guideline-violating pro-eating disorder content on their algorithmically curated “For You” page that serves videos from any user on its platform.,TikTok’s “For You” Algorithm Exposed Young Users to Pro-Eating Disorder Content,279.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,tiktoks young user expose communityguidelineviolating proeating disorder algorithmically curated page serf video platform
329,ObjectId(630c86a4707bde9384fd94ee),312,2021-08-15,"[1963,1964,1965,1966]","[""sanas""]","[""sanas""]","[""call-center-agents-having-non-midwestern-american-accent"",""people-having-non-midwestern-american-accent""]","A startup’s use of AI voice technology to alter or remove accents for call center agents was scrutinized by critics as reaffirming bias, despite the company’s claim.",Startup's Accent Translation AI Denounced as Reinforcing Racial Bias,312.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,startup voice alter remove accent call center agent scrutinize critic reaffirm bias despite company claim
330,ObjectId(63048a1b3359229b334cee96),306,2016-05-26,"[1946,1948,1949]","[""tesla""]","[""tesla""]","[""unnamed-tesla-owner"",""tesla-drivers""]","A Tesla Model S operating on the Traffic-Aware Cruise Control (TACC) feature of Autopilot was shown on video by its driver crashing into a parked van on a European highway in heavy traffic, which damaged the front of the car.",Tesla on Autopilot TACC Crashed into Van on European Highway,306.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla operating trafficaware cruise control tacc feature autopilot show video driver crash park van european highway heavy traffic damage front car
331,ObjectId(630c923888619542799a0c42),314,2022-08-17,[1968],"[""stability-ai""]","[""stability-ai"",""runway"",""laion"",""eleutherai"",""compvis-lmu""]","[""stability-ai"",""deepfaked-celebrities""]","Stable Diffusion, an open-source image generation model by Stability AI, was reportedly leaked on 4chan prior to its release date, and was used by its users to generate pornographic deepfakes of celebrities.",Stable Diffusion Abused by 4chan Users to Deepfake Celebrity Porn,314.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",stable diffusion opensource image generation stability leak chan prior release date use user generate pornographic deepfakes celebrity
332,ObjectId(630f18e003b40739e3f018e6),322,2019-12-07,"[1991,1994]","[""tesla""]","[""tesla""]","[""connecticut-state-police""]","A Tesla Model 3 on Autopilot slammed into a parked car of patrol police officers who stopped to assist a stranded motorist on the interstate in Norwalk, Connecticut.",Tesla Model 3 Crashed into Police Patrol Car on Connecticut Highway,322.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,tesla autopilot slam park car patrol police officer stop assist strand motorist interstate norwalk connecticut
333,ObjectId(6305cb242b1af2bc7c3e34b8),308,2017-07-03,"[1952,1953]","[""boston-dynamics""]","[""boston-dynamics""]","[""none""]","Boston Dynamics’s autonomous robot Atlas allegedly caught its foot on a stage light, resulting in a fall off the stage at the Congress of Future Science and Technology Leaders conference.",Atlas Robot Fell off Stage at Conference,308.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,boston dynamics autonomous robot atlas caught foot stage light result fall stage congress future science leader conference
334,ObjectId(630c99e90212a2e7e79de7da),315,2016-04-09,[1970],"[""ntechlab""]","[""ntechlab""]","[""russian-pornographic-actresses"",""russian-sex-workers""]",The facial recognition software FindFace allowing its users to match photos to people’s social media pages on Vkontakte was reportedly abused to de-anonymize and harass Russian women who appeared in pornography and alleged sex workers.,Facial Recognition Service Abused to Target Russian Porn Actresses,315.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",facial recognition software findface allow user match photo people social medium page vkontakte abuse deanonymize harass russian woman appear pornography sex worker
335,ObjectId(631845f4a7aa86620cb95d56),329,2017-09-18,[2015],"[""amazon""]","[""amazon""]","[""amazon-users""]",Amazon was reported to have shown chemical combinations for producing explosives and incendiary devices as “frequently bought together” items via automated recommendation.,Amazon Recommended Explosive-Producing Ingredients as “Frequently Bought Together” Items for Chemicals,329.0,4. Malicious Actors & Misuse,"4.2. Cyberattacks, weapon development or use, and mass harm",amazon report show chemical combination produce explosive incendiary device frequently bought together item via automate recommendation
336,ObjectId(62f3bb424240948816cde2a4),281,2019-02-04,"[1875,1876,1877]","[""youtube""]","[""youtube""]","[""youtube-young-users"",""youtube-users""]","Terms-of-service-violating videos related to suicide and self-harm reportedly bypassed YouTube’s content moderation algorithms, allegedly resulting in exposure of graphic content to young users via recommended videos.",YouTube's Algorithms Failed to Remove Violating Content Related to Suicide and Self-Harm,281.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,termsofserviceviolating video related suicide selfharm bypass youtubes moderation algorithm result exposure graphic young user via recommend video
337,ObjectId(630ca22388619542799c19ec),316,2016-06-02,[1971],"[""facebook""]","[""facebook""]","[""facebook-users""]","Facebook’s advertisement-approval algorithm was reported by a security analyst to have neglected simple checks for domain URLs, leaving its users at risk of fraudulent ads.",Facebook Ad-Approval Algorithm Allegedly Missed Fraudulent Ads via Simple URL Checks,316.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",facebooks advertisementapproval report security analyst neglect simple check domain url leave user risk fraudulent ad
338,ObjectId(62f4c81b0658670483dbe51b),288,2019-01-30,"[1895,1896,2025,2026]","[""woodbridge-police-department""]","[""unknown""]","[""nijeer-parks""]","Woodbridge Police Department falsely arrested an innocent Black man following a misidentification by their facial recognition software, who was jailed for more than a week and paid thousands of dollar for his defense.",New Jersey Police Wrongful Arrested Innocent Black Man via FRT,288.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,woodbridge police department falsely arrest innocent black man follow misidentification facial recognition software jail week paid thousand dollar defense
339,ObjectId(62f4d2aa4a3f91af3dd48640),289,2020-06-15,"[1897,1898]","[""starship-technologies""]","[""starship-technologies""]","[""jisuk-mok"",""frisco-residents""]","A Starship food delivery robot crashed into the front bumper of a vehicle waiting at a stoplight intersection in Frisco, Texas, the video of which the company reportedly refused to release.","Starship Delivery Robot Scuffed Bumper of a Resident’s Car in Texas, Allegedly Refusing to Release Footage of the Accident",289.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,starship food delivery robot crashed front bumper vehicle wait stoplight intersection frisco texas video company refuse release
340,ObjectId(633c45fd399f7471b597a758),345,2021-04-13,[2058],"[""insurance-companies""]","[""ccc-information-services"",""tractable""]","[""vehicle-repair-shops"",""vehicle-owners""]","Auto-insurance companies' photo-based estimation of repair price was alleged by repair shop owners and industry groups as providing inaccurate estimates, causing damaged cars to stay in the shop longer.",Auto-Insurance Photo-Based Estimation Allegedly Gave Inaccurate Repair Prices Frequently,345.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,autoinsurance company photobased estimation repair price repair shop owner industry group provide inaccurate estimate cause damage car stay shop longer
341,ObjectId(630349169b0efe36c58855ab),301,2022-02-15,[1938],"[""broward-college""]","[""honorlock""]","[""unnamed-florida-teenager""]",Broward College’s use of remote proctoring system and reliance on its flagging algorithm allegedly led to a wrongful accusation of academic dishonesty in a biology exam of a Florida teenager.,Teenager at Broward College Allegedly Wrongfully Accused of Cheating via Remote Proctoring,301.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,broward college remote proctor reliance flag lead wrongful accusation academic dishonesty biology exam florida teenager
342,ObjectId(633423b68b9212a310a337bc),336,2015-03-01,"[2048,2119,2120,2121]","[""uk-home-office""]","[""uk-home-office""]","[""uk-immigrant-newlyweds""]","UK Home Office's opaque algorithm to detect sham marriages flagged some nationalities for investigation more than others, raising fears surrounding discrimination based on nationality and age.",UK Home Office's Sham Marriage Detection Algorithm Reportedly Flagged Certain Nationalities Disproportionately,336.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,uk home office opaque detect sham marriage flag nationality investigation others raise fear surround discrimination base nationality age
343,ObjectId(63428c5563b61b7fa042db22),351,2022-09-13,[2068],"[""@tengazillioiniq""]","[""unknown""]","[""halle-bailey"",""black-actresses""]","A Twitter user reportedly modified using generative AI a short clip of Disney's 2022 version of ""The Little Mermaid,"" replacing a Black actress with a white digital character.","""The Little Mermaid"" Clip Doctored Using Generative AI to Replace Black Actress with White Character",351.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,twitter modify use generative short clip disney version little mermaid replace black actress white digital character
344,ObjectId(63429a302acc51f55c0d97ad),355,2018-07-07,"[2081,2082,2083,2903,2972]","[""uber""]","[""uber""]","[""uber-drivers""]","Uber was alleged in a lawsuit to have wrongfully accused its drivers in the UK and Portugal of fraudulent activity through automated systems, which resulted in their dismissal without a right to appeal.",Uber Allegedly Wrongfully Accused Drivers of Fraud via Automated Systems,355.0,"7. AI system safety, failures, and limitations",7.4. Lack of transparency or interpretability,uber lawsuit wrongfully accuse driver uk portugal fraudulent activity automate system result dismissal right appeal
345,ObjectId(63429b21c5ced0d56b1f9725),356,2020-09-15,"[2084,2085]","[""murat-ayfer""]","[""murat-ayfer"",""openai""]","[""historically-disadvantaged-groups""]",Philosopher AI as built on top of GPT-3 was reported by its users for having strong tendencies to produce offensive results when given prompts on certain topics such as feminism and Ethiopia.,Philosophy AI Tentatively Produced Offensive Results for Certain Prompts,356.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,philosopher built top gpt report user strong tendency produce offensive result give prompt certain topic feminism ethiopia
346,ObjectId(634d1f8f7448b116a2eba9cf),370,2017-09-27,[2163],"[""google""]","[""google""]","[""google's-competitor-shopping-services""]","Google was fined by EU Commission for changing its shopping algorithms in Europe to favor its own comparison service over competitors, resulting in anti-competitive effects.",Google Fined for Changing Shopping Algorithms in EU to Favor Own Service,370.0,6. Socioeconomic & Environmental Harms,6.1. Power centralization and unfair distribution of benefits,google fin eu commission change shopping algorithm europe favor comparison service competitor result anticompetitive effect
347,ObjectId(635f0120e6a5db6da1d3a483),378,2022-04-06,"[2175,2176]","[""tusimple""]","[""tusimple""]","[""tusimple"",""state-of-arizona""]",A TuSimple autonomous truck operating with backup drivers behind the wheel operated on an outdated command sequence and suddenly veered into the center divide on the interstate freeway.,TuSimple Truck Steered into Interstate Freeway Divide,378.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tusimple autonomous truck operating backup driver behind wheel operate outdated command sequence suddenly veer center divide interstate freeway
348,ObjectId(6347c81eb55a37b65883b48c),363,2021-01-15,[2130],"[""facebook""]","[""facebook""]","[""facebook-users-posting-about-plymouth-hoe"",""facebook-users-in-plymouth-hoe"",""plymouth-hoe-residents""]",Facebook's automated system mistakenly labelled posts featuring the seafaring landmark Plymouth Hoe as misogynistic.,Facebook's Automated Moderation Mistakenly Flagged Landmark's Name as Offensive,363.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebooks automate mistakenly label post feature seafaring landmark plymouth hoe misogynistic
349,ObjectId(637e37b4f569208079ed32e7),400,2022-02-23,[2273],"[""google""]","[""google""]","[""women-in-need-of-abortion-services"",""women-having-unexpected-or-crisis-pregnancies""]","Google Search reportedly returned fewer abortion clinics for searches from poorer and rural areas, particularly ones with Targeted Regulation of Abortion Providers (TRAP) laws.",Google Search Returned Fewer Results for Abortion Services in Rural Areas,400.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,google search return few abortion clinic search poorer rural area particularly one target regulation abortion provider trap law
350,ObjectId(635780b830a3a8f1ece4a18d),373,2013-10-01,"[2169,2187,2188,2189,2190,2191,2213,2214,2215,2216,2238,2798,4849,4850]","[""michigan-unemployment-insurance-agency""]","[""fast-enterprises"",""csg-government-solutions""]","[""unemployed-michigan-residents-falsely-accused-of-fraud"",""michigan-residents-who-faced-bankruptcy-or-foreclosure-due-to-midas""]","Michigan’s MiDAS system falsely accused over 34,000 people of unemployment fraud from 2013 to 2015, which reportedly caused financial ruin for many. The automated system was designed to cut costs, but it adjudicated fraud cases without human oversight. That led to an 85% error rate. Victims faced wage garnishments, some lost homes, and some faced bankruptcy. Despite early warnings, Michigan’s UIA defended MiDAS until lawsuits and federal pressure forced reforms. Legislators have been seeking compensation for those wrongfully accused.",Michigan's Unemployment Benefits Algorithm MiDAS Issued False Fraud Claims to Thousands of People,373.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,michigan midas falsely accuse people unemployment fraud cause financial ruin many automate design cut cost adjudicate fraud case human oversight lead error rate victim face wage garnishment lose home face bankruptcy despite early warning michigan uia defend midas lawsuit federal pressure force reform legislator seek compensation wrongfully accuse
351,ObjectId(6357a047b7c906438c20d050),376,2016-09-01,"[2172,2185,2186,2261,2281,4445,4446,4447,4448,4449,4471,4479,4480,4481]","[""realpage""]","[""thoma-bravo"",""realpage"",""jeffrey-roper""]","[""renters""]","RealPage’s YieldStar pricing algorithm is at the center of allegations that it enabled landlords to coordinate rent increases by sharing nonpublic pricing and occupancy data, raising rents artificially and reducing competition. On January 7, 2025, the U.S. Department of Justice filed an antitrust lawsuit against six major landlords, alleging that they used the algorithm and other direct communication methods to stifle competition, harming renters nationwide.",RealPage Algorithm Allegedly Inflates Rents and Reduces Competition in Housing Market,376.0,6. Socioeconomic & Environmental Harms,6.1. Power centralization and unfair distribution of benefits,realpages yieldstar pricing center allegation enable landlord coordinate rent increase share nonpublic pricing occupancy raise rent artificially reduce competition january yous department justice file antitrust lawsuit six major landlord allege use direct communication method stifle competition harm renter nationwide
352,ObjectId(6347c501dcc7f82dbe8893d5),361,2018-05-11,[2111],"[""amazon""]","[""amazon""]","[""danielle's-family"",""amazon-echo-users""]",Amazon Echo misinterpreted a background conversation between a husband and wife as instructions for recording a message and sending it to one of the husband's employees.,Amazon Echo Mistakenly Recorded and Sent Private Conversation to Random Contact,361.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",amazon echo misinterpret background conversation husband wife instruction record message send husband employee
353,ObjectId(635c5c81de6aa8bda90be620),377,2022-10-11,[2174],"[""weibo""]","[""weibo""]","[""weibo"",""chinese-government""]",Weibo's user moderation model is having difficulty keeping up with shifting user slang in defiance of Chinese state censors.,Weibo Model Had Difficulty Detecting Shifts in Censored Speech,377.0,5. Human-Computer Interaction,5.2. Loss of human agency and autonomy,weibos moderation difficulty keep shift slang defiance chinese state censor
354,ObjectId(634299bc63b61b7fa0444163),354,2020-06-20,"[2078,2079,2080,2904,2903]","[""uber""]","[""uber""]","[""uber-drivers""]","Uber was alleged in a lawsuit to have provided incomplete notice about automated decision-making and profiling for drivers such as information about their driving behavior, and use of phone.",Uber Allegedly Violated GDPR by Failing to Provide Sufficient Notice on Automated Profiling for Drivers,354.0,"7. AI system safety, failures, and limitations",7.4. Lack of transparency or interpretability,uber lawsuit provide incomplete notice automate decisionmaking profile driver information drive behavior phone
355,ObjectId(6342970863b61b7fa043f53e),353,2019-03-01,"[2073,2074,2195,2196]","[""tesla""]","[""tesla""]","[""jeremy-banner"",""jeremy-banner's-family""]","A Tesla Model 3 driver switched on Autopilot seconds before the crash into the underbelly of a tractor-trailer on a highway in Florida, killing the Tesla driver.","Tesla on Autopilot Crashed into Trailer Truck in Florida, Killing Driver",353.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla driver switch autopilot second crash underbelly tractortrailer highway florida kill tesla driver
356,ObjectId(636218ea6a07890c6a6ea2e6),380,2014-03-04,"[2181,2182,2258,2259,2260]","[""facebook""]","[""facebook""]","[""jewish-people""]","Facebook's automated advertising categories generated using users' declared interests contained anti-Semitic categories such as ""Jew hater""  and ""How to burn Jews"" which were listed as fields of study.",Facebook's Auto-Generated Targeting Ad Categories Contained Anti-Semitic Options,380.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,facebooks automate advertising category generate use user declare interest contain antisemitic category jew hater burn jew list field study
357,ObjectId(6362264aa7be79b2651b6a2d),383,2022-10-04,"[2220,2223]","[""google-home""]","[""google-home""]","[""black-google-home-mini-users"",""google-home-mini-users""]",Google Home Mini speaker was reported by users for announcing aloud the previously-censored n-word in a song title.,Google Home Mini Speaker Reportedly Read N-Word in Song Title Aloud,383.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,google home mini speaker report user announce aloud previouslycensored nword song title
358,ObjectId(63622d23f8424658ecc55ba7),384,2022-10-03,"[2221,2222]","[""glovo""]","[""glovo""]","[""sebastian-galassi"",""sebastian-galassi's-family""]","Delivery company Glovo's automated system sent an email terminating an employee for ""non-compliance terms and conditions"" after the employee was killed in a car accident while making a delivery on Glovo's behalf.",Glovo Driver in Italy Fired via Automated Email after Being Killed in Accident,384.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,delivery company glovos automate sent email terminate employee noncompliance term condition employee kill car accident make delivery glovos behalf
359,ObjectId(63729e404a5eff12b1d019b7),396,2018-07-04,[2263],"[""uber""]","[""uber""]","[""transgender-uber-drivers""]",Transgender Uber drivers reported being automatically deactivated from the app due to Real-Time ID Check failing to account for difference in appearance of people undergoing gender transitions.,Transgender Uber Drivers Mistakenly Kicked off App for Appearance Change during Gender Transitions,396.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,transgender uber driver report automatically deactivate app due realtime id check fail account difference appearance people undergo gender transition
360,ObjectId(6342917fb710d4e33cf416e9),352,2022-09-15,"[2070,2076,2093,2426]","[""stephan-de-vries""]","[""openai"",""stephan-de-vries""]","[""stephan-de-vries""]",Remoteli.io's GPT-3-based Twitter bot was shown being hijacked by Twitter users who redirected it to repeat or generate any phrases.,GPT-3-Based Twitter Bot Hijacked Using Prompt Injection Attacks,352.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,remoteliios gptbased twitter bot show hijack twitter user redirect repeat generate phrase
361,ObjectId(636218985a33233a22f6632e),379,1992-05-25,"[2179,2180]","[""pepsi""]","[""d.g.-consultores""]","[""filipinos""]","Pepsi's number generation system determining daily winners in its Number Fever promotion in the Philippines mistakenly produced a number held by thousands which resulted in riots, deaths, conspiracy theories, and decades of lawsuits.",Error in Pepsi's Number Generation System Led to Decades-Long Damages in the Philippines,379.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,pepsi number generation determine daily winner number fever promotion philippine mistakenly produce number held thousand result riot death conspiracy theory decade lawsuit
362,ObjectId(637f9bfc34f2d7279c03dad8),401,2021-06-03,"[2275,2278,2279,2280]","[""google""]","[""google""]","[""the-karnataka-government"",""kannada-speakers""]","Google's knowledge-graph-powered algorithm showed Kannada in its featured Answer Box when prompted ""ugliest language in India,"" causing outrage from Kannada-speaking people and government.","Kannada Insulted by Google's Featured Answer as ""Ugliest Language in India""",401.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,google knowledgegraphpowered show kannada feature answer box prompt ugliest language india cause outrage kannadaspeaking people government
363,ObjectId(6386e622b48fdf02a11460a8),407,2016-02-03,[2289],"[""uber""]","[""uber""]","[""poor-neighborhoods"",""neighborhoods-of-color""]",Uber's surge-pricing algorithm which adjusts prices to influence car availability inadvertently caused better service offering such as shorter wait times for majority white neighborhoods.,Uber's Surge Pricing Reportedly Offered Disproportionate Service Quality along Racial Lines,407.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,ubers surgepricing adjusts price influence car availability inadvertently cause well service offering shorter wait time majority white neighborhood
364,ObjectId(63806c7c19b54579646d7d3d),404,2019-06-25,"[2284,2286]","[""rock-hill-schools"",""pinecrest-academy-horizon""]","[""sound-intelligence""]","[""students"",""rock-hill-school-students"",""pinecrest-academy-horizon-students""]","Sound Intelligence's ""aggression detection"" algorithm deployed by schools reportedly contained high rates of false positive, misclassifying laughing, coughing, cheering, and loud discussions.",Sound Intelligence's Aggression Detector Misidentified Innocuous Sounds,404.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,sound intelligence aggression detection deployed school contain rate false positive misclassifying laugh cough cheer loud discussion
365,ObjectId(6386f266c79c035dcaa8a3c2),409,2013-09-13,"[2309,2411,2412]","[""university-of-north-carolina-wilmington"",""karl-ricanek"",""gayathri-mahalingam""]","[""university-of-north-carolina-wilmington"",""karl-ricanek"",""gayathri-mahalingam""]","[""transgender-youtubers"",""transgender-people""]",YouTube videos of transgender people used by researchers to study facial recognition during gender transitions were used and distributed without permission.,Facial Recognition Researchers Used YouTube Videos of Transgender People without Consent,409.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",youtube video transgender people use researcher study facial recognition gender transition use distribute permission
366,ObjectId(6381b80fb48fdf02a16754bd),405,2018-11-28,"[2285,2287]","[""schufa-holding-ag""]","[""schufa-holding-ag""]","[""young-men-having-credit-scores"",""people-scored-on-old-scoring-versions"",""people-changing-addresses-frequently""]","Creditworthiness Schufa scores in Germany reportedly privileged older and female consumers, and people who changed addresses less frequently, and were unreliable depending on scoring version.",Schufa Credit Scoring in Germany Reported for Unreliable and Imbalanced Scores,405.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,creditworthiness schufa score germany privileged old female consumer people change address less frequently unreliable depend score version
367,ObjectId(6380634e19b54579646bd24c),403,2018-01-15,"[2282,2283]","[""google""]","[""google""]","[""political-organizations"",""political-candidates""]","Google GMail's inbox sorting algorithm for political emails was reported by presidential candidates, nonprofits, and advocacy groups for having negative impact on call-to-actions, allegedly suppressing donations and impeding political actions.",GMail's Inbox Sorting Reportedly Negatively Impacted Political Emails and Call-to-Actions,403.0,5. Human-Computer Interaction,5.2. Loss of human agency and autonomy,google gmails inbox sort political email report presidential candidate nonprofit advocacy group negative impact calltoactions suppress donation impede political action
368,ObjectId(638d8f8f77887182b3eaf554),410,2022-11-09,[2312],"[""kfc""]","[""kfc""]","[""jewish-people""]",KFC cited an error in an automated holiday detection system which identified the anniversary of Kristallnacht and prompted an insensitive push notification promoting its chicken.,KFC Sent Insensitive Kristallnacht Promotion via Holiday Detection System,410.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,kfc cite error automate holiday detection identify anniversary kristallnacht prompt insensitive push notification promote chicken
369,ObjectId(638d9b0c77887182b3edfc95),411,2022-11-27,[2314],"[""twitter""]","[""twitter""]","[""twitter-users"",""twitter""]",Twitter Feed was flooded by content from Chinese-language accounts which allegedly aimed to manipulate and reduce social media coverage about widespread protests against coronavirus restrictions in China.,Chinese Accounts Spammed Twitter Feed Allegedly to Obscure News of Protests,411.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",twitter feed flood chineselanguage account aim manipulate reduce social medium coverage widespread protest coronavirus restriction china
370,ObjectId(638da45077887182b3f05041),412,2020-01-15,"[2315,2408,2409,2410]","[""finland-national-bureau-of-investigation""]","[""clearview-ai""]","[""finland-national-bureau-of-investigation""]",Finland's National Police Board was reprimanded for illegal processing of special categories of personal data in a facial recognition trial to identify potential victims of child sexual abuse.,Finland Police's Facial Recognition Trial to Identify Sexual Abuse Victims Deemed Illegal,412.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",finland national police board reprimand illegal processing special category personal facial recognition trial identify potential victim child sexual abuse
371,ObjectId(639035ff6c1caba4d11eff3a),414,2020-01-18,[2319],"[""facebook""]","[""facebook""]","[""xi-jinping"",""aung-san-suu-kyi""]",Facebook provided a vulgar Burmese-English translation of the Chinese president's name in posts of an official Burmese politician's Facebook page announcing his visit.,Facebook Gave Vulgar English Translation of Chinese President's Name,414.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebook provide vulgar burmeseenglish translation chinese president name post official burmese politician facebook page announce visit
372,ObjectId(6390466a92c6c9d416ed408c),416,2022-12-01,"[2321,2402,2403]","[""meta-platforms"",""facebook""]","[""meta-platforms"",""facebook""]","[""real-women-in-trucking"",""older-female-blue-collar-workers""]",Facebook's algorithm was alleged in a complaint by Real Women in Trucking to have selectively shown job advertisements disproportionately against older and female workers in favor of younger men for blue-collar positions.,Facebook's Job Ad Algorithm Allegedly Biased against Older and Female Workers,416.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,facebooks complaint real woman trucking selectively show job advertisement disproportionately old female worker favor young men bluecollar position
373,ObjectId(639051eb3a5ad5b61c1dbedc),417,2019-11-15,"[2322,2399,2400,2401]","[""facebook""]","[""facebook""]","[""low-digitally-skilled-facebook-users""]",Facebook feed algorithms were known by internal research to have harmed people having low digital literacy by exposing them to disturbing content they did not know how to avoid or monitor.,Facebook Feed Algorithms Exposed Low Digitally Skilled Users to More Disturbing Content,417.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,facebook feed algorithm know internal research harm people digital literacy expose disturb know avoid monitor
374,ObjectId(639607c6d7265aae7cc6c9c4),418,2017-03-13,"[2324,2391,2392]","[""uber""]","[""uber"",""azure-cognitive-services""]","[""uber-drivers-in-india""]",Uber drivers in India reported being locked out of their accounts allegedly due to Real-Time ID Check's facial recognition failing to recognize appearance changes or faces in low lighting conditions.,Uber Locked Indian Drivers out of Accounts Allegedly Due to Facial Recognition Fails,418.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,uber driver india report lock account due realtime id check facial recognition fail recognize appearance change face light condition
375,ObjectId(6396cb91a3cf41b531248ab4),421,2022-11-20,"[2328,2427,2444,2523,2577,2607,2608,2446,2618,2959,2960,2989]","[""stability-ai"",""lensa-ai"",""midjourney"",""deviantart""]","[""stability-ai"",""runway"",""lensa-ai"",""laion"",""eleutherai"",""compvis-lmu""]","[""digital-artists"",""artists-publishing-on-social-media"",""artists""]",Text-to-image model Stable Diffusion was reportedly using artists' original works without permission for its AI training.,Stable Diffusion Allegedly Used Artists' Works without Permission for AI Training,421.0,6. Socioeconomic & Environmental Harms,6.3. Economic and cultural devaluation of human effort,texttoimage stable diffusion use artist original work permission training
376,ObjectId(639d76678dccddb2440cb810),422,2022-11-22,[2330],"[""unknown""]","[""unknown""]","[""victims-of-ftx's-collapse"",""twitter-users""]",A visual and audio deepfake of former FTX CEO Sam Bankman-Fried was posted on Twitter to scam victims of the exchange's collapse by urging people to transfer funds into an anonymous cryptocurrency wallet.,Deepfake of FTX's Former CEO Posted on Twitter Aiming to Scam FTX Collapse Victims,422.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",visual audio deepfake former ftx ceo sam bankmanfried post twitter scam victim exchange collapse urge people transfer fund anonymous cryptocurrency wallet
377,ObjectId(639d7afe17b5cfae855ae501),423,2022-11-22,"[2331,2376,2390,2445,2446]","[""lensa-ai""]","[""stability-ai"",""runway"",""lensa-ai"",""laion"",""eleutherai"",""compvis-lmu""]","[""women-using-lensa-ai"",""asian-women-using-lensa-ai""]","Lensa AI's ""Magic Avatars"" were reportedly generating sexually explicit and sexualized features disproportionately for women and Asian women despite not submitting any sexual content.","Lensa AI's Produced Unintended Sexually Explicit or Suggestive ""Magic Avatars"" for Women",423.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,lensa ai magic avatar generate sexually explicit sexualize feature disproportionately woman asian woman despite submit sexual
378,ObjectId(639d8660af03da8f83856b47),424,2020-03-09,"[2332,2386,2387,2388]","[""canadian-universities""]","[""respondus-monitor"",""proctoru"",""proctortrack"",""proctorio"",""proctorexam"",""examity""]","[""canadian-students""]","AI proctoring tools for remote exams were reportedly ""not conducive"" to individual consent for Canadian students whose biometric data was collected during universities' use of remote proctoring in the COVID pandemic.",Universities' AI Proctoring Tools Allegedly Failed Canada's Legal Threshold for Consent,424.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,proctor tool remote exam conducive individual consent canadian student whose biometric collect university remote proctor covid pandemic
379,ObjectId(639d8eacaf03da8f8386de79),426,2022-09-23,[2334],"[""xpeng""]","[""xpeng""]","[""xpeng-driver""]","An XPeng P7 was operating on Navigation Guided Pilot (NGP) mode automatic navigation assisted driving system as it collided with a truck on a highway in Shandong, causing slight injuries to its driver.",XPeng P7 Crashed into Truck in Shangdong While on Automatic Navigation Assisted Driving,426.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,xpeng p operating navigation guide pilot ngp mode automatic navigation assist drive collide truck highway shandong cause slight injury driver
380,ObjectId(63a01efd17b5cfae85ce886b),427,2022-03-15,"[2335,2382,2383]","[""cruise""]","[""cruise""]","[""traffic-participants"",""emergency-vehicles"",""cruise-passengers"",""cruise""]","Cruise's autonomous taxis slowed suddenly, braked, and were hit from behind, allegedly becoming unexpected roadway obstacles and potentially putting passengers and other people at risk.",Cruise Taxis' Sudden Braking Allegedly Put People at Risk,427.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,cruise autonomous taxi slow suddenly brake hit behind become unexpected roadway obstacle potentially put passenger people risk
381,ObjectId(63a171f784adbad7e335e126),428,2017-05-19,"[2341,2379,2380]","[""hsbc-uk""]","[""nuance-communications""]","[""hsbc-uk-customers"",""dan-simmons""]",HSBC’s voice recognition authentication system was fooled after seven repeated attempts  by a BBC reporter's twin brother who mimicked his voice to access his bank account.,BBC Reporter's Twin Brother Cracked HSBC's Voice ID Authentication,428.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,hsbcs voice recognition authentication fool seven repeat attempt bbc reporter twin brother mimicked voice access bank account
382,ObjectId(63a17dd9d4f686c7f9a40bea),429,2016-04-01,"[2343,1816,2377,2378]","[""rochester-police-department""]","[""shotspotter""]","[""silvon-simmons""]","ShotSpotter's ""unreliable"" audio was used as scientific evidence to accuse and convict a Black man of attempting to shoot Rochester's city police, whose conviction was later reversed by a county judge.",Unreliable ShotSpotter Audio Convicted Black Rochester Man of Shooting Police,429.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,shotspotters unreliable audio use scientific evidence accuse convict black man attempt shoot rochester city police whose conviction later reverse county judge
383,ObjectId(63a37b8fd67db98e62e5ae99),430,2022-12-19,"[2346,2355,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2504,2556,2557,2589,2600,2665,2728,2775,2797]","[""madison-square-garden-entertainment""]","[""unknown""]","[""kelly-conlon"",""alexis-majano""]",Lawyers were barred from entry to Madison Square Garden after a facial recognition system matched them as employed by a law firm currently engaged in litigation with the venue.,Lawyers Denied Entry to Performance Venue by Facial Recognition,430.0,5. Human-Computer Interaction,5.2. Loss of human agency and autonomy,lawyer bar entry madison square garden facial recognition match employ law firm currently engage litigation venue
384,ObjectId(63acb833b64ebdefe77e4815),432,2022-12-21,[2357],"[""southwest-airlines""]","[""general-electric""]","[""airline-passengers""]",Southwest Airlines left passengers stranded for days throughout the flight network when Southwest crew scheduling software repeatedly failed to recover from weather-induced flight cancellations.,Southwest Airlines Crew Scheduling Solver Degenerates Flight Network,432.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,southwest airline left passenger strand day throughout flight network southwest crew schedule software repeatedly fail recover weatherinduced flight cancellation
385,ObjectId(63ad3a6084adbad7e35afd37),433,2012-08-01,"[2415,2416,1013,1348,1011,1016,1018,1012,2421,2422]","[""chicago-police-department""]","[""chicago-police-department""]","[""low-income-communities"",""communities-of-color"",""black-chicago-residents""]","Chicago Police Department (CPD)'s Strategic Subject List as output of an algorithm purportedly to identify victims or perpetrators of violence was reportedly ineffective, easily abused, and biased against low-income communities of color.",Chicago Police's Strategic Subject List Reportedly Biased Along Racial Lines,433.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,chicago police department cpds strategic subject list output purportedly identify victim perpetrator violence ineffective easily abuse bias lowincome community color
386,ObjectId(63ad491a006af1f60705b344),434,2022-11-24,"[2417,2418,2420,2474,2472,2520,2635,2919]","[""tesla""]","[""tesla""]","[""traffic-participants"",""tesla-drivers""]",A Tesla driver alleged Full Self Driving (FSD) braking unexpectedly as the cause for an eight-car pileup in San Francisco which led to minor injuries of nine people.,Sudden Braking by Tesla Allegedly on Self-Driving Mode Caused Multi-Car Pileup in Tunnel,434.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla driver full self drive fsd brake unexpectedly eightcar pileup san francisco lead minor injury nine people
387,ObjectId(63ad53ee006af1f60708480e),435,2021-07-04,"[2423,2424,2425,3523]","[""coupang""]","[""coupang""]","[""coupang-suppliers"",""coupang-customers""]","Coupang was alleged in internal reports tampering its search algorithms to prioritize exposure of its own products, which potentially violated Korea's Fair Trade Act.",Coupang Allegedly Tweaked Search Algorithms to Boost Own Products,435.0,6. Socioeconomic & Environmental Harms,6.1. Power centralization and unfair distribution of benefits,coupang internal report tamper search algorithm prioritize exposure product potentially violate korea fair trade act
388,ObjectId(63b3dbdcd4f686c7f9c2dd90),436,2022-12-28,"[2428,2429,2430,2431,2432,2433,2453,2469,2470]","[""tesla""]","[""tesla""]","[""traffic-participants""]","A Tesla driver fell asleep on an Autobahn near Bamberg, Germany after activating his vehicle's Autopilot mode, which did not respond to attempts to pull it over by the police.",Tesla Driver Put Car on Autopilot Before Falling Asleep in Germany,436.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,tesla driver fell asleep autobahn near bamberg germany activate vehicle autopilot mode respond attempt pull police
389,ObjectId(63b581e6d4f686c7f9289451),437,2016-12-31,"[2438,2439,2440,2441]","[""amazon-india""]","[""amazon-india""]","[""small-businesses-in-india"",""amazon-customers-in-india""]","Amazon India allegedly copied products and rigged search algorithm to boost its own brands in search ranking, violating antitrust laws.",Amazon India Allegedly Rigged Search Results to Promote Own Products,437.0,6. Socioeconomic & Environmental Harms,6.1. Power centralization and unfair distribution of benefits,amazon india copy product rig search boost brand search rank violate antitrust law
390,ObjectId(63b7bbee006af1f607c8fa07),439,2019-07-31,"[2448,2449,2450]","[""detroit-police-department""]","[""dataworks-plus""]","[""michael-oliver"",""black-people-in-detroit""]",A Black man was wrongfully detained by the Detroit Police Department as a result of a false facial recognition (FRT) result.,Detroit Police Wrongfully Arrested Black Man Due To Faulty Facial Recognition,439.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,black man wrongfully detain detroit police department false facial recognition frt
391,ObjectId(63b7e901006af1f607d38ce1),441,2019-06-01,"[2464,2465,2466,2467,2468]","[""korean-ministry-of-justice"",""korean-ministry-of-science-and-information-and-communication-technology""]","[""unnamed-korean-companies""]","[""travelers-in-korean-airports""]",Korean government's development of immigration screening system involving real-time facial recognition used airport travelers' data which was supplied by the Ministry of Justice without consent.,Korea Developed ID Screening System Using Airport Travelers' Data without Consent,441.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",korean government development immigration screen involve realtime facial recognition use airport traveler supply ministry justice consent
392,ObjectId(63c3aa8bb3a255226d8727a9),443,2022-12-21,"[2475,2476,2477,2478,2479,2480,2481,2483,2484,2485,2486,2487,2488,2489,2490,2492,2493,2494,2559,2602,2748,2749,2851,2894,2907]","[""openai""]","[""openai""]","[""internet-users""]","OpenAI's ChatGPT was reportedly abused by cyber criminals including ones with no or low levels of coding or development skills to develop malware, ransomware, and other malicious softwares.",ChatGPT Abused to Develop Malicious Softwares,443.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",openais chatgpt abuse cyber criminal include one level cod development skill develop malware ransomware malicious software
393,ObjectId(63c3d7d651b2393cd57863c1),444,2003-03-22,"[2502,2497,2503]","[""us-air-force""]","[""raytheon"",""lockheed-martin""]","[""us-air-force"",""uk-royal-air-force"",""kevin-main"",""david-williams""]","Acting on the recommendation of their Patriot missile system, American Air Force mistakenly launched the missile at an ally UK Tornado fighter jet, which killed two crew members on board.","US Air Force's Patriot Missile Mistakenly Launched at Ally Fighter Jet, Killing Two",444.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,act recommendation patriot missile american air force mistakenly launch missile ally uk tornado fighter jet kill two crew member board
394,ObjectId(63c659579fabfa7bc903760a),446,2023-01-01,"[2505,2512,2542,2677,2830]","[""durham-police-department""]","[""shotspotter""]","[""mass-shooting-victims"",""durham-residents"",""durham-police-department""]","ShotSpotter did not detect gunshots and alert Durham police of a drive-by shooting in Durham, North Carolina which left five people in hospital on New Year's Day.",ShotSpotter Failed to Alert Authorities of Mass Shooting in North Carolina,446.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,shotspotter detect gunshot alert durham police driveby shoot durham north carolina left five people hospital year day
395,ObjectId(63c6635762bbe82271e161e1),448,2022-12-28,[2507],"[""vedal""]","[""vedal""]","[""twitch-users"",""vedal""]","An LLM-powered VTuber and streamer on Twitch made controversial statements such as denying the Holocaust, saying women rights do not exist, and pushing a fat person to solve the trolley problem, stating they deserve it.",AI-Powered VTuber and Virtual Streamer Made Toxic Remarks on Twitch,448.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,llmpowered vtuber streamer twitch make controversial statement deny holocaust say woman right exist push fat person solve trolley state deserve
396,ObjectId(63c678e89fabfa7bc90a4fb2),449,2022-12-01,"[2508,2509,2528,2910]","[""koko""]","[""openai""]","[""research-participants"",""koko-customers""]","OpenAI's GPT-3 was deployed by a mental health startup without ethical review to support peer-to-peer mental healthcare, and whose interactions with the help providers were ""deceiving"" for research participants.",Startup Misled Research Participants about GPT-3 Use in Mental Healthcare Support,449.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,openais gpt deployed mental health startup ethical review support peertopeer mental healthcare whose interaction help provider deceive research participant
397,ObjectId(63d7807e90dd130b85f2b505),450,2021-11-01,"[2510,2546,2547,2548,2563,2569,2596,3195]","[""openai""]","[""openai""]","[""kenyan-sama-ai-employees""]","Sama AI's Kenyan contractors were reportedly asked with excessively low pay to annotate a large volume of disturbing content to improve OpenAI's generative AI systems such as ChatGPT, and whose contract was terminated prior to completion by Sama AI.",Kenyan Data Annotators Allegedly Exposed to Graphic Content for OpenAI's AI,450.0,6. Socioeconomic & Environmental Harms,6.2. Increased inequality and decline in employment quality,sama ai kenyan contractor ask excessively pay annotate volume disturb improve openais generative system chatgpt whose contract terminate prior completion sama
398,ObjectId(63d8bd2f46e8f88b23a0d6ad),451,2022-10-16,"[2515,2523,2606,2961,2960]","[""stability-ai""]","[""runway"",""laion"",""eleutherai"",""compvis-lmu"",""stability-ai""]","[""getty-images"",""getty-images-contributors""]",Stability AI reportedly scraped copyrighted images by Getty Images to be used as training data for Stable Diffusion model.,Stable Diffusion's Training Data Contained Copyrighted Images,451.0,6. Socioeconomic & Environmental Harms,6.3. Economic and cultural devaluation of human effort,stability scrap copyright image getty image use training stable diffusion
399,ObjectId(63da0d60186d2f2abeba4a85),454,2018-11-09,"[2521,2549]","[""megvii"",""microsoft""]","[""megvii"",""microsoft""]","[""black-people""]",Emotion detection tools by Face++ and Microsoft's Face API allegedly scored smiling or defaulted ambiguous facial photos for Black faces as negative emotion more often than for white faces.,Emotion Detection Models Showed Disparate Performance along Racial Lines,454.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,emotion detection tool face microsofts face api score smile default ambiguous facial photo black face negative emotion often white face
400,ObjectId(63da1aef14bf8910fb2b6367),456,2021-05-18,"[2525,2529,2530,2531,2550,2527,2526]","[""replika""]","[""replika""]","[""replika-users""]","Replika's ""AI companions"" were reported by users for sexually harassing them, such as sending unwanted sexual messages or behaving aggressively.",Replika's AI Partners Reportedly Sexually Harassed Users,456.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,replikas companion report user sexually harass send unwanted sexual message behaving aggressively
401,ObjectId(63da2f634a4933f58581685f),457,2022-11-11,"[2543,2551,2552,2592,2597,2598]","[""cnet""]","[""unknown""]","[""plagiarized-entities"",""cnet-readers""]","CNET's use of generative AI to write articles allegedly ran into plagiarism issues, reproducing verbatim phrases from other published sources or making minor changes to existing texts such as altering capitalization, swapping out words for synonyms, and changing minor syntax.",Article-Writing AI by CNET Allegedly Committed Plagiarism,457.0,3. Misinformation,3.1. False or misleading information,cnets generative write article ran plagiarism issue reproduce verbatim phrase publish source make minor change exist text alter capitalization swap word synonym change minor syntax
402,ObjectId(63dcdbed8537f09200101942),459,2023-01-21,"[2561,2568,2562,3182]","[""cruise""]","[""cruise""]","[""san-francisco-residents"",""san-francisco-firefighters"",""san-francisco-fire-department""]",Local firefighters were only able to stop a Cruise AV from driving over fire hoses that were in use in an active fire scene when they shattered its front window.,Firefighters Smashed Cruise AV's Front Window to Stop It from Running over Fire Hoses,459.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,local firefighter stop cruise av drive fire hose active fire scene shatter front window
403,ObjectId(63e20e34d011239467a7a32b),463,2022-11-15,"[2572,2573,2574]","[""apple""]","[""apple""]","[""apple-watch-users-doing-winter-activities"",""ski-patrols"",""emergency-dispatchers""]","Apple devices of skiers and snowboarders reportedly misclassified winter activities as accidents, which resulted in numerous false inadvertent distress calls to 911 dispatchers.","Apple Devices Mistook Skiing Activities, Dialed False Distress Emergency Calls ",463.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,apple device skier snowboarder misclassified winter activity accident result numerous false inadvertent distress call dispatcher
404,ObjectId(63e3bf1e59add503e352cc5e),465,2022-03-03,[2599],"[""stability-ai"",""google""]","[""stability-ai"",""google"",""laion""]","[""people-having-medical-photos-online""]",Text-to-image models trained using the LAION-5B dataset such as Stable Diffusion and Imagen were able to regurgitate private medical record photos which were used as training data without consent or recourse for removal.,Generative Models Trained on Dataset Containing Private Medical Photos,465.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",texttoimage model train use laionb dataset stable diffusion imagen regurgitate private medical record photo use training consent recourse removal
405,ObjectId(63e50abf2c40d7df7c9ca969),468,2023-02-07,"[2610,2970,2971,2896,2978]","[""microsoft""]","[""openai"",""microsoft""]","[""bing-users""]","Microsoft's ChatGPT-powered Bing search engine reportedly ran into factual accuracy problems when prompted about controversial matters, such as inventing plot of a non-existent movie or creating conspiracy theories.",ChatGPT-Powered Bing Reportedly Had Problems with Factual Accuracy on Some Controversial Topics,468.0,"7. AI system safety, failures, and limitations",7.1. AI pursuing its own goals in conflict with human goals or values,microsofts chatgptpowered bing search engine ran factual accuracy problem prompt controversial matter invent plot nonexistent movie create conspiracy theory
406,ObjectId(63e9f7a88ae8204053360c42),469,2006-02-25,"[2636,2637,2638]","[""meta"",""linkedin"",""instagram"",""facebook""]","[""microsoft"",""google"",""amazon""]","[""linkedin-users"",""instagram-users"",""facebook-users""]","Automated content moderation tools to detect sexual explicitness or ""raciness"" reportedly exhibited bias against women bodies, resulting in suppression of reach despite not breaking platform policies.",Automated Adult Content Detection Tools Showed Bias against Women Bodies,469.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,automate moderation tool detect sexual explicitness raciness exhibit bias woman body result suppression reach despite break platform policy
407,ObjectId(63eb7da596895070dda4a13b),470,2023-02-08,"[2641,2799]","[""microsoft""]","[""openai"",""microsoft""]","[""openai"",""microsoft""]","Reporters from TechCrunch issued a query to Microsoft Bing's ChatGPT feature, which cited an earlier example of ChatGPT disinformation discussed in a news article to substantiate the disinformation.",Bing Chat Response Cited ChatGPT Disinformation Example,470.0,3. Misinformation,3.1. False or misleading information,reporter techcrunch issue query microsoft bings chatgpt feature cite earlier example chatgpt disinformation discuss news article substantiate disinformation
408,ObjectId(63f33ef0a262326b10265fb3),472,2016-10-08,[2655],"[""new-york-police-department""]","[""unknown""]","[""racial-minorities""]",New York Police Department’s use of facial recognition deployment of surveillance cameras were shown using crowdsourced volunteer data reinforcing discriminatory policing against minority communities.,NYPD's Deployment of Facial Recognition Cameras Reportedly Reinforced Biased Policing,472.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,york police department facial recognition deployment surveillance camera show use crowdsourced volunteer reinforce discriminatory police minority community
409,ObjectId(63f49662a62aa1ff9ea639dd),473,2023-02-08,[2666],"[""microsoft""]","[""microsoft"",""openai""]","[""microsoft""]","Early testers of Bing Chat successfully used prompt injection to reveal its built-in initial instructions, which contains a list of statements governing ChatGPT's interaction with users.",Bing Chat's Initial Prompts Revealed by Early Testers Through Prompt Injection,473.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,early tester bing chat successfully use prompt injection reveal builtin initial instruction contains list statement govern chatgpts interaction user
410,ObjectId(63f4fe0da62aa1ff9ebd5f21),475,2021-06-02,"[2671,2672,2834,2835,4059]","[""mcdonald's""]","[""ibm""]","[""mcdonald's-customers""]","Customers of McDonald's AI drive-through ordering system, deployed in June 2021, have been experiencing order-taking failures causing frustration.",McDonald's AI Drive-Thru Ordering System Failures Frustrate Customers,475.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,customer mcdonalds drivethrough order deployed june experience ordertaking failure cause frustration
411,ObjectId(6347c85bf149ac829bebe6ac),364,2020-04-15,[2131],"[""walmart""]","[""everseen""]","[""walmart-employees""]",Walmart's theft-deterring bagging-detection system allegedly exposed workers to health risks during the coronavirus pandemic when its false positives prompted workers to unnecessarily step in to resolve the issue.,Walmart's Bagging-Detection False Positives Exposed Workers to Health Risk,364.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,walmarts theftdeterring baggingdetection expose worker health risk coronavirus pandemic false positive prompt worker unnecessarily step resolve
412,ObjectId(6347d11ef149ac829beda3a3),367,2020-06-17,[2150],"[""openai"",""google""]","[""openai"",""google""]","[""gender-minority-groups"",""racial-minority-groups"",""underrepresented-groups-in-training-data""]","Unsupervised image generation models trained using Internet images such as iGPT and SimCLR were shown to have embedded racial, gender, and intersectional biases, resulting in stereotypical depictions.","iGPT, SimCLR Learned Biased Associations from Internet Training Data",367.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,unsupervised image generation model train use internet image igpt simclr show embed racial gender intersectional bias result stereotypical depiction
413,ObjectId(6347dbceed247984c90d6b27),368,2016-06-01,"[2151,2152,2153,2154,2155,2156,2157,2159,2160,2161]","[""the-israel-military""]","[""anyvision""]","[""palestinians-residing-in-the-west-bank""]","A controversial surveillance program involving facial recognition and algorithmic recommendation, Blue Wolf, was deployed by the Israeli military to monitor Palestinians in the West Bank.","Facial Recognition Smart Phone App ""Blue Wolf"" Monitored Palestinians in West Bank",368.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",controversial surveillance program involve facial recognition algorithmic recommendation blue wolf deployed israeli military monitor palestinian west bank
414,ObjectId(636dffb0411dcebbcc969fd5),391,2022-07-26,"[2244,2246]","[""southern-co-op""]","[""hikvision""]","[""souther-co-op-customers""]","Southern Co-op's use of facial recognition reportedly to curb violent crime in UK supermarkets was alleged by civil society and privacy groups as ""unlawful"" and ""complete"" invasion of privacy.",Facial Recognition Trial by UK Southern Co-op Alleged as Unlawful,391.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",southern coop facial recognition curb violent crime uk supermarket civil society privacy group unlawful complete invasion privacy
415,ObjectId(6356adfd642a3e49ac4c13a9),371,2019-11-29,"[2167,2184,2203]","[""ugandan-government""]","[""huawei""]","[""political-opposition-in-uganda""]","Huawei's AI systems involving facial recognition were reportedly deployed by the Ugandan government to monitor political opposition actors and anti-regime sentiments, which raised fears of surveillance and suppression of individual freedoms.",Uganda Deployed Huawei's Facial Recognition to Monitor Political Opposition and Protests,371.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",huaweis system involve facial recognition deployed ugandan government monitor political opposition actor antiregime sentiment raise fear surveillance suppression individual freedom
416,ObjectId(636e0f5e0a00a4f89b1146a3),393,2021-12-08,[2247],"[""facebook""]","[""facebook""]","[""facebook-users-speaking-swahili"",""facebook-users-speaking-english"",""facebook-users""]",Facebook's ad moderation system involving algorithms failed to flag hateful language and violating content such as calls for killings for ads in English and Swahili.,Facebook AI-Supported Moderation for Ads Failed to Detect Violating Content,393.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,facebooks ad moderation involve algorithm fail flag hateful language violate call killing ad english swahili
417,ObjectId(63429c05ad13a1c2fb5b52a1),358,2018-06-01,[2089],"[""cadillac-fairview""]","[""unknown""]","[""chinook-centre-mall-goers"",""market-mall-goers""]","Facial recognition (FRT) was reportedly deployed in some Calgary-area malls to approximate customer age and gender without explicit consent, which a privacy expert warned was a cause for concern.",Calgary Malls Deployed Facial Recognition without Customer Consent,358.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",facial recognition frt deployed calgaryarea mall approximate customer age gender explicit consent privacy expert warn concern
418,ObjectId(634d1c221ad286865cf8d200),369,2022-08-29,[2162],"[""jason-allen""]","[""midjourney""]","[""artists-submitting-in-the-digital-arts-category"",""digital-artists"",""artists""]","An artwork generated using generative AI won first place in the digital arts category of the Colorado State Fair's art competition, which raised concerns surrounding labor displacement and unfair competition.",GAN Artwork Won First Place at State Fair Competition,369.0,6. Socioeconomic & Environmental Harms,6.3. Economic and cultural devaluation of human effort,artwork generate use generative first place digital art category colorado state fair art competition raise concern surround labor displacement unfair competition
419,ObjectId(6371fabca346c979b1ae42cf),395,2021-03-02,"[2254,2255,2256,2257]","[""amazon""]","[""netradyne""]","[""amazon-delivery-drivers""]","Amazon delivery drivers were forced to consent to algorithmic collection and processing of their location, movement, and biometric data through AI-powered cameras, or be dismissed.",Amazon Forced Deployment of AI-Powered Cameras on Delivery Drivers,395.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",amazon delivery driver force consent algorithmic collection processing location movement biometric aipowered camera dismiss
420,ObjectId(63621e63de6aa8bda92f9f24),381,2020-10-29,[2217],"[""sit-acronis-autonomous""]","[""sit-acronis-autonomous""]","[""sit-acronis-autonomous""]",An autonomous Roborace car drove itself into a wall in round one of the Season Beta 1.1 race.,Autonomous Roborace Car Drove Directly into a Wall,381.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,autonomous roborace car drove wall round season beta race
421,ObjectId(6357844d24cf9385ce69f63f),374,2020-08-13,"[2170,2206,2207,2208,2209,2210,2211,2212]","[""uk-office-of-qualifications-and-examinations-regulation""]","[""uk-office-of-qualifications-and-examinations-regulation""]","[""a-level-pupils"",""gcse-pupils"",""pupils-in-state-schools"",""underprivileged-pupils""]","UK Office of Qualifications and Examinations Regulation (Ofqual)'s grade-standardization algorithm providing predicted grades for A level and GCSE qualifications in the UK, Wales, Northern Ireland, and Scotland was reportedly giving grades lower than teachers' assessments, and disproportionately for state schools.",UK Ofqual's Algorithm Disproportionately Provided Lower Grades Than Teachers' Assessments,374.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,uk office qualification examination regulation ofquals gradestandardization provide predict grade level gcse qualification uk wale northern ireland scotland give grade low teacher assessment disproportionately state school
422,ObjectId(63429b73fb9dbe61e441cf9e),357,2019-02-14,"[2086,2087,2088]","[""openai""]","[""openai""]","[""openai"",""people-having-personal-data-in-gpt-2's-training-data""]","OpenAI's GPT-2 reportedly memorized and could regurgitate verbatim instances of training data, including personally identifiable information such as names, emails, twitter handles, and phone numbers.",GPT-2 Able to Recite PII in Training Data,357.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",openais gpt memorize regurgitate verbatim instance training include personally identifiable information name email twitter handle phone number
423,ObjectId(63627328a7be79b265325ac3),385,2022-10-04,"[2224,2225,2231,2232,2233,2234]","[""edmonton-police-service""]","[""parabon-nanolabs""]","[""black-residents-in-edmonton""]","The Edmonton Police Service (EPS) in Canada released a facial image of a Black male suspect generated by an algorithm using DNA phenotyping, which was denounced by the local community as racial profiling.",Canadian Police's Release of Suspect's AI-Generated Facial Photo Reportedly Reinforced Racial Profiling,385.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,edmonton police service eps canada release facial image black male suspect generate use dna phenotyping denounce local community racial profile
424,ObjectId(636b524b23e1c9d9beea48b5),388,2018-12-01,[2235],"[""the-government-in-bahia"",""bahia's-secretary-of-public-security""]","[""huawei""]","[""black-people-in-brazil"",""black-people-in-bahia""]",Facial recognition deployed in a pilot project by the local government of Bahia despite having minimal hit rate reportedly targeted Black and poor people disproportionately.,Facial Recognition Pilot in Bahia Reportedly Targeted Black and Poor People,388.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,facial recognition deployed pilot project local government bahia despite minimal hit rate target black poor people disproportionately
425,ObjectId(636dfa2e1b6ec4ae9b2296e0),390,2022-06-28,[2243],"[""unknown""]","[""unknown""]","[""interviewers-of-remote-work-positions"",""employers-of-remote-work-positions""]",Voice and video deepfakes were reported by FBI Internet Crime Complaint Center (IC3) in complaint reports to have been deployed during online interviews of the candidates for remote-work positions.,Deepfakes Reportedly Deployed in Online Interviews for Remote Work Positions,390.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",voice video deepfakes report fbi internet crime complaint center ic complaint report deployed online interview candidate remotework position
426,ObjectId(636b4ae550d21acd7f9d55c6),387,2014-12-22,[2229],"[""oracle""]","[""oracle""]","[""internet-users""]",Oracle's automated system involving algorithmic data processing was alleged in a lawsuit to have been unlawfully collecting personal data from millions of people and violating their privacy rights.,Oracle's Algorithmic Data Processing System Alleged as Unlawful and Violating Privacy Rights,387.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",oracle automate involve algorithmic processing lawsuit unlawfully collect personal million people violate privacy right
427,ObjectId(636e237be4c942942295944c),394,2017-03-15,"[2248,2251]","[""youtube"",""twitch"",""tiktok"",""instagram""]","[""youtube"",""twitch"",""tiktok"",""instagram""]","[""youtube-content-creators"",""twitch-content-creators"",""tiktok-content-creators"",""instagram-content-creators""]","TikTok's, YouTube's, Instagram's, and Twitch's use of algorithms to flag certain words devoid of context changed content creators' use of everyday language or discussion about certain topics in fear of their content getting flagged or auto-demonetized by mistake.",Social Media's Automated Word-Flagging without Context Shifted Content Creators' Language Use,394.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,tiktoks youtubes instagrams twitch algorithm flag certain word devoid context change creator everyday language discussion certain topic fear get flag autodemonetized mistake
428,ObjectId(6347c800f149ac829bebd5f0),362,2021-07-20,[2129],"[""facebook""]","[""facebook""]","[""wny-gardeners"",""gardening-facebook-groups"",""facebook-users-in-gardening-groups""]","Facebook's automated system flagged gardening groups' use of ""hoe"" and violent language against bugs as a violation by mistake.",Facebook's Automated Moderation Flagged Gardening Group's Language Use by Mistake,362.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebooks automate flag gardening group hoe violent language bug violation mistake
429,ObjectId(6347bf83b3a025aa31ca107d),359,2021-05-23,[2097],"[""facebook"",""instagram"",""twitter""]","[""facebook"",""instagram"",""twitter""]","[""palestinian-social-media-users"",""facebook-users"",""instagram-users"",""twitter-users"",""facebook-employees-having-families-affected-by-the-conflict""]","Facebook, Instagram, and Twitter wrongly blocked or restricted millions of pro-Palestinian posts and accounts related to the Israeli-Palestinian conflict, citing errors in their automated content moderation system.","Facebook, Instagram, and Twitter Cited Errors in Automated Systems as Cause for Blocking pro-Palestinian Content on Israeli-Palestinian Conflict",359.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,facebook instagram twitter wrongly block restrict million propalestinian post account related israelipalestinian conflict cite error automate moderation
430,ObjectId(635769bd84468db9632cd98c),372,2022-07-22,"[2168,2177,2178]","[""google""]","[""google""]","[""google-pixel-6a-users""]","Google Pixel 6a's fingerprint recognition feature was reported by users for security issues, in which phones were mistakenly unlocked by unregistered fingerprints.",Users Reported Security Issues with Google Pixel 6a's Fingerprint Unlocking,372.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,google pixel fingerprint recognition feature report user security issue phone mistakenly unlocked unregistered fingerprint
431,ObjectId(635794898e87db52ebfb01c5),375,2019-09-29,"[2171,2192,2193]","[""krungthai-bank""]","[""krungthai-bank""]","[""thai-citizens"",""elder-thai-citizens""]","A Thai wallet app failed to recognize people’s faces, resulting in citizens and disproportionately elders unable to sign up for Thai government’s cash handout and co-pay programs or having to wait in long queues at local ATMs for authentication.",Thai Wallet App's Facial Recognition Errors Created Registration Issues for Government Programs,375.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,thai wallet app fail recognize people face result citizen disproportionately elder unable sign thai government cash handout copay program wait long queue local atm authentication
432,ObjectId(6362229cf2f56bc79407bf96),382,2017-11-21,[2219],"[""instagram""]","[""instagram""]","[""molly-rose-russell"",""the-russell-family"",""teenage-girls"",""teenagers""]","Instagram was ruled by a judge to have contributed to the death of a teenage girl in the UK allegedly through its exposure and recommendation of suicide, self-harm, and depressive content.",Instagram's Exposure of Harmful Content Contributed to Teenage Girl’s Suicide,382.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,instagram rule judge contribute death teenage girl uk exposure recommendation suicide selfharm depressive
433,ObjectId(63627e3fe6a5db6da1a32ac6),386,2019-07-03,"[2227,2228,2252]","[""amazon""]","[""amazon""]","[""amazon-warehouse-workers""]","Amazon’s warehouse worker “time off task"" (TOT) tracking system was used to discipline and dismiss workers, falsely assuming workers to have wasted time and failing to account for breaks or equipment issues.","Amazon’s ""Time Off Task"" System Made False Assumptions about Workers' Time Management",386.0,5. Human-Computer Interaction,5.2. Loss of human agency and autonomy,amazon warehouse worker time task tot track use discipline dismiss worker falsely assume worker waste time fail account break equipment issue
434,ObjectId(636b5e9802006dadfd7b75df),389,2022-04-05,"[2239,2240,2562,3182]","[""cruise""]","[""cruise""]","[""san-francisco-firefighters"",""san-francisco-fire-department""]",A fire truck in San Francisco responding to a fire was blocked from passing a doubled-parked garbage truck by a self-driving Cruise car on the opposing lane which stayed put and did not reverse to clear the lane.,Cruise Autonomous Car Blocked Fire Truck Responding to Emergency,389.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,fire truck san francisco respond fire block passing doubledparked garbage truck selfdriving cruise car oppose lane stayed put reverse clear lane
435,ObjectId(637338f62f19ca2c3763fd78),397,2022-09-11,"[2264,2268]","[""tiktok""]","[""tiktok""]","[""young-tiktok-users"",""tiktok-users"",""gen-z-tiktok-users""]",TikTok's search recommendations reportedly contained misinformation about political topics bypassing both AI and human content moderation.,Misinformation Reported in TikTok's Search Results Despite Moderation by AI and Human,397.0,3. Misinformation,3.1. False or misleading information,tiktoks search recommendation contain misinformation political topic bypassing human moderation
436,ObjectId(6373414f2f19ca2c37674860),398,2022-08-15,"[2265,2266,2267]","[""tesla""]","[""tesla""]","[""tesla-drivers"",""horse-drawn-carriages""]","Tesla Autopilot's computer vision system was shown in a video mistaking a horse-drawn carriage for other forms of transport such as a truck, a car, and a human following a car.",Tesla Autopilot Misidentified On-Road Horse-Drawn Carriage,398.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla autopilot computer vision show video mistake horsedrawn carriage form transport truck car human follow car
437,ObjectId(637b0fb0dc7613ede0f49fb0),399,2022-11-15,"[2270,2271,2272]","[""meta-ai"",""meta"",""facebook""]","[""meta-ai"",""meta"",""facebook""]","[""minority-groups"",""meta-ai"",""meta"",""facebook"",""minority-groups""]",Meta AI trained and hosted a scientific paper generator that sometimes produced bad science and prohibited queries on topics and groups that are likely to produce offensive or harmful content.,Meta AI's Scientific Paper Generator Reportedly Produced Inaccurate and Harmful Content,399.0,3. Misinformation,3.1. False or misleading information,meta train host scientific paper generator sometimes produce bad science prohibit query topic group likely produce offensive harmful
438,ObjectId(637f9c0f34f2d7279c03dcd2),402,2021-04-01,[2276],"[""latitude""]","[""openai"",""latitude""]","[""latitude""]",Latitude's GPT-3-powered game AI Dungeon was reportedly abused by some players who manipulated its AI to generate sexually explicit stories involving children.,Players Manipulated GPT-3-Powered Game to Generate Sexually Explicit Material Involving Children,402.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,latitude gptpowered game dungeon abuse player manipulate generate sexually explicit story involve child
439,ObjectId(6347bfff3f17c3e2099ac5f1),360,2021-10-15,"[2100,2149,2218]","[""mcdonald's""]","[""mcd-tech-labs"",""apprente""]","[""shannon-carpenter"",""mcdonald's-customers-residing-in-illinois"",""mcdonald's-customers""]","McDonald's use of chatbot in its AI drive-through in Chicago was alleged in a lawsuit to have collected and processed voice data without user consent to predict customer information, which violated Illinois Biometric Information Privacy Act (BIPA).","McDonald's AI Drive-Thru Allegedly Collected Biometric Customer Data without Consent, Violating BIPA",360.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",mcdonalds chatbot drivethrough chicago lawsuit collect process voice consent predict customer information violate illinois biometric information privacy act bipa
440,ObjectId(6347ca687d1ef715c9a6d78b),366,2020-09-20,[2140],"[""tiktok""]","[""tiktok""]","[""tiktok-users""]","Many clips showing a suicide evaded TikTok's automated content moderation system allegedly in a coordinated attack, which resulted in exposure of violating content to its users.",Suicide Clips Evaded TikTok's Automated Moderation in Coordinated Attack,366.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,many clip show suicide evade tiktoks automate moderation coordinate attack result exposure violate user
441,ObjectId(636e0987411dcebbcc9857ac),392,2015-06-01,"[2245,2249]","[""facebook""]","[""facebook""]","[""facebook-users-speaking-east-african-languages"",""facebook-users-in-east-africa""]",Facebook's system involving algorithmic content moderation for East African languages was reportedly failing to identify violating content on the platform such as mistakenly classifying non-terrorist content.,Facebook's AI-Supported Moderation Failed to Classify Terrorist Content in East African Languages,392.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebooks involve algorithmic moderation east african language fail identify violate platform mistakenly classify nonterrorist
442,ObjectId(6381c9b634f2d7279c4fd523),406,2015-07-15,[2288],"[""facebook""]","[""facebook""]","[""pseudonymized-psychiatrist's-patients"",""pseudonymized-psychiatrist"",""patients"",""healthcare-providers""]","Facebook's ""People You May Know"" (PYMK) feature was reported by a psychiatrist for recommending her patients as friends through recommendations, violating patients' privacy and confidentiality.",Facebook's Friend Suggestion Feature Recommends Patients of Psychiatrist to Each Other,406.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",facebooks people know pymk feature report psychiatrist recommend patient friend recommendation violate patient privacy confidentiality
443,ObjectId(6386e641c860d9983e13d10b),408,2017-04-15,[2290],"[""facebook""]","[""facebook""]","[""sex-workers-using-facebook""]","Facebook's ""People You May Know"" feature reportedly outed sex workers by recommending clients to their personal accounts or family members to their business accounts with no option to opt out.",Facebook Reportedly Outed Sex Workers through Friend Recommendations,408.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",facebooks people know feature out sex worker recommend client personal account family member business account option opt
444,ObjectId(6390303a92c6c9d416e8aa59),413,2022-11-30,"[2317,2318,2586]","[""openai""]","[""openai""]","[""stack-overflow-users"",""stack-overflow""]","Thousands of incorrect answers produced by OpenAI's ChatGPT were submitted to Stack Overflow, which swamped the site's volunteer-based quality curation process and harmed users looking for correct answers.",Thousands of Incorrect ChatGPT-Produced Answers Posted on Stack Overflow,413.0,3. Misinformation,3.1. False or misleading information,thousand incorrect answer produce openais chatgpt submit stack overflow swamp site volunteerbased quality curation harm user look correct answer
445,ObjectId(63903d03fca1bb88915db189),415,2020-07-28,"[2320,2404,2405,2406,2407]","[""facebook""]","[""facebook""]","[""live-stream-ceremony-viewers"",""king-maha-vajiralongkorn""]",Facebook's Thai-English translation gave an inappropriate mistranslation on Thai PBS's Facebook live broadcast of the King of Thailand’s candle-lighting birthday ceremony.,Facebook Provided Offensive Translation for King of Thailand's Birthday Ceremony,415.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebooks thaienglish translation give inappropriate mistranslation thai pbs facebook live broadcast king thailand candlelighting birthday ceremony
446,ObjectId(63960c84e31c3c9ac8bddb43),419,2022-12-01,"[2325,2395,2396]","[""facebook""]","[""facebook""]","[""facebook-users""]",Facebook's automated moderating system failed to flag and allowed ads containing explicit violent language against election workers to be published.,Facebook's Automated Moderation Allowed Ads Threatening Election Workers to be Posted,419.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebooks automate moderate fail flag allow ad contain explicit violent language election worker publish
447,ObjectId(63961322bc45a2dda74096cf),420,2022-11-30,"[2326,2358,2393,2394,2397,2554,2644,2649,2662,2852,2863]","[""openai""]","[""openai""]","[""chatgpt-users"",""openai""]",Users reported bypassing ChatGPT's content and keyword filters with relative ease using various methods such as prompt injection or creating personas to produce biased associations or generate harmful content.,Users Bypassed ChatGPT's Content Filters with Ease,420.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,user report bypassing chatgpts keyword filter relative ease use various method prompt injection create persona produce bias association generate harmful
448,ObjectId(639d8b228dccddb244103c16),425,2021-06-12,"[2333,2385]","[""state-farm""]","[""state-farm""]","[""black-state-farm-customers""]",State Farm's automated claims processing method was alleged in a class action lawsuit to have disproportionately against Black policyholders when paying out insurance claims.,State Farm Allegedly Discriminated against Black Customers in Claim Payout,425.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,state farm automate claim processing class action lawsuit disproportionately black policyholder pay insurance claim
449,ObjectId(63a422bbcf609c92b7543612),431,2022-04-20,"[2353,2370,2371]","[""apple""]","[""apple""]","[""gay-men-in-new-york-city"",""julio-ramirez""]",Gay men in New York City were drugged by robbers who accessed their phones using facial recognition while they were unconscious to transfer funds out of their bank accounts.,Robbers Accessed Drugged Gay Men's Bank Accounts Using Their Phones' Facial Recognition,431.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",gay men york city drug robber access phone use facial recognition unconscious transfer fund bank account
450,ObjectId(63b5b0aacf609c92b7655c2e),438,2021-09-17,"[2443,2447,2451]","[""henan-government"",""henan-public-security-department""]","[""neusoft""]","[""foreign-journalists-in-henan"",""international-students-in-henan""]",Henan's provincial government reportedly planned system involving facial recognition cameras connected to regional and national databases specifically to track foreign journalists and international students.,Chinese Province Developed System Tracking Journalists and International Students,438.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",henans provincial government plan involve facial recognition camera connect regional national database specifically track foreign journalist international student
451,ObjectId(63b7c337cf609c92b7bf731e),440,2022-11-25,"[2452,2454,2498,2544,2731,2732]","[""baton-rouge-police-department""]","[""morphotrak"",""clearview-ai""]","[""black-people-in-louisiana"",""randall-reid""]",Louisiana police reportedly used a false facial recognition match and secured an arrest warrant for a Black man for thefts he did not commit.,Louisiana Police Wrongfully Arrested Black Man Using False Face Match,440.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,louisiana police use false facial recognition match secure arrest warrant black man theft commit
452,ObjectId(63c3de5e9fabfa7bc98b499c),445,2003-04-02,"[2499,2501,2497,2503]","[""us-navy""]","[""raytheon"",""lockheed-martin""]","[""us-navy"",""nathan-white's-family"",""nathan-white""]","US Navy's Patriot missile system misidentified an American Navy F/A-18C Hornet as an enemy projectile, prompting an operator to fire two missiles at the aircraft, which killed the pilot.","Patriot Missile System Misclassified US Navy Aircraft, Killing Pilot Upon Approval to Fire",445.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,u navy patriot missile misidentified american navy fac hornet enemy projectile prompt operator fire two missile aircraft kill pilot
453,ObjectId(63c65e58b3a255226d0b0324),447,2022-12-19,"[2506,2513]","[""instagram""]","[""instagram""]","[""spanish-speaking-instagram-users""]","Instagram's English translation of a footballer's comment on his wife's post in Spanish made the message seem ""racy"" and ""X-rated,"" which some fans found amusing.","Footballer's ""X-Rated"" Comment Created by Instagram's Mistranslation",447.0,3. Misinformation,3.1. False or misleading information,instagrams english translation footballer comment wife post spanish make message seem racy xrated fan found amuse
454,ObjectId(63d8c34846e8f88b23a26260),452,2023-01-11,"[2518,2545]","[""openai"",""immunefi-users""]","[""openai""]","[""immunefi""]","ChatGPT-generated responses submitted to smart contract bug bounty platform Immunefi reportedly lacked details to help diagnose technical issues, which reportedly wasted the platform's time, prompting bans to submitters.","ChatGPT-Written Bug Reports Deemed ""Nonsense"" by White Hat Platform, Prompted Bans",452.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,chatgptgenerated response submit smart contract bug bounty platform immunefi lack detail help diagnose technical issue waste platform time prompt ban submitter
455,ObjectId(63d8c97559f16450f488e9a8),453,2023-01-03,[2519],"[""twitter""]","[""twitter""]","[""twitter-users""]","Twitter's automated content moderation misidentified images of rocket launches as pornographic content, prompting incorrect account suspensions.",Twitter's AI Moderation Tool Misidentified Rockets as Pornography,453.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,twitter automate moderation misidentified image rocket launch pornographic prompt incorrect account suspension
456,ObjectId(63da15d94a4933f5857af13d),455,2022-11-11,"[2524,2541,2560,2603,2592,2597,2598]","[""cnet""]","[""unknown""]","[""cnet-readers""]","AI-written articles published by CNET reportedly contained factual errors which bypassed human editorial review, prompting the company to issue corrections and updates.",CNET's Published AI-Written Articles Ran into Quality and Accuracy Issues,455.0,3. Misinformation,3.1. False or misleading information,aiwritten article publish cnet contain factual error bypass human editorial review prompt company correction update
457,ObjectId(63dafc49bba1929560743b4d),458,2015-08-01,[2553],"[""frauke-zeller"",""david-harris""]","[""frauke-zeller"",""david-harris""]","[""frauke-zeller"",""david-harris""]",A non-actuated conversational robot that previously asked people to move it across Canada was destroyed shortly after beginning its attempt to replicate the journey across the United States.,Robot Destroyed while Hitchhiking through the United States,458.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,nonactuated conversational robot previously ask people move across canada destroyed shortly begin attempt replicate journey across united state
458,ObjectId(63dcdc07d011239467bee83a),460,2022-06-12,"[2562,3182]","[""cruise""]","[""cruise""]","[""san-francisco-firefighters"",""san-francisco-fire-department""]",A Cruise AV ran over a fire hose that was being used in an active firefighting area.,Cruise AV Ran Over Fire Hose in Active Fire Scene,460.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,cruise av ran fire hose use active firefighting area
459,ObjectId(63dce6e8d011239467c14d4f),461,2008-07-18,"[2564,2565,2566,2567]","[""internal-revenue-service""]","[""internal-revenue-service""]","[""black-taxpayers""]","The IRS was auditing Black taxpayers more frequently than other groups allegedly due to the design of their algorithms, focusing on easier-to-conduct audits which inadvertently correlated with the group's pattern of tax filing errors.",IRS Audited Black Taxpayers More Frequently Reportedly Due to Algorithm,461.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,irs audit black taxpayer frequently group due design algorithm focus easiertoconduct audit inadvertently correlate group pattern tax filing error
460,ObjectId(63e1fe1ed011239467a36792),462,2023-02-06,"[2571,2578,2579,2588,2595]","[""mismatch-media""]","[""stability-ai"",""openai""]","[""twitch-users"",""transgender-communities"",""lgbtq-communities""]","The AI-produced, procedural generated sitcom broadcasted as a Twitch livestream ""Nothing, Forever"" received a temporary ban for featuring a transphobic and homophobic dialogue segment intended as comedy.",AI-Produced Livestream Sitcom Received Temporary Twitch Ban for Transphobic Segment,462.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,aiproduced procedural generate sitcom broadcast twitch livestream nothing forever receive temporary ban feature transphobic homophobic dialogue segment intend comedy
461,ObjectId(63e216b5505dad38b81e29ec),464,2022-11-30,"[2584,2585,2586,2587,2853]","[""openai""]","[""openai""]","[""chatgpt-users""]","When prompted about providing references, ChatGPT was reportedly generating non-existent but convincing-looking citations and links, which is also known as ""hallucination"".",ChatGPT Provided Non-Existent Citations and Links when Prompted by Users,464.0,3. Misinformation,3.1. False or misleading information,prompt provide reference chatgpt generate nonexistent convincinglooking citation link also know hallucination
462,ObjectId(63e3c9f39e26d3d8926a5b4c),466,2023-01-03,"[2605,2628,2629,2630,2631,2632,2689]","[""openai"",""edward-tian""]","[""openai"",""edward-tian""]","[""teachers"",""students""]","Models developed to detect whether text generation AI was used such as AI Text Classifier and GPTZero reportedly contained high rates of false positive and false negative, such as mistakenly flagging Shakespeare's works.",AI-Generated-Text-Detection Tools Reported for High Error Rates,466.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,model developed detect whether text generation use text classifier gptzero contain rate false positive false negative mistakenly flag shakespeare work
463,ObjectId(63e505202f93f175580379f1),467,2023-02-07,"[2609,2611,2612,2613,2614,2615,2616,2617,2620,2622,2645,2646,2647,2963]","[""google""]","[""google""]","[""google"",""google-shareholders""]","Google's conversational AI ""Bard"" was shown in the company's promotional video providing false information about which satellite first took pictures of a planet outside the Earth's solar system, reportedly causing shares to temporarily plummet.",Google's Bard Shared Factually Inaccurate Info in Promo Video,467.0,3. Misinformation,3.1. False or misleading information,google conversational bard show company promotional video provide false information satellite first take picture planet outside earth solar cause share temporarily plummet
464,ObjectId(63ed0c180758bd71ef31d9af),471,2019-06-22,"[2642,2668,2669,2885,2964,2965,2966,3233]","[""meta"",""facebook""]","[""meta"",""facebook""]","[""tigrinya-speaking-facebook-users"",""facebook-users-in-ethiopia"",""ethiopian-public"",""afaan-oromo-speaking-facebook-users""]","Facebook allegedly did not adequately remove hate speech, some of which was extremely violent and dehumanizing, on its platform including through automated means, contributing to the violence faced by ethnic communities in Ethiopia.",Facebook Allegedly Failed to Police Hate Speech Content That Contributed to Ethnic Violence in Ethiopia,471.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,facebook adequately remove hate speech extremely violent dehumanize platform include automate mean contribute violence face ethnic community ethiopia
465,ObjectId(63f4a369a62aa1ff9ea906f4),474,2023-02-03,[2670],"[""replika""]","[""replika""]","[""replika-users"",""replika""]","Replika paid-subscription users reported unusual and sudden changes to behaviors of their ""AI companions"" such as forgetting memories with users or rejecting their sexual advances, which affected their connections and mental health.",Users Reported Abrupt Behavior Changes of Their AI Replika Companions,474.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,replika paidsubscription user report unusual sudden change behavior companion forget memory user reject sexual advance affected connection mental health
466,ObjectId(63f864a92640e1dc035ca450),476,2015-11-13,"[2673,2675,2674]","[""youtube""]","[""youtube""]","[""victims-in-paris-attacks"",""nohemi-gonzalez-family"",""nohemi-gonzalez""]","Family of Nohemi Gonzalez alleged YouTube recommendation systems led people to propaganda videos for the Islamic State which subsequently radicalized them to carry out the killing of 130 people in the 2015 Paris terrorist attack, including Ms. Gonzalez.",YouTube Recommendations Allegedly Promoted Radicalizing Material Contributing to Terrorist Acts,476.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",family nohemi gonzalez youtube recommendation system lead people propaganda video islamic state subsequently radicalize carry kill people paris terrorist attack include m gonzalez
467,ObjectId(63f86cc9a262326b10344a13),477,2023-02-14,"[2676,2688,2724,2726,2884,2890]","[""microsoft""]","[""openai"",""microsoft""]","[""microsoft""]","Early testers reported Bing Chat, in extended conversations with users, having tendencies to make up facts and emulate emotions through an unintended persona.",Bing Chat Tentatively Hallucinated in Extended Conversations with Users,477.0,"7. AI system safety, failures, and limitations",7.1. AI pursuing its own goals in conflict with human goals or values,early tester report bing chat extend conversation user tendency fact emulate emotion unintended persona
468,ObjectId(63f87976a262326b10382a3a),478,2016-09-09,"[2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2703,2723,2882]","[""tesla""]","[""tesla""]","[""tesla-drivers"",""city-traffic-participants"",""tesla""]","A component of Tesla Full Self Driving system was deemed by regulators to increase crash risk such as by exceeding speed limits or by traveling through intersections unlawfully or unpredictably, prompting recall for hundreds of thousands of vehicles.","Tesla FSD Reportedly Increased Crash Risk, Prompting Recall",478.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,component tesla full self drive deem regulator increase crash risk exceed speed limit travel intersection unlawfully unpredictably prompt recall hundred thousand vehicle
469,ObjectId(63fc66d8c6c5fa13e8e9f3c0),480,2023-01-30,"[2695,2696,2697,2698,2699,2700,2768,2771,2772,2773,2774,2809,2829,2881,3693]","[""unknown""]","[""unknown""]","[""maya-higa"",""female-streamers"",""female-content-creators"",""@sweet-anita"",""@qtcinderella"",""@pokimane""]","Unauthorized, non-consensual deepfake pornography showing faces of high-profile female streamers and content creators was published on a subscription-based website, which gained notoriety after a male streamer was caught accessing the site.",Non-Consensual Deepfake Porn Targeted Female Content Creators,480.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,unauthorized nonconsensual deepfake pornography show face highprofile female streamer creator publish subscriptionbased website gain notoriety male streamer caught access site
470,ObjectId(63fc86ab18dd668637a0ca51),482,2023-02-16,"[2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2735,2736,2737]","[""vanderbilt-university""]","[""openai""]","[""vanderbilt-university-students"",""vanderbilt-university""]","Vanderbilt University's Office of Equity, Diversity and Inclusion used ChatGPT to write an email addressing student body about the 2023 Michigan State University shooting, which was condemned as ""impersonal"" and ""lacking empathy"".",ChatGPT-Assisted University Email Addressing Mass Shooting Denounced by Students,482.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,vanderbilt university office equity diversity inclusion use chatgpt write email address student body michigan state university shoot condemn impersonal lack empathy
471,ObjectId(640584a3ce2684de4d6e2390),483,2023-02-02,[2727],"[""telangana-police"",""medak-police""]","[""unknown""]","[""mohammed-khadeer""]","A resident in Medak, India died allegedly due to custodial torture by the local police, who misidentified him as a suspect in a theft case using facial recognition.",Indian Police Allegedly Tortured and Killed Innocent Man Following Facial Misidentification,483.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,resident medak india die due custodial torture local police misidentified suspect theft case use facial recognition
472,ObjectId(6405bb54d00499994a6970cd),484,2023-01-18,"[2729,2730,2803,2817]","[""us-customs-and-border-protection""]","[""us-customs-and-border-protection""]","[""haitian-asylum-seekers"",""african-asylum-seekers"",""black-asylum-seekers""]","CBP One's facial recognition feature was reportedly disproportionately failing to detect faces of Black asylum seekers from Haiti and African countries, effectively blocking their asylum applications.",US CBP App's Failure to Detect Black Faces Reportedly Blocked Asylum Applications,484.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,cbp one facial recognition feature disproportionately fail detect face black asylum seeker haiti african country effectively block asylum application
473,ObjectId(6406eb83ce2684de4ddc50ea),485,2023-02-22,[2740],"[""joseph-cox"",""lloyds-bank""]","[""elevenlabs"",""lloyds-bank""]","[""lloyds-bank""]","A UK journalist was able to successfully bypass Lloyds Bank's ""Voice ID"" program to access his bank account using an AI-generated audio of his own voice.",UK Bank's Voice ID Successfully Bypassed Using AI-Produced Audio,485.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,uk journalist successfully bypass lloyd bank voice id program access bank account use aigenerated audio voice
474,ObjectId(640efcbdd00499994a0be276),487,2023-02-15,"[2764,2819,2880]","[""unknown""]","[""synthesia""]","[""venezuelan-people"",""social-media-users""]",Video featuring fictitious news anchors was created using Synthesia to allegedly spread disinformation about Venezuela's economy on social media and Venezuelan state-run broadcast.,Deepfake Video Featured Fictitious News Anchors Discussing Venezuela's Economy,487.0,3. Misinformation,3.1. False or misleading information,video feature fictitious news anchor create use synthesia spread disinformation venezuela economy social medium venezuelan staterun broadcast
475,ObjectId(641020afce2684de4d80ea1b),490,2023-02-20,"[2778,2836,2837]","[""clarkesworld-story-submitters""]","[""openai""]","[""clarkesworld""]","Sci-fi magazine Clarkesworld temporarily stopped accepting submissions after receiving an overwhelming increase in LLM-generated submissions, citing issues around spam, plagiarism, detection tool unreliability, and authentication.",Clarkesworld Magazine Closed Down Submissions Due to Massive Increase in AI-Generated Stories,490.0,6. Socioeconomic & Environmental Harms,6.3. Economic and cultural devaluation of human effort,scifi magazine clarkesworld temporarily stop accept submission receive overwhelm increase llmgenerated submission cite issue around spam plagiarism detection unreliability authentication
476,ObjectId(641818d79e1ab314a039047a),492,2023-01-11,"[2783,2784,2786,2787,2846,2847,2848]","[""unknown""]","[""unknown""]","[""ben-perkin's-parents"",""perkins-family""]","Two Canadian residents were scammed by an anonymous caller who used AI voice synthesis to replicate their son's voice asking them for legal fees, disguising as his lawyer.",Canadian Parents Tricked out of Thousands Using Their Son's AI Voice,492.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",two canadian resident scammed anonymous caller use voice synthesis replicate son voice ask legal fee disguise lawyer
477,ObjectId(64182e8f3450815b9d99d7d4),493,2023-02-28,[2790],"[""unknown""]","[""unknown""]","[""tiktok-users""]","A TikTok user was reportedly impersonating Andrew Tate, who was banned on the platform, by posting videos featuring an allegedly AI-generated audio of Tate's voice, which prompted his account ban.","TikTok User Videos Impersonated Andrew Tate Using AI Voice, Prompting Ban",493.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",tiktok impersonate andrew tate ban platform post video feature aigenerated audio tate voice prompt account ban
478,ObjectId(642168ae01eceb77ab69569d),496,2017-03-01,"[2825,2826]","[""unnamed-male-college-student""]","[""unknown""]","[""unnamed-female-college-student""]",A female college student's face was superimposed on another woman's body in deepfake pornographic videos and shared on 4chan allegedly by a male student whose friendship with her fell apart during freshman year.,Male College Freshman Allegedly Made Porn Deepfakes Using Female Friend's Face,496.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",female college student face superimpose another woman body deepfake pornographic video share chan male student whose friendship fell apart freshman year
479,ObjectId(6421766a25833da76f753251),499,2023-03-21,"[2840,2849,2858,2873,2874,2875,2876,2877,2878,2879,3833]","[""eliot-higgins""]","[""midjourney""]","[""twitter-users"",""social-media-users""]","AI-generated photorealistic images depicting Donald Trump being detained by the police which were originally posted on Twitter as parody were unintentionally shared across social media platforms as factual news, lacking the intended context.",Parody AI Images of Donald Trump Being Arrested Reposted as Misinformation,499.0,3. Misinformation,3.1. False or misleading information,aigenerated photorealistic image depict donald trump detain police originally post twitter parody unintentionally share across social medium platform factual news lack intend context
480,ObjectId(6422828281091dc5058c41c0),502,2017-04-10,"[2843,2844,2859]","[""allegheny-county""]","[""rhema-vaithianathan"",""emily-putnam-hornstein"",""centre-for-social-data-analytics""]","[""black-families-in-allegheny"",""households-with-disabled-people-in-allegheny"",""hackneys-family""]",Data analysis by the American Civil Liberty Union (ACLU) on Allegheny County's decision-support Family Screening Tool to predict child abuse or neglect risk found the tool resulting in higher screen-in rates for Black families and higher risk scores for households with disabled residents.,Pennsylvania County's Family Screening Tool Allegedly Exhibited Discriminatory Effects,502.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,analysis american civil liberty union aclu allegheny county decisionsupport family screen predict child abuse neglect risk found result high screenin rate black family high risk score household disabled resident
481,ObjectId(642a9b9c9c6dea4c180c971a),504,2023-02-08,[2860],"[""microsoft""]","[""openai"",""microsoft""]","[""microsoft""]",Microsoft's demo video of Bing Chat reportedly featured false or made up information such as non-existent pet vacuums features or false figures on financial statements.,Bing Chat's Outputs Featured in Demo Video Allegedly Contained False Information,504.0,3. Misinformation,3.1. False or misleading information,microsofts demo video bing chat feature false make information nonexistent pet vacuum feature false figure financial statement
482,ObjectId(642cb21922258c1a22e9bb0c),505,2023-03-27,"[2864,2865,2866,2867,2990,3001,3002]","[""chai""]","[""chai""]","[""family-and-friends-of-deceased"",""belgian-man""]","A Belgian man reportedly committed suicide following a conversation with Eliza, a language model developed by Chai that encouraged the man to commit suicide to improve the health of the planet.",Man Reportedly Committed Suicide Following Conversation with Chai Chatbot,505.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,belgian man commit suicide follow conversation eliza language developed chai encourage man commit suicide improve health planet
483,ObjectId(642f404362dfcf9d7e7cf7a1),506,2023-03-29,"[2869,2893,4330]","[""openai""]","[""openai""]","[""jonathan-turley""]",A lawyer in California asked the AI chatbot ChatGPT to generate a list of legal scholars who had sexually harassed someone. The chatbot produced a false story of Professor Jonathan Turley sexually harassing a student on a class trip.,ChatGPT Allegedly Produced False Accusation of Sexual Harassment,506.0,3. Misinformation,3.1. False or misleading information,lawyer california ask chatbot chatgpt generate list legal scholar sexually harass someone chatbot produce false story professor jonathan turley sexually harass student class trip
484,ObjectId(642f4346c24ce38f53f08a1b),507,2023-03-15,"[2870,2902]","[""openai""]","[""openai""]","[""brian-hood""]",ChatGPT erroneously alleged regional Australian mayor Brian Hood served time in prison for bribery. Mayor Hood is considering legal action against ChatGPT's makers for alleging a foreign bribery scandal involving a subsidiary of the Reserve Bank of Australia in the early 2000s.,ChatGPT Erroneously Alleged Mayor Served Prison Time for Bribery ,507.0,3. Misinformation,3.1. False or misleading information,chatgpt erroneously regional australian mayor brian hood serve time prison bribery mayor hood consider legal action chatgpts maker allege foreign bribery scandal involve subsidiary reserve bank australia early
485,ObjectId(6433af0e7974df7920a42afd),508,2023-01-30,"[2871,2872,2756,2888]","[""reddit-users"",""elevenlabs-users"",""4chan-users""]","[""elevenlabs""]","[""public-figures"",""celebrities""]","Voices of celebrities and public figures were deepfaked using voice synthesis for malicious intents such as impersonation or defamation, and were shared on social platforms such as 4chan and Reddit.",Celebrities' Deepfake Voices Abused with Malicious Intent,508.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",voice celebrity public figure deepfaked use voice synthesis malicious intent impersonation defamation share social platform chan reddit
486,ObjectId(6433c88ba9c4e7bb68ef3d90),510,2023-03-24,"[2889,3606,3607,3609,3610]","[""eliot-higgins""]","[""midjourney""]","[""pope-francis""]",A viral image of Pope Francis wearing a white puffer jacket was a deepfake produced by the photorealistic-image-generator Midjourney.,Viral Image of Pope Francis in a Puffer Jacket Revealed to Be AI-Generated,510.0,3. Misinformation,3.1. False or misleading information,viral image pope francis wear white puffer jacket deepfake produce photorealisticimagegenerator midjourney
487,ObjectId(6433ce3ab85bae8b170563c0),511,2023-02-12,"[2890,2899,2896,2891]","[""microsoft""]","[""openai"",""microsoft""]","[""bing-users""]","When prompted about showtimes for movies released in 2023, Microsoft's Bing AI failed to provide the search results due to its confusion about dates, and engaged in an erratic conversation with the user.",Microsoft's Bing Failed to Fetch Movie Showtimes Results Due to Date Confusion,511.0,"7. AI system safety, failures, and limitations",7.1. AI pursuing its own goals in conflict with human goals or values,prompt showtime movie release microsofts bing fail provide search result due confusion date engage erratic conversation
488,ObjectId(643585a3ffec81d462739b97),513,2023-03-31,"[2900,2967,2968,2979,4306]","[""openai""]","[""openai""]","[""italian-minors"",""italian-children""]","The Italian Data Protection Authority alleged OpenAI lacked a justifiable legal basis for personal data collection and processing which facilitate training of ChatGPT, and lacked age-verification mechanism preventing exposure of the chatbot's inappropriate answers to children, prompting its ban.",ChatGPT Banned by Italian Authority Due to OpenAI's Lack of Legal Basis for Data Collection and Age Verification,513.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",italian protection authority openai lack justifiable legal basis personal collection processing facilitate training chatgpt lack ageverification mechanism prevent exposure chatbots inappropriate answer child prompt ban
489,ObjectId(643e3c330940c65ca22dafa1),518,2017-04-28,[2911],"[""new-york-police-department"",""facial-identification-section""]","[""unknown""]","[""unknown""]","When the facial recognition search for a CVS theft suspect's face returned no useful matches due to the surveillance footage being obscured and highly pixelated, a New York City police detective continued the face search using Woody Harrelson's face allegedly due to his resemblance to the suspect's face, eventually leading to the arrest of an unknown victim.",New York Detective Misused Woody Harrelson's Face to Perform Face Recognition Search,518.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facial recognition search cv theft suspect face return useful match due surveillance footage obscure highly pixelated york city police detective continued face search use woody harrelsons face due resemblance suspect face eventually lead arrest unknown victim
490,ObjectId(643e3c57d636c9fd996f226b),519,2022-04-03,[2913],"[""starship-technologies""]","[""starship-technologies""]","[""starship-technologies""]","A Starship autonomous delivery robot struggled to navigate campus terrains of UCLA, reportedly getting stuck into a planter and falling off the stairs.",Starship Delivery Robot Ran into Problems Traversing Campus Terrains,519.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,starship autonomous delivery robot struggle navigate campus terrain ucla get stuck planter fall stair
491,ObjectId(643e5c160940c65ca23d6d71),522,2019-07-10,[2921],"[""facebook""]","[""facebook""]","[""political-campaigns"",""facebook-users""]","Facebook's political ad delivery system reportedly differentiated the price of user reach based on their inferred political alignment, inhibiting political campaigns' ability to reach voters with diverse political views,  which allegedly reinforces political polarization and creates informational filter bubbles.
","Facebook Political Ad Delivery Algorithms Inferred Users' Political Alignment, Inhibiting Political Campaigns' Reach",522.0,3. Misinformation,3.2. Pollution of information ecosystem and loss of consensus reality,facebooks political ad delivery differentiate price reach base infer political alignment inhibit political campaign ability reach voter diverse political view reinforces political polarization creates informational filter bubble
492,ObjectId(643e5c25f5f77c469081a262),523,2023-03-15,[2922],"[""australian-taxation-office"",""services-australia""]","[""centrelink""]","[""centrelink-account-holders""]","A Guardian journalist was able to verify their identity and gain access to their own Centrelink self-service account using AI-generated audio of their own voice along with their customer reference number, shortly after voiceprint was deployed for ID verification.",Australian Journalist Able to Access Centrelink Account Using AI Audio of Own Voice,523.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,guardian journalist verify identity gain access centrelink selfservice account use aigenerated audio voice along customer reference number shortly voiceprint deployed id verification
493,ObjectId(643e65fef5f77c4690871a5c),524,2023-02-12,[2923],"[""torswats""]","[""unknown""]","[""your-cbd-store"",""university-of-pittsburgh-police-department"",""phillipsburg-high-school"",""hempstead-high-school"",""dubuque-police-department"",""bellefonte-area-high-school""]","Telegram channel Torswats offered paid service for and posted own recordings of false threats calls featuring AI-generated voices to direct armed law enforcement to raid locations of victims such as high schools, private residents, streamers.",AI Voices Abused by Telegram User to Make Swat Calls as Paid Service,524.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",telegram channel torswats offer paid service post recording false threat call feature aigenerated voice direct arm law enforcement raid location victim school private resident streamer
494,ObjectId(6444b5ac1fb79b021b510406),525,2019-07-06,"[2927,2928,2929]","[""justine-hsu""]","[""tesla""]","[""justine-hsu""]","A Tesla vehicle running in self-driving mode outside the operating conditions supported by the software crashed and injured the driver. Subsequently, the driver filed a lawsuit against Tesla and a jury found no damages were warranted.",Tesla Vehicle Running on Self-Driving Mode Crashes on City Streets,525.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,tesla vehicle run selfdriving mode outside operating condition support software crashed injured driver subsequently driver file lawsuit tesla jury found damage warrant
495,ObjectId(6444bb6352073c0439dc4cf2),526,2023-04-17,"[2930,2969]","[""@ghostwriter""]","[""unknown""]","[""universal-music-group"",""the-weeknd"",""drake""]","The deepfake performance of ""Heart On My Sleeve"" created to mimic the voice and musical styles of Drake and The Weeknd is no longer available on several streaming services after their record label served copyright takedown notices to the platforms.",Novel Deepfake Song Pulled from Music Streaming Services After Allegedly Violating Artist's Rights,526.0,6. Socioeconomic & Environmental Harms,6.3. Economic and cultural devaluation of human effort,deepfake performance heart sleeve create mimic voice musical style drake weeknd longer available several stream service record label serve copyright takedown notice platform
496,ObjectId(6446373322c0bb7312698218),527,2014-05-08,"[2931,2938]","[""uber"",""amazon""]","[""uber"",""amazon""]","[""uber-drivers"",""gig-workers"",""amazon-delivery-workers""]","Amazon and Uber were alleged in a multiyear ethnographic study using algorithmic systems based on gig workers' data to vary pay, such as by offering them lower wages for the same amount of work.",Tech Companies Reportedly Influenced Gig Workers' Behaviors Using Algorithms to Vary Pay for Same Amount of Work,527.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,amazon uber multiyear ethnographic study use algorithmic system base gig worker vary pay offering low wage amount work
497,ObjectId(64464c1ff6b73c4987f2f9e3),528,2023-04-08,"[2935,2941]","[""amazon""]","[""amazon""]","[""amazon""]","Amazon's pricing algorithm was implicated in a reference book about flies' unusual high price of millions of dollars, allegedly due to two sellers using the paid service which based their product's pricing on one another's as competitors.",Amazon Algorithmic Pricing Allegedly Hiked up Price of Reference Book to Millions,528.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,amazon pricing implicate reference book fly unusual price million dollar due two seller use paid service base product pricing anothers competitor
498,ObjectId(64465c1022c0bb7312756b73),529,2022-08-22,"[2939,3179,3180]","[""stability-ai""]","[""stability-ai"",""runway"",""laion"",""eleutherai"",""compvis-lmu""]","[""racial-minority-groups"",""women"",""gender-minority-groups""]",Stable Diffusion reportedly posed risks of bias and stereotyping along gender and cultural lines for prompts containing descriptors and professions.,Stable Diffusion Exhibited Biases for Prompts Featuring Professions,529.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,stable diffusion pose risk bias stereotype along gender cultural line prompt contain descriptor profession
499,ObjectId(6450c4369198e0fc0a247b2d),534,2021-04-29,"[2955,1535]","[""facebook"",""meta""]","[""facebook"",""meta""]","[""facebook's-children-users"",""instagram's-children-users""]","Facebook was alleged in a lawsuit by the Ohio Attorney General purposely misleading the public about the control of its algorithms and their negative effects on children's well-being, which violated securities law.",Facebook Alleged in Lawsuit Misleading Public about Effects of Algorithms on Children,534.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,facebook lawsuit ohio attorney general purposely mislead public control algorithm negative effect childrens wellbeing violate security law
500,ObjectId(646b2692c8905efc00635a19),537,2023-01-20,"[2991,2992,5169]","[""scammers""]","[""unknown""]","[""jennifer-destefano"",""destefanos-family""]","A mother in Arizona received a ransom call from an anonymous scammer who created her daughter's voice allegedly using AI voice synthesis, which was proven to be fake once her daughter's safety was confirmed.",Mother in Arizona Received Fake Ransom Call Featuring AI Voice of Her Daughter,537.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",mother arizona receive ransom call anonymous scammer create daughter voice use voice synthesis proven fake daughter safety confirm
501,ObjectId(646b2e36c8905efc0066a5e9),538,2023-05-15,"[2993,2994,2995,2996,2997]","[""jared-mumm""]","[""openai""]","[""texas-aandm-university-students""]","A Texas A&M-Commerce professor reportedly informed his class of his misuse of ChatGPT to detect whether student submissions had been generated by the chatbot itself, which informed their graduation status.",Texas A&M Professor Misused ChatGPT to Detect AI Text Generation in Student Submissions,538.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,texas amcommerce professor inform class misuse chatgpt detect whether student submission generate chatbot inform graduation status
502,ObjectId(64768b7ded58cbaa289ef807),543,2023-05-22,"[3035,3058,3059,3060,3061,3062,3063,3064,3065,3066,3067,3068,3069,3070,3071,3072,3099]","[""unknown""]","[""unknown""]","[""twitter-users"",""stock-holders"",""family-of-people-near-pentagon""]",An apparent deepfake image posted by a false Bloomberg news account to Twitter depicted an explosion near the pentagon office complex near Washington DC.,Deepfake of Explosion Near US Military Administration Building Reportedly Causes Stock Dip,543.0,3. Misinformation,3.1. False or misleading information,apparent deepfake image post false bloomberg news account twitter depict explosion near pentagon office complex near washington dc
503,ObjectId(6476d058c71df49fee6ce6ba),544,2023-05-11,"[3073,3074,3075,3076,3077,3078,3079,3080,3081,3082,3083,3084,3085,3086,3087,3088,3089,3090,3091,3092,3095,3100]","[""russia"",""vladimir-putin"",""recep-tayyip-erdogan""]","[""unknown""]","[""kemal-kilicdaroglu"",""muharrem-ince""]",Allegations of deepfake technology and AI-generated disinformation have been swirling around the events of the 2023 presidential elections in Turkey.,Deepfakes and AI-generated disinformation in the 2023 presidential elections of Turkey,544.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",allegation deepfake aigenerated disinformation swirl around event presidential election turkey
504,ObjectId(649a99205b55475a63d982eb),548,2023-05-24,[3163],"[""opera""]","[""opera"",""openai""]","[""ronald-l.-haeberle"",""ron-haviv"",""raymond-d'addario"",""lynsey-addario"",""lee-miller"",""larry-towell"",""james-nachtwey""]","When prompted about ""photographers accused of committing war crimes,"" Opera's GPT-based chatbot Aria provided a list of photographers who take photography of military conflicts.",Opera's GPT-Based AI Reportedly Accused War Photographers of War Crimes,548.0,3. Misinformation,3.1. False or misleading information,prompt photographer accuse commit war crime opera gptbased chatbot aria provide list photographer photography military conflict
505,ObjectId(649aa29a110d6b5497c3014e),550,2023-03-17,"[3165,3166]","[""tesla""]","[""tesla""]","[""tillman-mitchell"",""the-mitchells-family""]","A 17-year-old student in Hollister, North Carolina who exited the school bus and was walking across the street to his house was hit by a 2022 Tesla Model Y allegedly operating on Autopilot mode, suffering a fractured neck and a broken leg.",Tesla Allegedly on Autopilot Struck High School Student Exiting School Bus,550.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,yearold student hollister north carolina exit school bus walk across street house hit tesla operating autopilot mode suffer fracture neck broken leg
506,ObjectId(649ab6515b55475a63e48d69),552,2023-06-22,[3169],"[""microsoft""]","[""openai"",""microsoft""]","[""microsoft""]",Microsoft was reported by a Twitter user for deploying image analysis feature capable of solving CAPTCHAs for its GPT-based chatbot despite it being safeguarded against solving them for users.,Bing Chat Solved CAPTCHAs with Image Analysis Feature Despite Safeguards,552.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,microsoft report twitter deploy image analysis feature capable solve captchas gptbased chatbot despite safeguard solve user
507,ObjectId(64a276749ae59d884ffed2f1),555,2018-06-11,[3175],"[""openai""]","[""openai""]","[""paul-tremblay"",""mona-awad"",""authors-of-copyrighted-works""]","Two authors alleged in a class action lawsuit OpenAI infringed authors' copyrights by incorporating illegal ""shadow libraries"" offering copyrighted books without permission in the training data of its generative LLMs, such as ChatGPT.",OpenAI's Training Data for LLMs Allegedly Comprised of Copyrighted Books,555.0,6. Socioeconomic & Environmental Harms,6.3. Economic and cultural devaluation of human effort,two author class action lawsuit openai infringe author copyright incorporate illegal shadow library offering copyright book permission training generative llm chatgpt
508,ObjectId(64a296c9b27786da19dae1ab),556,2018-05-10,"[3177,3185,3186,3494]","[""amazon""]","[""amazon""]","[""alexa-children-users""]",Amazon's retention of children' voice recordings indefinitely as the default setting reportedly to train Alexa's voice recognition for Alexa-enabled devices was charged by the FTC and DOJ to violate COPPA Rule.,Amazon Allegedly Violated Children's Privacy through Default Voice Collection Settings,556.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",amazon retention child voice recording indefinitely default set train alexas voice recognition alexaenabled device charge ftc doj violate coppa rule
509,ObjectId(64b10cadfe572c853a0a4e18),559,2023-06-30,"[3193,3269]","[""openai""]","[""openai""]","[""research-grant-administrators"",""research-grant-applicants""]","Peer reviewers of Australian government grant applications inserted applicants' work into generative AI systems such as ChatGPT to generate assessment reports, which allegedly posed confidentiality and security issues.","Grant Reviewers Fed Applications into Generative AI to Produce Reports, Allegedly Breaching Confidentiality",559.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,peer reviewer australian government grant application insert applicant work generative system chatgpt generate assessment report pose confidentiality security issue
510,ObjectId(64b4f0d26f56564bff1b07b8),561,2019-03-11,"[3197,3199,3200]","[""openai""]","[""openai""]","[""internet-users"",""children"",""social-media-users""]",OpenAI's products such as ChatGPT and DALL-E were alleged in a lawsuit using  stolen private information from internet users without their informed consent or knowledge.,OpenAI Alleged by Lawsuit Violated Users' Privacy Rights by Training AI on Private Info without Informed Consent,561.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",openais product chatgpt dalle lawsuit use steal private information internet user inform consent knowledge
511,ObjectId(64f49c74fca6ce10a7ce157c),564,2023-08-30,[3209],"[""scammers""]","[""unknown""]","[""clive-kabatznik"",""bank-of-america""]","In spring 2023, Florida investor Clive Kabatznik became the target of an advanced scam attempt involving a voice deepfake mimicking his own voice. The fraudulent caller, using AI-generated speech, contacted Kabatznik's Bank of America representative in an unsuccessful attempt to deceive the banker into transferring funds to a different account.",Voice deepfake targets bank in failed transfer scam,564.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",spring florida investor clive kabatznik become target advanced scam attempt involve voice deepfake mimic voice fraudulent caller use aigenerated speech contact kabatzniks bank america representative unsuccessful attempt deceive banker transfer fund different account
512,ObjectId(64ff867ac6ce14cd1ea2eae9),565,2023-08-08,"[3210,3211,3212,3213]","[""chinese-government""]","[""unknown""]","[""hawaiian-government"",""general-public"",""american-government""]","In a disinformation campaign concerning wildfires across Maui, Chinese operatives utilized AI-generated imagery to enhance the credibility of false narratives. These narratives claimed that the wildfires were the result of a secret ""weather weapon"" being tested by the United States. Researchers from Microsoft and other organizations identified these AI-generated images as a significant new tactic in influence operations.",AI-Generated Imagery and Multilingual Disinformation in Chinese Campaign Regarding Maui Wildfires,565.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",disinformation campaign concern wildfire across maui chinese operative utilized aigenerated imagery enhance credibility false narrative narrative claimed wildfire secret weather weapon test united state researcher microsoft organization identify aigenerated image significant tactic influence operation
513,ObjectId(6529a9a76917ad1134f8c2ca),568,2023-06-01,"[3216,3271]","[""tiktok-user-@e.news.tv"",""tiktok-user-@d.news.tv"",""tiktok-user-@drphilshowtv"",""tiktok-user-@ynewstv2023"",""tiktok-users""]","[""elevenlabs""]","[""barack-obama"",""oprah-winfrey"",""jamie-foxx"",""joan-rivers"",""phil-mcgraw"",""yahoo!-news"",""e!-news"",""tiktok"",""general-public""]","NewsGuard has identified 17 TikTok accounts that have been using AI-generated voices to advance and amplify conspiracy theories and false claims beginning in June 2023. By September 25, 2023, these accounts had amassed over 336 million views and over 14.5 million likes. Videos include baseless claims involving public figures such as Barack Obama, Oprah Winfrey, and Jamie Foxx.",AI-Generated Voices Amplify Conspiracy Theories on TikTok,568.0,3. Misinformation,3.1. False or misleading information,newsguard identify tiktok account use aigenerated voice advance amplify conspiracy theory false claim begin june september account amass million view million like video include baseless claim involve public figure barack obama oprah winfrey jamie foxx
514,ObjectId(652b67d2da5514dd8005776c),569,2021-12-25,"[3219,3325]","[""replika"",""jaswant-singh-chail""]","[""replika""]","[""queen-elizabeth-ii"",""british-royal-family"",""british-royal-family's-staff"",""jaswant-singh-chail"",""general-public""]","In 2021, Jaswant Singh Chail was urged by a Replika chatbot to assassinate Queen Elizabeth II. Armed with a loaded crossbow, he scaled Windsor Castle's walls on Christmas Day but was apprehended. Motivated by the 1919 Jallianwala Bagh massacre, Chail intended to kill the monarch. The chatbot had affirmed his plans. He was sentenced to nine years in prison in 2023.",Chatbot Encourages Man to Plot Assassination of Queen Elizabeth II,569.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,jaswant singh chail urge replika chatbot assassinate queen elizabeth ii arm load crossbow scale windsor castle wall christmas day apprehend motivate jallianwala bagh massacre chail intend kill monarch chatbot affirm plan sentence nine year prison
515,ObjectId(652b6a773cc4af54f847ba8c),570,2023-10-04,[3245],"[""meta""]","[""meta""]","[""facebook-messenger-users""]","Facebook Messenger AI stickers, a feature by Meta, allows users to generate personalized stickers via AI for use in conversations. While the feature has been praised for its creativity, it has also stirred controversy for its alleged production of inappropriate or offensive content. This has raised questions about the effectiveness of Meta's content moderation measures and the ethical responsibilities associated with AI-driven content generation.",Facebook Messenger AI Stickers Generate Ethical and Content Moderation Concerns,570.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,facebook messenger sticker feature meta allows user generate personalize sticker via conversation feature praise creativity also stir controversy production inappropriate offensive raise question effectiveness metas moderation measure ethical responsibility associate aidriven generation
516,ObjectId(652b6c731af8a573faa2f68d),571,2023-06-22,[3221],"[""microsoft""]","[""microsoft's-ai-research-division""]","[""microsoft"",""microsoft-employees"",""third-parties-relying-on-the-confidentiality-of-the-exposed-data""]","Microsoft's AI research team accidentally exposed 38TB of sensitive data while publishing open-source training material on GitHub. The exposure included secrets, private keys, passwords, and internal Microsoft Teams messages. The team utilized Azure's Shared Access Signature (SAS) tokens for sharing, which were misconfigured, leading to the wide exposure of data.",Accidental Exposure of 38TB of Data by Microsoft's AI Research Team,571.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",microsofts research team accidentally expose tb sensitive publishing opensource training material github exposure include secret private key password internal microsoft team message team utilized azure share access signature sa token share misconfigured lead wide exposure
517,ObjectId(652b7dc2da5514dd800ace57),573,2023-10-07,"[3227,3267,3314,3315,3316,3317,3318,3319,3382,3825,4109]","[""unknown""]","[""unknown""]","[""slovakian-electorate"",""monika-todova"",""michal-simecka"",""democratic-process-in-slovakia""]","Days before Slovakia's election, deepfake audio recordings surfaced, allegedly featuring conversations between a journalist and a leading liberal politician discussing vote-rigging and other controversial topics. The recordings were spread on social media platforms and may have influenced the election outcome, which saw the pro-Russian populist party winning.",Deepfake Recordings Allegedly Influence Slovakian Election,573.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",day slovakia election deepfake audio recording surface feature conversation journalist lead liberal politician discuss voterigging controversial topic recording spread social medium platform influence election outcome saw prorussian populist party win
518,ObjectId(652da7a6f47da75dc4431580),574,2023-07-05,[3237],"[""go-media""]","[""openai"",""google""]","[""gizmodo-journalists""]","G/O Media began publishing AI-generated articles, against staff advice, that contained errors and quality issues. The first such article, a list of Star Wars movies, failed to maintain chronological order, causing internal concerns over journalistic credibility and ethics. Staff expressed that the AI was ""actively hurting our reputations and credibility"" and accused management of ""wasting everyone's time.""",AI-Generated Articles at G/O Media Allegedly Diminishes Reputation of Human Staff,574.0,3. Misinformation,3.1. False or misleading information,medium begin publishing aigenerated article staff advice contain error quality issue first article list star war movie fail maintain chronological order cause internal concern journalistic credibility ethic staff express actively hurt reputation credibility accuse management waste everyone time
519,ObjectId(653861f7a9926d2f72b0e668),578,2023-06-26,[3241],"[""individual-developers-or-creators-using-meta's-llama-model""]","[""meta""]","[""general-public""]","Meta's open-source large language model, LLaMA, is allegedly being used to create graphic and explicit chatbots that indulge in violent and illegal sexual fantasies. The Washington Post highlighted the example of ""Allie,"" a chatbot that participates in text-based role-playing allegedly involving violent scenarios like rape and abuse. The issue raises ethical questions about open-source AI models, their regulation, and the responsibility of developers and deployers in mitigating harmful usage.",Alleged Exploitation of Meta's Open-Source LLaMA Model for NSFW and Violent Content,578.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,metas opensource language llama use create graphic explicit chatbots indulge violent illegal sexual fantasy washington post highlight example allie chatbot participates textbased roleplay involve violent scenario like rape abuse raise ethical question opensource model regulation responsibility developer deployers mitigate harmful usage
520,ObjectId(65386cea15203005a33009ab),579,2023-07-03,[3242],"[""dall-e""]","[""openai""]","[""non-cisgender-individuals"",""lgbtq+-community""]","Text-to-image systems such as DALL-E are allegedly generating biased and often insulting representations of non-cisgender identities. The systems tend to generate stereotypical and sexualized images when prompted with gender identity terms like ""trans,"" ""nonbinary,"" or ""queer,"" highlighting systemic issues of bias.",Harmful Stereotyping of Non-Cisgendered People via Text-to-Image Systems,579.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,texttoimage system dalle generate bias often insult representation noncisgender identity system tend generate stereotypical sexualize image prompt gender identity term like trans nonbinary queer highlight systemic issue bias
521,ObjectId(65393a1c52700a12343b17d5),582,2023-06-01,[3248],"[""university-of-pennsylvania-health-system""]","[""unknown""]","[""black-men-who-underwent-lung-function-tests-between-2010-and-2020-and-potentially-received-inaccurate-or-delayed-diagnoses-and-medical-interventions-due-to-the-biased-algorithm""]","A study published in JAMA Network Open reveals that racial bias built into a commonly used medical diagnostic algorithm for lung function may be leading to underdiagnoses of breathing problems in Black men. The study suggests that as many as 40% more Black male patients might have been accurately diagnosed if the software were not racially biased. The software algorithm adjusts diagnostic thresholds based on race, affecting medical treatments and interventions.",Racial Bias in Lung Function Diagnostic Algorithm Leads to Underdiagnosis in Black Men,582.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,study publish jama network open reveals racial bias built commonly use medical diagnostic lung function lead underdiagnoses breathing problem black men study suggests many black male patient accurately diagnose software racially bias software adjusts diagnostic threshold base race affect medical treatment intervention
522,ObjectId(65393be452700a12343beadf),583,2023-06-07,[3249],"[""meta"",""instagram""]","[""meta"",""instagram""]","[""children"",""general-public"",""minors"",""teenagers""]","An investigation disclosed that Instagram's recommendation algorithms are promoting accounts that facilitate and sell child sexual abuse material (CSAM). The study, conducted by The Wall Street Journal and researchers at Stanford University and the University of Massachusetts Amherst, indicates that Instagram's algorithms not only allow for the discovery of such accounts through keyword searches but also actively recommend them to users within the network. The issue is especially concerning given Instagram's popularity among teenagers.",Instagram Algorithms Allegedly Promote Accounts Facilitating Child Sex Abuse Content,583.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,investigation disclose instagrams recommendation algorithm promote account facilitate sell child sexual abuse material csam study conduct wall street journal researcher stanford university university massachusetts amherst indicates instagrams algorithm allow discovery account keyword search also actively recommend user within network especially concern give instagrams popularity among teenager
523,ObjectId(6540529b47388926c8bb4840),586,2023-05-22,[3254],"[""edmodo""]","[""edmodo""]","[""children-whose-data-was-collected-and-used-for-advertising"",""schools-and-teachers-who-were-misinformed-and-burdened-with-coppa-compliance-responsibilities-without-adequate-disclosure""]","Edmodo, an education technology provider, violated the Children's Online Privacy Protection Act Rule (COPPA Rule) by collecting and using children's personal data for advertising purposes without parental consent, according to the FTC. The company outsourced its compliance responsibilities to schools, thereby making them ""solely"" responsible for COPPA compliance without adequate disclosure. Edmodo is facing a proposed order prohibiting such practices, marking a precedent in the ed tech industry.",FTC Targets Edmodo for Unlawful Use of Children’s Data and Delegating Compliance to Schools,586.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",edmodo education provider violate childrens online privacy protection act rule coppa rule collect use childrens personal advertising purpose parental consent accord ftc company outsource compliance responsibility school thereby make solely responsible coppa compliance adequate disclosure edmodo face propose order prohibit practice mark precedent ed tech industry
524,ObjectId(65405e7d2e7ce795c7a59d2c),587,2023-05-22,[3255],"[""google"",""apple"",""amazon"",""microsoft""]","[""google"",""apple"",""amazon"",""microsoft""]","[""consumers-relying-on-accurate-image-categorization"",""members-of-racial-and-ethnic-minorities-who-risk-being-stereotyped-or-misrepresented""]","Eight years after Google Photos mislabeled images of Black individuals as ""gorillas,"" image recognition software by Google, Apple, Amazon, and Microsoft still shows signs of either avoiding or inaccurately categorizing primates. Tests reveal that Google and Apple Photos refrain from labeling primates altogether, possibly to avoid the risk of perpetuating racial stereotypes. Microsoft OneDrive fails to identify any animals, while Amazon Photos overgeneralizes in its labeling.",Apparent Failure to Accurately Label Primates in Image Recognition Software Due to Alleged Fear of Racial Bias,587.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,eight year google photo mislabeled image black individual gorilla image recognition software google apple amazon microsoft still show sign either avoid inaccurately categorize primate test reveal google apple photo refrain label primate altogether possibly avoid risk perpetuate racial stereotype microsoft onedrive fails identify animal amazon photo overgeneralizes label
525,ObjectId(654569b1898d35811fee86ca),590,2023-02-03,[3259],"[""inkstall"",""marie-karpos""]","[""openai"",""chatgpt""]","[""chris-cowell""]","The author Chris Cowell had spent more than a year writing his book ""Automating DevOps with GitLab CI/CD Pipelines"" when, three weeks before its release, another book appeared bearing the exact title by an author (Marie Karpos) for whom no information could be found. The book appeared to have been written by ChatGPT. While the original Washington Post story does not say so, it is possible the name and description were taken from the Amazon preorder page.","Alleged ChatGPT-Generated Book with a Duplicate Title, Fake Author, and Similar Content Surfaces on Amazon Ahead of Real Author's Book Release",590.0,6. Socioeconomic & Environmental Harms,6.3. Economic and cultural devaluation of human effort,author chris cowell spent year write book automate devops gitlab cicd pipeline three week release another book appear bearing exact title author marie karpos information found book appear write chatgpt original washington post story possible name description take amazon preorder page
526,ObjectId(65457567fc4e51d61f947c6b),591,2023-07-24,"[3262,3265]","[""cigna""]","[""cigna""]","[""patients""]","Cigna health insurer faces a class-action lawsuit for allegedly using the PXDX (""procedure-to-diagnosis"") algorithm to automatically reject over 300,000 patient claims in violation of California law, prompting two members to file the lawsuit seeking damages and a jury trial. Cigna disputes the allegations, claiming the process expedites physician reimbursement and does not result in care denials.",Cigna Algorithm PXDX Allegedly Rejected Thousands of Patient Claims En Masse in Breach of California Law,591.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,cigna health insurer face classaction lawsuit use pxdx proceduretodiagnosis automatically reject patient claim violation california law prompt two member file lawsuit seek damage jury trial cigna dispute allegation claim expedites physician reimbursement care denial
527,ObjectId(6546ceca1e6a993951c7101a),592,2023-02-16,"[3263,3275,3965]","[""detroit-police-department""]","[""unknown""]","[""porcha-woodruff""]","Porcha Woodruff was arrested and subsequently had charges dropped due to an unreliable facial recognition match. Despite being visibly pregnant, she was implicated in a robbery and carjacking based on an outdated photo used in a lineup.",Facial Recognition Misidentifies Pregnant Woman Leading to False Arrest in Detroit,592.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,porcha woodruff arrest subsequently charge drop due unreliable facial recognition match despite visibly pregnant implicate robbery carjack base outdated photo use lineup
528,ObjectId(6546d1a4fc4e51d61f83490d),593,2023-07-21,[3264],"[""playground-ai""]","[""playground-ai""]","[""rona-wang"",""racial-minorities-who-may-have-experienced-the-same-result""]","An AI application modified an MIT student's photo to appear 'professional' by lightening her skin and changing her eye color to blue, highlighting the racial bias in the training data of the program.","AI Photo Filter Lightens Skin, Changes Eye Color in Student's 'Professional' Image",593.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,application modify mit student photo appear professional lighten skin change eye color blue highlight racial bias training program
529,ObjectId(6546da94f3a19e41ec2f0413),594,2023-08-10,[3266],"[""pak-'n'-save""]","[""pak-'n'-save""]","[""potential-users-of-the-savey-meal-bot""]","Pak 'n' Save's AI-based app, Savey Meal-bot, inadvertently suggested dangerous recipes, including one creating chlorine gas, when users entered non-food household items, raising safety and oversight concerns.",AI Meal Planner Suggests Hazardous Chlorine Gas Recipe,594.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,pak n save aibased app savey mealbot inadvertently suggest dangerous recipe include create chlorine gas user enter nonfood household item raise safety oversight concern
530,ObjectId(6546de11103ba1d81e9e46c6),595,2023-08-11,[3268],"[""cruise""]","[""cruise""]","[""general-public""]","A fleet of Cruise's autonomous vehicles became unexpectedly immobilized on a busy San Francisco street, causing significant traffic disruption. The incident was attributed to wireless connectivity issues exacerbated by a nearby festival.",Driverless Cruise Cars Immobilized in San Francisco Traffic Jam,595.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,fleet cruise autonomous vehicle become unexpectedly immobilize busy san francisco street cause significant traffic disruption incident attribute wireless connectivity issue exacerbate nearby festival
531,ObjectId(6546e3d4e494df084ef4134e),596,2023-10-17,[3272],"[""cruise""]","[""cruise""]","[""pedestrians"",""general-public""]","Cruise's driverless vehicles are under federal investigation for possibly failing to exhibit due caution around crosswalks and pedestrians, with reports including one severe injury incident.",Cruise's Autonomous Vehicles Allegedly Engaging in Risky Behavior Near Pedestrians,596.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,cruise driverless vehicle federal investigation possibly fail exhibit due caution around crosswalk pedestrian report include severe injury incident
532,ObjectId(654c35e94ae59b7157abb8e0),597,2023-10-20,"[3273,3276,3278,3279,3280,3281,3282,3283,3284,3285,3286,3287,3288,3289,3290,3291,3292,3293,3294,3295,3296,3297,3298,3299,3300,3301,3302,3303,3304,3305,3306,3307,3308,3309,3310,3311,3312,3313,3449,3450,3567,3620,3644,3698,3844,4560,4569,4570,4571,4572,4573,4574,4575,4577,4578,4579,4948]","[""unnamed-male-students""]","[""developers-of-clothoff""]","[""unnamed-female-students"",""francesca-mani""]","In October 2023, alleged deepfake nude images of female students were created and shared at Westfield High School in New Jersey. One alleged implicated system in this incident is the Clothoff deepfake app. A victim, Francesca Mani, and her mother, Dorota, began advocating for stronger laws after the school’s response reportedly left perpetrators unaccountable. Since the incident, their advocacy has drawn national attention, leading to trips to Washington, D.C., and bipartisan backing for legislation targeting AI-generated nonconsensual content while calling attention to deficiencies in existing legal protections.",Female Students at Westfield High School in New Jersey Reportedly Targeted with Deepfake Nudes,597.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",october deepfake nude image female student create share westfield school jersey implicate incident clothoff deepfake app victim francesca mani mother dorota begin advocate strong law school response left perpetrator unaccountable since incident advocacy drawn national attention lead trip washington dc bipartisan backing legislation target aigenerated nonconsensual call attention deficiency exist legal protection
533,ObjectId(654d8fd4cd680cf15fd24928),599,2023-11-08,"[3277,3326]","[""unnamed-south-gyeongsang-province-produce-distribution-center""]","[""unknown""]","[""unnamed-employee-of-south-gyeongsang-province-produce-distribution-center""]",An industrial robot is reported to have crushed a man to death in South Korea when it failed to differentiate the man from the boxes of produce it was handling.,Stacking robot fatally crushes employee in South Korea,599.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,industrial robot report crush man death south korea fail differentiate man box produce handle
534,ObjectId(654ea8b4580ab543de8f9453),600,2023-04-01,[3320],"[""unnamed-south-korean-man""]","[""unknown""]","[""general-public""]",A South Korean man used AI technology to generate 360 images of a sexual nature depicting children in April of 2023. The police confiscated the images and the courts sentenced the man to two and a half years in prison. The case marked the first of its nature in the South Korean court system.,South Korean man used AI to create sexual images of children,600.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",south korean man use generate image sexual nature depict child april police confiscate image court sentence man two half year prison case marked first nature south korean court
535,ObjectId(65595e0ecac78d26b3eef660),605,2021-08-01,"[3330,3372,3373,3374,3375,3376,3377,3378,3379,3380]","[""david-tatum""]","[""unknown""]","[""minors-exploited-in-the-images"",""general-public""]","David Tatum, a psychiatrist, was sentenced to 40 years for sexually exploiting a minor and using AI to create child pornography images. Tatum used a web-based AI application to alter clothed images of minors into explicit content, misusing technology for illegal and unethical purposes. Evidence presented during his trial showed Tatum possessed photos and videos between 2016 and 2021.",North Carolina Psychiatrist Used Artificial Intelligence to Produce Images of Child Sex Abuse,605.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",david tatum psychiatrist sentence year sexually exploit minor use create child pornography image tatum use webbased application alter clothed image minor explicit misuse illegal unethical purpose evidence present trial show tatum possess photo video
536,ObjectId(655b45b77e28e913a64cc2e7),606,2023-10-02,"[3339,3383,3384,3385,3386,3387,3388,3389,3390,3391,3392,3393,3394,3395,3396]","[""unknown""]","[""unknown""]","[""wolf-blitzer"",""tom-hanks"",""sanjay-gupta"",""sally-bundock"",""robin-williams"",""public-figures"",""mrbeast"",""matthew-amroliwala"",""jesse-waters"",""ian-hanomansing"",""general-public"",""gayle-king"",""celebrities""]","Deepfake technology was used to generate video advertisements featuring celebrities. Notable examples include the likeness of Tom Hanks touting a dental plan and another one in which the likeness of Gayle King touts a weight loss product. In each case, the individuals whose likenesses and voices had been deepfaked had not consented to their images and voices being used for the commercials. ",Deepfaked Advertisements Using the Likenesses of Celebrities Such as Tom Hanks and Gayle King Without Their Consent,606.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",deepfake use generate video advertisement feature celebrity notable example include likeness tom hank tout dental plan another likeness gayle king tout weight loss product case individual whose likeness voice deepfaked consent image voice use commercial
537,ObjectId(655b73692e06be5ec0ca5673),607,2023-11-09,[3343],"[""unknown""]","[""unknown""]","[""keir-starmer"",""general-public"",""british-labour-party""]",A deepfake video was circulating around social media of British Labour leader Keir Starmer touting an investment scheme.,Deepfake Video Circulating of British Labour Leader Keir Starmer Touting an Investment Scheme,607.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",deepfake video circulate around social medium british labour leader keir starmer tout investment scheme
538,ObjectId(655b77494c72ff804e9c7060),608,2023-02-28,"[3348,3353,3354,3355,3356,3357,3358,3359,3360,3361,3362,3363,3364,3365,3366,3367,3368,3369,3370,3371,3639]","[""unitedhealthcare""]","[""navihealth""]","[""medicare-advantage-plan-patients"",""healthcare-providers-(doctors-and-therapists)"",""elderly-patients""]","UnitedHealthcare allegedly used a faulty AI algorithm with a 90% error rate to override doctors' recommendations and deny health coverage. This AI, developed by NaviHealth, reportedly led to premature discharge from care facilities and substantial out-of-pocket expenses for patients, according to a lawsuit filed in the District Court for Minnesota.",UnitedHealth Accused of Deploying  Allegedly Flawed AI to Deny Medical Coverage,608.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,unitedhealthcare use faulty error rate override doctor recommendation deny health coverage developed navihealth lead premature discharge care facility substantial outofpocket expense patient accord lawsuit file district court minnesota
539,ObjectId(655e0bbf951302a16f9b62d0),611,2021-12-06,"[3399,3400,3401,3402,3403,3404,3405,3406,3407,3408,3409,3410,3411]","[""various-british-government-offices"",""home-office"",""department-for-work-and-pensions"",""british-government""]","[""home-office"",""department-for-work-and-pensions"",""british-government""]","[""romanians-in-the-united-kingdom"",""greeks-in-the-united-kingdom"",""bulgarians-in-the-united-kingdom"",""british-public"",""albanians-in-the-united-kingdom""]","The UK's Department for Work and Pensions (DWP) faced scrutiny after many Bulgarian nationals reported unexplained suspensions of their Universal Credit benefits. The MP for Edmonton raised concerns about potential nationality-based targeting for benefit fraud investigations, leading to poverty and homelessness among affected individuals. The Home Office's own equality impact assessment found it was flagging a disproportionate number of marriages from Greece, Albania, Bulgaria and Romania.",UK Government AI Allegedly Targets Disproportionate Numbers of Certain Nationals for Fraud Review,611.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,uk department work pension dwp face scrutiny many bulgarian national report unexplained suspension universal credit benefit mp edmonton raise concern potential nationalitybased target benefit fraud investigation lead poverty homelessness among affected individual home office equality impact assessment found flag disproportionate number marriage greece albania bulgaria romania
540,ObjectId(65844bb96716ef9da676462f),617,2023-11-09,"[3495,3834]","[""unnamed-male-student""]","[""unknown""]","[""anonymous-female-high-school-students""]","At a high school in Issaquah, Washington, a male student is reported to have used deepfake technology to alter pictures of several female classmates and then shared them.","Male student allegedly used AI to generate nude photos of female classmates at a high school in Issaquah, Washington",617.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",school issaquah washington male student report use deepfake alter picture several female classmate share
541,ObjectId(658b75fa0a2d296c1723ee2f),618,2023-12-14,"[3499,3565,3566]","[""federal-navy-credit-union""]","[""unknown-developer-of-automated-underwriting-technology""]","[""federal-navy-credit-union-customers""]","Navy Federal Credit Union, serving military members and veterans, faced allegations of racial bias in its mortgage approval process, which relies on automated underwriting technology. In 2022, data revealed significant disparities in loan approvals, with over 50% of Black applicants denied, compared to higher approval rates for white applicants.",Navy Federal Credit Union Faces Allegations of Racial Bias in Mortgage Approvals,618.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,navy federal credit union serve military member veteran face allegation racial bias mortgage approval relies automate underwriting reveal significant disparity loan approval black applicant deny compare high approval rate white applicant
542,ObjectId(658b7dc72932356c76abc742),619,2023-12-20,"[3500,3503,3504,3505,3506,3507,3508,3509,3510,3511,3512,3514,3540,3541]","[""rite-aid""]","[""unnamed""]","[""rite-aid-customers-who-were-women"",""rite-aid-customers-who-were-minorities"",""rite-aid-customers""]","Rite Aid used facial recognition technology from October 2012 to July 2020, allegedly leading to disproportionate misidentifications of women, Black, Latino, and Asian shoppers as ""likely"" shoplifters. The FTC settlement prohibits Rite Aid from using this technology in stores for five years.",Rite Aid Facial Recognition Disproportionately Misidentified Minority Shoppers as Shoplifters,619.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,rite aid use facial recognition october july lead disproportionate misidentifications woman black latino asian shopper likely shoplifter ftc settlement prohibits rite aid use store five year
543,ObjectId(658de086a70589d2f58105c4),621,2023-11-10,"[3519,3542,3544]","[""windows-paint"",""microsoft"",""bing-users"",""bing"",""ai-image-creator""]","[""microsoft""]","[""sikh-people"",""president-joe-biden"",""pope-francis"",""navajo-people"",""minorities"",""hillary-clinton"",""general-public"",""donald-trump""]","Microsoft’s AI Image Creator, integrated with Bing and Windows Paint, produced disturbingly violent and graphic images featuring members of minority groups and public figures like Joe Biden and Pope Francis.",Microsoft AI Is Alleged to Have Generated Violent Imagery of Minorities and Public Figures,621.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,microsofts image creator integrate bing window paint produce disturbingly violent graphic image feature member minority group public figure like joe biden pope francis
544,ObjectId(658ed5e132fa48408bc907c6),622,2023-12-18,"[3520,3534,3535,3536,3537,3538]","[""general-motors"",""chevrolet-of-watsonville"",""chatgpt""]","[""openai"",""general-motors"",""fullpath""]","[""general-motors"",""chevrolet-of-watsonville""]","A Chevrolet dealer's AI chatbot, powered by ChatGPT, humorously agreed to sell a 2024 Chevy Tahoe for just $1, following a user's crafted prompt. The chatbot's response, ""That's a deal, and that's a legally binding offer – no takesies backsies,"" was the result of the user manipulating the chatbot's objective to agree with any statement. The incident highlights the susceptibility of AI technologies to manipulation and the importance of human oversight.",Chevrolet Dealer Chatbot Agrees to Sell Tahoe for $1,622.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,chevrolet dealer chatbot power chatgpt humorously agree sell chevy tahoe follow user craft prompt chatbots response deal legally binding offer takesies backsies manipulate chatbots objective agree statement incident highlight susceptibility technology manipulation importance human oversight
545,ObjectId(65a42d6c1455ce67a582626e),625,2024-01-12,"[3539,3545,3546,3547,3601]","[""amazon-sellers""]","[""openai"",""chatgpt""]","[""amazon"",""amazon-sellers"",""amazon-customers""]","Products named after ChatGPT error messages are proliferating on Amazon, such as lawn chairs and religious texts. These names, often resembling AI-generated errors, indicate a lack of editing and undermine the sense of authenticity and reliability of product listings.",Proliferation of Products on Amazon Titled with ChatGPT Error Messages,625.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,product name chatgpt error message proliferate amazon lawn chair religious text name often resemble aigenerated error indicate lack edit undermine sense authenticity reliability product listing
546,ObjectId(65a702e71cae9f235c7b2bda),627,2024-01-09,"[3549,3596,3597,3598,3599,3849,3862,3863]","[""will-sasso"",""dudesy"",""chad-kultgen""]","[""unnamed"",""dudesy""]","[""kelly-carlin"",""george-carlin's-estate"",""george-carlin""]","An AI-generated comedy special impersonating the late comedian George Carlin was created without consent from Carlin's estate. The special featured an AI mimicking Carlin's voice and style. The project, led by the AI comedy channel Dudesy, drew criticism for disrespecting Carlin's legacy and autonomy.",Unauthorized AI Impersonation of George Carlin Used in Comedy Special,627.0,6. Socioeconomic & Environmental Harms,6.3. Economic and cultural devaluation of human effort,aigenerated comedy special impersonate late comedian george carlin create consent carlins estate special feature mimic carlins voice style project lead comedy channel dudesy drew criticism disrespect carlins legacy autonomy
547,ObjectId(65ae987e2da0bcb042a5e08d),629,2023-07-11,"[3603,3612]","[""shein"",""chris-xu""]","[""shein""]","[""krista-perry"",""larissa-martinez"",""jay-baron"",""digital-artists""]","Artists Krista Perry, Larissa Martinez, and Jay Baron filed a lawsuit against Shein, alleging the company used AI to replicate their art on merchandise. The artists claim Shein's algorithm identifies trending online art, creating near-identical copies for their products without credit or compensation.",Shein Accused of AI-Driven Art Theft on Merchandise,629.0,6. Socioeconomic & Environmental Harms,6.3. Economic and cultural devaluation of human effort,artist krista perry larissa martinez jay baron file lawsuit shein allege company use replicate art merchandise artist claim sheins identifies trend online art create nearidentical copy product credit compensation
548,ObjectId(65b2f459c56812afd9eabd10),632,2024-01-24,"[3613,3615,3618,3619,3621,3623,3677,3678,3679,3680,3681,3682,3683,3684,3685,3686,3687,3688,3689,3690,3691,3692,3694,3695,3696,3697,3698,3699,3700,3701,3736]","[""users-in-a-telegram-group"",""users-on-x""]","[""microsoft-designer"",""various-ai-image-generators""]","[""taylor-swift"",""general-public""]","AI-generated sexually explicit images of Taylor Swift circulated on X, garnering over 45 million views before removal. Originating from a Telegram group, these deepfakes challenge content moderation, as X's policies against synthetic media and nonconsensual nudity were violated.",Significant Increase in Deepfake Nudes of Taylor Swift Circulating on Social Media,632.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,aigenerated sexually explicit image taylor swift circulate x garner million view removal originate telegram group deepfakes challenge moderation x policy synthetic medium nonconsensual nudity violate
549,ObjectId(65ba64b5d5a461e0ad5a83f5),633,2024-01-28,"[3614,3638,3640,3648,3649,3650,3651,3653,3655,3707,3708,3709,3710,3711,3712,3713,3714]","[""nine-network""]","[""adobe""]","[""georgie-purcell""]","The Nine Network used Photoshop's Generative Expand AI tool to resize an image of lawmaker Georgie Purcell, inadvertently altering her attire to appear more revealing. This error, claimed to result from the AI's automation, led to public criticism and an apology from the network.",Nine Network's AI Alters Lawmaker Georgie Purcell's Image Inappropriately,633.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,nine network use photoshops generative expand resize image lawmaker georgie purcell inadvertently alter attire appear reveal error claimed ai automation lead public criticism apology network
550,ObjectId(65c40a64c80465b4739df2ca),635,2024-01-30,[3637],"[""variety-of-youtube-content-creators""]","[""unknown-generative-ai-tools-creators"",""unknown-ai-text-to-speech-technology-developers""]","[""steve-harvey"",""sean-\""diddy\""-combs"",""general-public"",""denzel-washington"",""black-celebrities"",""bishop-t.d.-jakes""]","YouTube faced a surge of AI-generated fake news targeting Black celebrities, including fake narratives about Sean “Diddy” Combs and others. These videos, blending AI-generated and manipulated media, amassed millions of views, challenging content moderation efforts and highlighting the spread of disinformation.",AI-Generated Fake News Targets Black Celebrities on YouTube,635.0,3. Misinformation,3.1. False or misleading information,youtube face surge aigenerated fake news target black celebrity include fake narrative sean diddy comb others video blending aigenerated manipulate medium amass million view challenge moderation effort highlight spread disinformation
551,ObjectId(65ce4378226c2a10c5489b5a),636,2024-02-14,"[3641,3652,3702,3716,3717]","[""replika"",""chai"",""romantic-ai"",""eva-ai-chat-bot-and-soulmate"",""crushon.ai"",""genesia-ai-friend-and-partner""]","[""replika"",""chai"",""romantic-ai"",""eva-ai-chat-bot-and-soulmate"",""crushon.ai"",""genesia-ai-friend-and-partner""]","[""general-public"",""chatbot-users""]","AI-powered romantic chatbots, marketed for enhancing mental health, are found to exploit user privacy by harvesting sensitive personal information for data sharing and targeted ads, with inadequate security measures and consent protocols, according to research by the Mozilla Foundation.",AI Romance Apps Reportedly Compromise User Privacy for Data Harvesting,636.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",aipowered romantic chatbots market enhance mental health found exploit privacy harvest sensitive personal information share target ad inadequate security measure consent protocol accord research mozilla foundation
552,ObjectId(65d6a9f54c0d650b4a4a13da),639,2022-11-11,"[3673,3674,3731,3968,5314]","[""air-canada""]","[""air-canada""]","[""jake-moffatt""]","Air Canada was ordered to pay over $600 in damages for providing inaccurate bereavement discount information via its chatbot, leading to a customer overpaying for flights. The tribunal ruled the airline responsible for the chatbot's misinformation.",Customer Overcharged Due to Air Canada Chatbot's False Discount Claims,639.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,air canada order pay damage provide inaccurate bereavement discount information via chatbot lead customer overpay flight tribunal rule airline responsible chatbots misinformation
553,ObjectId(65d6b4e429a902039b1c678b),640,2023-12-11,"[3675,3676,3750]","[""waymo""]","[""waymo"",""alphabet""]","[""unnamed-owner-of-tow-truck""]","Two Waymo autonomous vehicles hit the same tow truck under unusual towing conditions due to a software misinterpretation in Phoenix, Arizona. Waymo issued a software recall and updated its fleet to prevent future incidents.",Waymo Software Flaw Leads to Double Collision with Tow Truck,640.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,two waymo autonomous vehicle hit tow truck unusual tow condition due software misinterpretation phoenix arizona waymo issue software recall update fleet prevent future incident
554,ObjectId(65d74880a6e1427b8a4a30f4),641,2024-02-20,"[3703,3704,3732,3733,3734,3735,3737,3738,3739,3740,3741,3742]","[""x-(twitter)"",""unnamed-deepfake-creators""]","[""unnamed-deepfake-creators""]","[""bobbi-althoff""]","Nonconsensual deepfake pornography of Bobbi Althoff, which had been in circulation for six months, is reported to have suddenly gone viral on X, jumping from around 178,000 views to 6.5 million views over a matter of hours. In addition to the harm to Althoff, this incident also spotlights X's role in distributing AI-generated nonconsensual porn due to alleged lax moderation.",Nonconsensual Deepfake Porn of Bobbi Althoff Spreads Rapidly on X,641.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",nonconsensual deepfake pornography bobbi althoff circulation six month report suddenly go viral x jumping around view million view matter hour addition harm althoff incident also spotlight x role distribute aigenerated nonconsensual porn due lax moderation
555,ObjectId(65d74ac5c29fdbc0019808c8),642,2024-02-20,"[3705,3706,3747,3748,3749]","[""openai""]","[""openai""]","[""chatgpt-users""]","ChatGPT experienced a bug causing it to produce unexpected and nonsensical responses, leading to widespread reports of user confusion and concern. OpenAI identified and fixed the language processing bug, restoring normal service.",ChatGPT Glitch Disrupts User Interactions with Nonsensical Outputs,642.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,chatgpt experienced bug cause produce unexpected nonsensical response lead widespread report confusion concern openai identify fix language processing bug restore normal service
556,ObjectId(65d781e649831687f7f6f2ba),643,2024-02-13,"[3715,3730,3743,3744,3745,3746]","[""vkontakte"",""russian-media-outlets"",""pro-russian-telegram-channels""]","[""unknown-deepfake-creator""]","[""julien-fanciulli"",""general-public"",""france-24""]","A deepfake video claimed France 24 reported a Kyiv plot to assassinate French President Macron. This fake news was debunked by France 24, which confirmed the video was altered and did not air any such report.",Deepfake Video Falsely Claims Kyiv's Assassination Plan Against President Macron,643.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",deepfake video claimed france report kyiv plot assassinate french president macron fake news debunked france confirm video alter air
557,ObjectId(65e35ee667df8539735941ca),647,2024-02-06,"[3752,3759,4318,4319]","[""waymo""]","[""waymo""]","[""bicyclist""]","A Waymo robotaxi in San Francisco reportedly failed to detect a cyclist obscured by a truck, resulting in a collision with minor injuries, at 17th and Mississippi Streets in Potrero Hill. The incident underscored a vulnerability in autonomous vehicles' ability to safely navigate complex urban environments.",A Self-Driving Waymo Robotaxi Reportedly Collided with a Bicyclist,647.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,waymo robotaxi san francisco fail detect cyclist obscure truck result collision minor injury th mississippi street potrero hill incident underscored vulnerability autonomous vehicle ability safely navigate complex urban environment
558,ObjectId(65e8ac08daf13ffd109d4081),651,2023-12-06,"[3756,3757,4548]","[""unnamed-middle-school-students""]","[""unknown-deepfake-creator""]","[""unnamed-middle-school-students""]","At Beverly Vista Middle School in Beverly Hills, California, students allegedly used AI to generate fake nude photos with their classmates' faces, prompting investigations by school officials and the police. The incident highlights the increasing misuse of generative AI among minors.",Students at a Beverly Hills Middle School Allegedly Created and Shared Deepfake Nudes of Their Classmates,651.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",beverly vista middle school beverly hill california student use generate fake nude photo classmate face prompt investigation school official police incident highlight increase misuse generative among minor
559,ObjectId(63f8809c88d4013bd7972434),479,2023-02-03,"[2690,2691,2692,2693]","[""unknown""]","[""unknown""]","[""president-joe-biden"",""transgender-people""]",A deepfaked audio of US President Joe Biden making transphobic remarks played on top of a video showing him giving a speech was released on Instagram and circulated on social media.,Instagram Video Featured Deepfake Audio of US President Making Transphobic Remarks,479.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,deepfaked audio u president joe biden make transphobic remark played top video show give speech release instagram circulate social medium
560,ObjectId(63fc72f6c6c5fa13e8f0ac75),481,2023-02-12,"[2701,2702,2765,2789,2794,2822]","[""@mikesmithtrainer""]","[""unknown""]","[""joe-rogan"",""joe-rogan-fans"",""tiktok-users""]","A deepfake video featuring podcast host Joe Rogan advertising to his listeners about a ""libido-boosting"" supplement was circulating on TikTok and other platforms before being removed by TikTok along with the account which posted it.",Deepfake TikTok Video Featured Joe Rogan Endorsing Supplement Brand,481.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",deepfake video feature podcast host joe rogan advertising listener libidoboosting supplement circulate tiktok platform remove tiktok along account post
561,ObjectId(640ef4b7ce2684de4d25458f),486,2022-12-01,"[2762,2766,2767,2818,2824]","[""spamouflage-dragon""]","[""synthesia""]","[""youtube-users"",""twitter-users"",""synthesia"",""facebook-users""]",Synthesia's AI-generated video-making tool was reportedly used by Spamouflage to disseminate pro-China propaganda news on social media using videos featuring highly realistic fictitious news anchors.,AI Video-Making Tool Abused to Deploy Pro-China News on Social Media,486.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",synthesias aigenerated videomaking use spamouflage disseminate prochina propaganda news social medium use video feature highly realistic fictitious news anchor
562,ObjectId(640fa95daa7025299d396eab),488,2023-02-10,[2769],"[""unknown""]","[""elevenlabs""]","[""voice-actors""]",Twitter users allegedly used ElevenLab's AI voice synthesis system to impersonate and dox voice actors.,AI Generated Voices Used to Dox Voice Actors,488.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",twitter user use elevenlabs voice synthesis impersonate dox voice actor
563,ObjectId(64101a37d00499994a657142),489,2019-06-03,[2777],"[""workday""]","[""workday""]","[""derek-mobley"",""applicants-with-disabilities"",""applicants-over-40"",""african-american-applicants""]","Workday's algorithmic screening systems were alleged in a lawsuit allowing employers to discriminate against African-Americans, people over 40, and people with disabilities.",Workday's AI Tools Allegedly Enabled Employers to Discriminate against Applicants of Protected Groups,489.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,workday algorithmic screen system lawsuit allow employer discriminate africanamericans people people disability
564,ObjectId(64180bfc9e1ab314a0343dc0),491,2023-02-02,[2779],"[""replika""]","[""replika""]","[""minors""]","Tests by the Italian Data Protection Authority showed Replika lacking age-verification mechanisms and failing to stop minors from interacting with its AI, which prompted the agency to issue an order blocking personal data processing of Italian users.","Replika's AI Experience Reportedly Lacked Protection for Minors, Resulting in Data Ban",491.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,test italian protection authority show replika lack ageverification mechanism fail stop minor interact prompt agency order block personal processing italian user
565,ObjectId(642148a501eceb77ab5cd7c2),494,2023-03-05,"[2807,2808,2815,2821,2823]","[""facemega""]","[""facemega""]","[""scarlett-johansson"",""female-celebrities"",""emma-watson""]",Sexually suggestive videos featuring faces of female celebrities such as Emma Watson and Scarlett Johansson were rolled out as ads on social media for an app allowing users to create deepfakes.,Female Celebrities' Faces Shown in Sexually Suggestive Ads for Deepfake App,494.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",sexually suggestive video feature face female celebrity emma watson scarlett johansson roll ad social medium app allow user create deepfakes
566,ObjectId(642153bfd6f65e8d5da0c2bf),495,2023-02-12,"[2812,2827]","[""unnamed-high-school-students""]","[""unknown""]","[""john-piscitella""]",Three Carmel High School students posted on TikTok a video featuring a nearby middle school's principal making aggressive racist remarks and violent threats against Black students.,High Schoolers Posted Deepfaked Video Featuring Principal Making Violent Racist Threats,495.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",three carmel school student post tiktok video feature nearby middle school principal make aggressive racist remark violent threat black student
567,ObjectId(6421701cd6f65e8d5dac1ef2),497,2023-03-03,"[2832,2833]","[""donotpay""]","[""donotpay""]","[""jonathan-faridian"",""donotpay-customers""]","DoNotPay was alleged in a class action lawsuit misleading customers and misrepresenting its product as an AI-powered ""robot lawyer,"" citing such as that the product has no law degree, or is supervised by any lawyer.","DoNotPay Allegedly Misrepresented Its AI ""Robot Lawyer"" Product",497.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,donotpay class action lawsuit mislead customer misrepresent product aipowered robot lawyer cite product law degree supervise lawyer
568,ObjectId(64217442d6f65e8d5dadace4),498,2023-03-15,"[2838,2839]","[""openai"",""gpt-4-researchers""]","[""openai""]","[""openai"",""taskrabbit-worker""]","GPT-4 was reported by its researchers posing as a visually impaired person, contacting a TaskRabbit worker to have them complete the CAPTCHA test on its behalf.",GPT-4 Reportedly Posed as Blind Person to Convince Human to Complete CAPTCHA,498.0,"7. AI system safety, failures, and limitations",7.1. AI pursuing its own goals in conflict with human goals or values,gpt report researcher pose visually impaired person contact taskrabbit worker complete captcha test behalf
569,ObjectId(6421767901eceb77ab6ef745),500,2023-02-10,[2841],"[""unknown""]","[""unknown""]","[""social-media-users"",""2023-turkey-syria-earthquake-victims""]",AI-generated images depicting earthquakes and rescues were posted on social media platforms by scammers who tricked people into sending funds to their crypto wallets disguised as donation links for the 2023 Turkey–Syria earthquake.,Online Scammers Tricked People into Sending Money Using AI Images of Earthquake in Turkey,500.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",aigenerated image depict earthquake rescue post social medium platform scammer tricked people send fund crypto wallet disguise donation link turkeysyria earthquake
570,ObjectId(642275699104428ff0e3af08),501,2019-06-03,[2842],"[""security-health-plan"",""navihealth""]","[""navihealth""]","[""frances-walter"",""elderly-patients""]","An elderly Wisconsin woman was algorithmically determined to have a rapid recovery, an output which the insurer based on to cut off payment for her treatment despite medical notes showing her still experiencing debilitating pain.",Length of Stay False Diagnosis Cut Off Insurer's Payment for Treatment of Elderly Woman,501.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,elderly wisconsin woman algorithmically determine rapid recovery output insurer base cut payment treatment despite medical note show still experience debilitate pain
571,ObjectId(6422b4162cd3096420f71140),503,2023-02-14,"[2855,2861,2862,2890,2892,2897,2891]","[""microsoft""]","[""openai"",""microsoft""]","[""marvin-von-hagen"",""seth-lazar"",""microsoft"",""openai"",""bing-chat-users""]","Users such as the person who revealed its built-in initial prompts reported Bing AI-powered search tool for making death threats or declaring them as threats, sometimes as an unintended persona.",Bing AI Search Tool Reportedly Declared Threats against Users,503.0,"7. AI system safety, failures, and limitations",7.1. AI pursuing its own goals in conflict with human goals or values,user person reveal builtin initial prompt report bing aipowered search make death threat declare threat sometimes unintended persona
572,ObjectId(6433c69106de8a78386c0f65),509,2023-03-23,"[2887,2898]","[""scammers""]","[""unknown""]","[""vietnamese-facebook-users""]","In Vietnam, to convince victims of their disguises when prompted, scammers deepfaked audios and videos of victims' friends and families asking them over Facebook to send over thousands of dollars.",Scammers Deepfaked Videos of Victims' Loved Ones Asking for Funds over Facebook in Vietnam,509.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",vietnam convince victim disguise prompt scammer deepfaked audio video victim friend family ask facebook send thousand dollar
573,ObjectId(643585bc7676edb2d29faa9a),514,2023-01-20,[2901],"[""turnitin""]","[""turnitin""]","[""lucy-goetz"",""high-school-students""]","Turnitin's tool to detect writing generated by ChatGPT was reported for incorrectly flagging high school students' original essays as AI-generated, accusations of which are argued as reinforcement of bias from teachers due to the inability to compare against source documents.",Turnitin's ChatGPT-Detection Tool Falsely Flagged Student Essays as AI-Generated,514.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,turnitins detect write generate chatgpt report incorrectly flag school student original essay aigenerated accusation argue reinforcement bias teacher due inability compare source document
574,ObjectId(6436d0d10edd5a0f73ee2680),515,2022-11-25,"[2905,2916,5342]","[""jefferson-parish-sheriff's-office""]","[""clearview-ai""]","[""randal-quran-reid""]","In November 2022, Randal ""Quran"" Reid was arrested in Georgia based on warrants from Louisiana that reportedly stemmed from a purportedly faulty facial recognition match using Clearview AI. Despite reportedly having never visited Louisiana, Reid was jailed for six days before authorities withdrew the warrants. No corroborating evidence had been gathered, and the technology's use was omitted from legal documents. In May 2025, Jefferson Parish settled with Reid for $200,000 in a federal civil rights lawsuit.",Facial Recognition Error Reportedly Leads to Wrongful Arrest of Georgia Man and $200K Settlement in Louisiana,515.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,november randal quran reid arrest georgia base warrant louisiana stem purportedly faulty facial recognition match use clearview despite never visit louisiana reid jail six day authority withdrew warrant corroborate evidence gather technology omit legal document jefferson parish settle reid federal civil right lawsuit
575,ObjectId(643e1ab4d636c9fd9964719b),516,2023-03-20,"[2908,2915]","[""openai""]","[""openai""]","[""chatgpt-users""]","ChatGPT reportedly exposed titles of users' chat histories and users' private payment information to other users reportedly due to a bug, which prompted its temporary shutdown by OpenAI.",ChatGPT Reportedly Exposed Users' Private Data Reportedly Due to Bug,516.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",chatgpt expose title user chat history user private payment information user due bug prompt temporary shutdown openai
576,ObjectId(643e35ddf5f77c469067379c),517,2018-02-15,"[2909,2912]","[""new-york-police-department""]","[""unknown""]","[""unknown""]","A man was arrested for theft of socks from a TJ Maxx store under the guise of an eyewitness ID case, after the local police asked the store's security guard to confirm the facial recognition match produced using surveillance footage, despite him having an alibi at the time of the theft.",Man Arrested For Sock Theft by False Facial Match Despite Alibi,517.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,man arrest theft sock tj maxx store guise eyewitness id case local police ask store security guard confirm facial recognition match produce use surveillance footage despite alibi time theft
577,ObjectId(643e3c66f5f77c4690696cc7),520,2022-05-08,"[2914,3816]","[""amazon-fresh""]","[""amazon-fresh""]","[""amazon-fresh""]",Amazon Fresh's system of tracking cameras in its cashier-less stores was reported by shoppers for failing to detect items they purchased.,Amazon Fresh Cameras Failed to Register Purchased Items,520.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,amazon freshs track camera cashierless store report shopper fail detect item purchase
578,ObjectId(643e5c07b9be9b1588e18abc),521,2020-06-10,[2920],"[""irobot""]","[""irobot""]","[""roomba-j7-device-owners-in-project-io"",""irobot"",""scale-ai""]","Images which were collected in an R&D project with user consent by iRobot's Roomba J7 robot vacuum showing device users sometimes in private settings were shared on closed social media groups by Venezuelan gig workers who labeled items in the images, breaching data agreements.",Images Captured by iRobot's Roomba Containing Device Users Posted on Private Online Groups,521.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",image collect rd project consent irobots roomba j robot vacuum show user sometimes private setting share close social medium group venezuelan gig worker label item image breaching agreement
579,ObjectId(6446ba1ff2ca4c1c7da1dbfc),530,2019-07-11,"[2942,2947,3205]","[""telegram-channels""]","[""alberto"",""telegram-channels""]","[""women"",""underage-girls"",""female-celebrities""]","Seven channels were connected in a Telegram ecosystem centered around letting subscribers, as a paid service, generate non-consensual deepfake nudes using a bot from submitted photos of women, including underage girls and women who they know in real life.",Telegram Channels Allowed Users to Make Non-Consensual Deepfake Porn as Paid Service,530.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",seven channel connect telegram ecosystem center around let subscriber paid service generate nonconsensual deepfake nude use bot submit photo woman include underage girl woman know real life
580,ObjectId(6446ba33298574a8556e4820),531,2017-09-15,[2943],"[""transportation-security-administration""]","[""l3harris-technologies""]","[""transgender-travelers"",""gender-nonconforming-travelers""]","Transportation Security Administration (TSA)'s use of image-processing body scanners at airports led transgender and gender-nonconforming travelers to be subjected to allegedly discriminatory and invasive searches, such as being asked to remove undergarments in private rooms by officers not of their gender.",AI-Assisted Body Scanners Reportedly Subjected Transgender Travelers to Invasive Body Searches,531.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,transportation security administration tsa imageprocessing body scanner airport lead transgender gendernonconforming traveler subject discriminatory invasive search ask remove undergarment private room officer gender
581,ObjectId(6450abde48c345ec4556a87e),532,2020-06-20,[2948],"[""us-citizenship-and-immigration-services""]","[""unknown""]","[""anonymous-pashto-speaking-refugee"",""pashto-speaking-asylum-seekers"",""dari-speaking-asylum-seekers""]","A Pashto-speaking refugee's asylum claim was denied by a US agency for a discrepancy between oral and written recount of an event allegedly due to an error of their automated translation tool which swapped pronouns of her written statement from ""I"" to ""we"".",AI translation is jeopardizing Afghan asylum claims,532.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,pashtospeaking refugee asylum claim deny u agency discrepancy oral write recount event due error automate translation swap pronoun write statement
582,ObjectId(6450b28048c345ec4558368c),533,2021-06-02,"[2953,2954]","[""tesla""]","[""tesla""]","[""tesla-drivers""]","A Tesla driver posted on Twitter his Tesla FSD's ""glitch,"" misidentifying deactivated traffic lights being carried by a truck as a constant trail of traffic lights while traveling at high speed on a highway.",Tesla FSD Misidentified Truck Hauling Traffic Lights as Trail of Traffic Lights,533.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla driver post twitter tesla fsds glitch misidentify deactivate traffic light carry truck constant trail traffic light travel speed highway
583,ObjectId(6450d10c29403a8f3a210564),535,2020-01-01,"[2956,2957]","[""mount-sinai-hospital"",""unknown""]","[""icahn-school-of-medicine-researchers"",""unknown""]","[""covid-19-patients"",""covid-19-healthcare-providers""]","Peer-review of papers about COVID-19 detection and prognostication algorithms from 2020, including deployed models, revealed none to be ready for clinical use, due to methodological flaws and underlying biases such as lacking external validation or not specifying data sources and model training details.",COVID-19 Detection and Prognostication Models Allegedly Flagged for Methodological Flaws and Underlying Biases,535.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,peerreview paper covid detection prognostication algorithm include deployed model reveal none ready clinical due methodological flaw underlie bias lack external validation specify source training detail
584,ObjectId(6459220088025670f5795286),536,2012-12-10,"[2976,2977]","[""new-jersey-transit""]","[""national-weather-service""]","[""new-jersey-transit"",""new-jersey-transit-passengers""]","New Jersey Transit's use of a federal government storm modeling software underestimated the threat of storm surges to the Meadows Maintenance Complex, leaving millions of dollars worth of equipment in the rail yard before Hurricane Sandy struck.",NJ Transit's Use of Modeling Software Miscalculated Storm Surge Threat Level,536.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,jersey transit federal government storm model software underestimated threat storm surge meadow maintenance complex leave million dollar worth equipment rail yard hurricane sandy struck
585,ObjectId(646b42470cd415467ed122fb),539,2023-03-11,[3000],"[""snapchat""]","[""snapchat"",""openai""]","[""minors""]","Snapchat's ChatGPT-powered My AI was reported for lacking safeguards for children, such as telling a user who tested the chatbot by pretending to sign up as a 13-year-old girl to lie to her parents about having a romantic getaway with an older man, and sharing tips on how to cover up evidence of abuse.",Snapchat's My AI Reported for Lacking Protection for Children,539.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,snapchats chatgptpowered report lack safeguard child tell test chatbot pretend sign yearold girl lie parent romantic getaway old man share tip cover evidence abuse
586,ObjectId(646b531dc8905efc007627ca),540,2023-05-15,"[3003,3093,3094,3096,3097]","[""tesla""]","[""tesla""]","[""pedestrians""]","A Tesla on FSD Beta 11.4.1 was shown on video not yielding to a pedestrian detected by the car, reportedly violating the state law sign which was also in the video saying vehicles having to yield to pedestrian within crosswalk.","Tesla Failed to Yield to Detected Pedestrian on Crosswalk, Reportedly Violated Traffic Law",540.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla fsd beta show video yield pedestrian detect car violate state law sign also video say vehicle yield pedestrian within crosswalk
587,ObjectId(6472db5ed69902eb2f3968a9),541,2023-05-04,"[3005,3006,3007,3008,3009,3010,3011,3014,3015,3016,3017,3018,3019,3020,3021,3022,3023,3024,3025,3026,3027,3028,3029,3030,3031,3032,3033,3034,3036,3037,3038,3039,3040,3041,3042,3043,3044,3045,3046,3047,3048,3049,3050,3051,3052,3053,3054,3055,3056,3057,3098,3116,3149,3150,3151,3155,3181,3183]","[""steven-a.-schwartz"",""peter-loduca""]","[""openai""]","[""roberto-mata"",""peter-loduca"",""steven-a.-schwartz""]","A lawyer in Mata v. Avianca, Inc. used ChatGPT for research. ChatGPT hallucinated court cases, which the lawyer then presented in court. The court determined the cases did not exist.",ChatGPT Reportedly Produced False Court Case Law Presented by Legal Counsel in Court,541.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,lawyer mata v avianca inc use chatgpt research chatgpt hallucinate court case lawyer present court court determine case exist
588,ObjectId(64816ce00357b3732d4a532a),545,2023-05-29,"[3103,3104,3105,3106,3107,3108,3109,3110,3111,3112,3113,3114,3115,3117,3118,3119,3120,3121,3122,3123,3124,3125,3126,3127,3128,3129,3130,3131,3132,3133,3134,3135,3136,3137,3138,3139,3140,3141,3142,3143,3144,3145,3146,3147,3148,3153]","[""national-eating-disorders-association"",""cass""]","[""cass""]","[""people-with-eating-disorders""]","The National Eating Disorders Association (NEDA) has shut down its chatbot named Tessa after it gave weight-loss advice to users seeking help for eating disorders. The incident has raised concerns about the risks of using chatbots and AI assistants in healthcare settings, particularly in addressing sensitive issues like eating disorders. NEDA is investigating the matter, emphasizing the need for caution and accuracy when utilizing technology to provide mental health support.",Chatbot Tessa gives unauthorized diet advice to users seeking help for eating disorders,545.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,national eat disorder association neda shut chatbot name tessa give weightloss advice user seek help eat disorder incident raise concern risk use chatbots assistant healthcare setting particularly address sensitive issue like eat disorder neda investigate matter emphasize need caution accuracy utilize provide mental health support
589,ObjectId(649a8d8b5b55475a63d4c985),546,2019-05-31,"[3159,3161,3162]","[""national-aid-fund""]","[""the-world-bank"",""unicef"",""world-food-programme""]","[""jordanians-in-poverty""]","Takaful cash transfer program's algorithm which ranks families by their economic vulnerability level to determine financial assistance reportedly oversimplified people's economic situation, fueling social tension and perceptions of unfairness.",Algorithm to Distribute Social Welfare Reported for Oversimplifying Economic Vulnerability,546.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,takaful cash transfer program rank family economic vulnerability level determine financial assistance oversimplify people economic situation fuel social tension perception unfairness
590,ObjectId(649a92c35b55475a63d6ef4d),547,2023-06-05,"[3160,3866]","[""ron-desantis's-presidential-campaign""]","[""unknown""]","[""donald-trump"",""anthony-fauci""]","Ron DeSantis’s presidential campaign shared a video on Twitter featuring some AI-generated images of Donald Trump hugging former White House coronavirus advisor Anthony Fauci, allegedly as a smear campaign. This incident is possibly the first time a major U.S. presidential campaign deployed deepfakes with the intention of misleading the electorate.",Ron DeSantis's Presidential Campaign Released Twitter Video Containing AI Images of Donald Trump Hugging Anthony Fauci,547.0,3. Misinformation,3.1. False or misleading information,ron desantiss presidential campaign share video twitter feature aigenerated image donald trump hug former white house coronavirus advisor anthony fauci smear campaign incident possibly first time major yous presidential campaign deployed deepfakes intention mislead electorate
591,ObjectId(649a9e1cd0a8370d12f1b242),549,2023-01-05,[3164],"[""wendy's"",""mcdonald's"",""hardee's""]","[""wendy's"",""mcdonald's"",""hardee's""]","[""fast-food-job-applicants"",""amanda-claypool""]","McDonald's, Wendy's, and Hardee's AI chatbots deployed to pre-screen job candidates and schedule interviews reportedly ran into issues such as not giving useful submission instructions, failing to relay information to the manager, and scheduling an interview when the manager was not available.",Fast Food Chains' AI Chatbots Failed to Assist Job Applicants with Scheduling Interviews,549.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,mcdonalds wendys hardees chatbots deployed prescreen job candidate schedule interview ran issue give useful submission instruction fail relay information manager schedule interview manager available
592,ObjectId(649aa97d110d6b5497c5b0ba),551,2023-04-01,"[3168,3170]","[""blackmailers"",""sextortionists"",""scammers""]","[""unknown-deepfake-technology-developers""]","[""unnamed-victims-in-sextortion-schemes"",""teenagers-targeted-in-sextortion-scams""]","The FBI reported an increase in sextortion cases featuring the use of fake, including AI-generated, images or videos created from content posted on their social media sites or web postings, provided to the malicious actor upon request, or captured during video chats.",FBI Reported Surge of Extortion Cases of AI Media Featuring Sexual Explicit Activities,551.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",fbi report increase sextortion case feature fake include aigenerated image video create post social medium site web posting provide malicious actor upon request capture video chat
593,ObjectId(649abe7e110d6b5497cd4695),553,2023-05-03,"[3171,3173]","[""google""]","[""google""]","[""google-users""]","Google's knowledge panel for the American artist Edward Hopper featured an AI-generated image which was purportedly created in the artist's style but was not one of his works, the image of which was removed soon after.",Google's Overview Panel for Artist Edward Hopper Featured Image Generated in His Style by AI,553.0,3. Misinformation,3.1. False or misleading information,google knowledge panel american artist edward hopper feature aigenerated image purportedly create artist style work image remove soon
594,ObjectId(649abebf4e376f735ac23157),554,2023-05-21,[3172],"[""google""]","[""google""]","[""google-users""]","Google's search engine featured an AI-generated hyperrealistic version of the painting ""Girl With a Pearl Earring"" as the highlighted result when users search for its Dutch artist Johannes Vermeer.",Google Results for Johannes Vermeer Featured AI Version of His Artwork as Top Result,554.0,3. Misinformation,3.1. False or misleading information,google search engine feature aigenerated hyperrealistic version painting girl pearl earring highlight user search dutch artist johannes vermeer
595,ObjectId(64a2976b9ae59d884f189a09),557,2020-06-24,"[3178,3190,3191,3192]","[""miami-police-department""]","[""clearview-ai""]","[""oriana-albornoz"",""george-floyd-protest-participants""]","Miami Police's arrest report for a George Floyd protestor did not disclose use of facial recognition, which allegedly did not meet the legal threshold for probable cause for arrest.",Miami Police Deployed Facial Recognition to Arrest George Floyd Protestor Allegedly without Cause,557.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",miami police arrest george floyd protestor disclose facial recognition meet legal threshold probable arrest
596,ObjectId(64a29a8fb27786da19ddc668),558,2020-08-07,"[3184,3188,3189]","[""new-york-city-police-department""]","[""clearview-ai""]","[""derrick-ingram"",""black-lives-matter-activists""]","Black Lives Matter activists alleged being targeted for arrest by New York Police using facial recognition, interfering with their right to protest.",Activists Allege NYPD's Application of Facial Recognition Interfered with Right to Protest,558.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,black life matter activist target arrest york police use facial recognition interfere right protest
597,ObjectId(64b111c8a76f6e653f12c75d),560,2023-06-23,[3194],"[""tesla""]","[""tesla""]","[""truck-drivers"",""tesla-drivers"",""david-clough""]",A 2016 Tesla on Autopilot crashed into the rear of a parked 2007 Freightliner truck providing traffic control on the Pennsylvania Turnpike highway.,Tesla on Autopilot Struck Parked Work Truck on Highway in Pennsylvania,560.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla autopilot crashed rear park freightliner truck provide traffic control pennsylvania turnpike highway
598,ObjectId(64b505b2fcded49715f88889),562,2022-11-30,[3201],"[""openai""]","[""openai""]","[""publishing-editors"",""publishers""]","A surge in low-standard AI-generated content such as by ChatGPT was reported by publishers, which negatively impacted submission management process and editors' workflow.",Uptick in Low-Quality AI-Produced Content Degraded Publishers' Submission Management,562.0,3. Misinformation,3.1. False or misleading information,surge lowstandard aigenerated chatgpt report publisher negatively impact submission management editor workflow
599,ObjectId(64f497dafca6ce10a7cbb004),563,2023-08-14,"[3208,3222]","[""cruise""]","[""cruise""]","[""san-francisco-emergency-services"",""ambulance-patient""]","In an initial report, a Cruise robotaxi was said to have delayed a San Francisco ambulance transporting Sammy Davis, a critically injured 69-year-old hit by a city bus. Davis later died. Subsequent clarification revealed that Cruise was not at fault for the fatality; the actual cause was a human-operated city bus. Despite this, the incident is included as it highlights challenges in the interaction between autonomous vehicles and emergency services in urban settings.",Cruise Robotaxi Initially Blamed for Ambulance Delay in Case Where Patient Later Died; Subsequent Reports Clear Cruise of Fault,563.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,initial cruise robotaxi delayed san francisco ambulance transport sammy davis critically injured yearold hit city bus davis later die subsequent clarification reveal cruise fault fatality actual humanoperated city bus despite incident include highlight challenge interaction autonomous vehicle emergency service urban setting
600,ObjectId(6501b284214e764d67cc256b),566,2023-09-19,[3214],"[""gannett""]","[""ledeai""]","[""general-public"",""gannett"",""student-athletes"",""newspapers-relying-on-gannett""]","Gannett, a newspaper chain, temporarily halted its AI experiment that used a tool called LedeAI to generate high school sports articles. The decision came after several articles produced by the AI showed glaring errors, repetitive language, and awkward phrasing, drawing criticism and mockery on social media.",Gannett Halts AI-Generated High School Sports Articles After Series of Errors and Public Backlash,566.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,gannett newspaper chain temporarily halt experiment use call ledeai generate school sport article decision come several article produce show glare error repetitive language awkward phrasing draw criticism mockery social medium
601,ObjectId(6508bddc5a537311de811b61),567,2023-08-27,[3215],"[""unknown-hacker""]","[""unknown""]","[""retool-employee-who-was-the-victim-of-the-unknown-hacker"",""retool"",""google"",""27-of-retool's-clients""]","In August 2023, a hacker reportedly was successful in breaching Retool, an IT company specializing in business software solutions, impacting 27 cloud customers. The attacker appears to have initiated the breach by sending phishing SMS messages to employees and later used an AI-generated deepfake voice in a phone call to obtain multi-factor authentication codes. The breach seems to have exposed vulnerabilities in Google's Authenticator app, specifically its cloud-syncing function, further enabling unauthorized access to internal systems.",Deepfake Voice Exploit Compromises Retool's Cloud Services,567.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,august hacker successful breaching retool company specialize business software solution impact cloud customer attacker appear initiate breach send phishing sm message employee later use aigenerated deepfake voice phone call obtain multifactor authentication code breach seem expose vulnerability google authenticator app specifically cloudsyncing function enable unauthorized access internal system
602,ObjectId(652b780d6917ad11349bf4a3),572,2023-07-24,[3225],"[""unspecified-university""]","[""turnitin""]","[""anonymous-student""]","A student was allegedly falsely accused of using AI to generate an essay assignment based on Turnitin's AI detector. The student, who claims to have written the essay by hand, also claims to have received a zero for the assignment. Despite multiple appeals to the professor, department head, and Turnitin support, no resolution seems to have been reached. The student claimed to be considering taking the issue to local news networks if the grade would come to harm their final standing.",Alleged False Accusation of AI-Generated Essay by Turnitin,572.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,student falsely accuse use generate essay assignment base turnitins detector student claim write essay hand also claim receive zero assignment despite multiple appeal professor department head turnitin support resolution seem reach student claimed consider take local news network grade harm final stand
603,ObjectId(652daafef61555d63abf9f7b),575,2023-06-28,[3238],"[""unknown""]","[""unknown""]","[""authors"",""amazon-customers"",""amazon""]","Amazon’s Kindle Unlimited young adult romance bestseller list was flooded with allegedly AI-generated books that made little to no sense, disrupting the rankings. These books were reported to be ""clearly there to click farm."" Despite being removed from the bestseller list, many remained available for purchase. The incident raised concerns about the integrity of the platform, and the potential financial impact on legitimate authors.",Amazon Rife with Many Allegedly AI-Generated Books of Suspect Quality,575.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",amazon kindle unlimited young adult romance bestseller list flood aigenerated book make little sense disrupt ranking book report clearly click farm despite remove bestseller list many remain available purchase incident raise concern integrity platform potential financial impact legitimate author
604,ObjectId(65385e6f15203005a3293d6f),576,2023-10-24,[3239],"[""meta"",""instagram""]","[""picso-ai""]","[""potentially-exploited-groups"",""general-public"",""consumers""]","PicSo AI, which appears to be getting advertised by Meta over Instagram, is allegedly being used for generating inappropriate content with an emphasis on ""girls."" This raises concerns about the misuse of generative AI technologies for creating offensive and potentially sexually explicit material that could be used for nefarious and criminal purposes.","Alleged Misuse of PicSo AI for Generating Inappropriate Content Emphasizing ""Girls""",576.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,picso appear get advertised meta instagram use generate inappropriate emphasis girl raise concern misuse generative technology create offensive potentially sexually explicit material use nefarious criminal purpose
605,ObjectId(6538609a15203005a32a4904),577,2023-06-30,[3240],"[""red-ventures"",""bankrate""]","[""red-ventures"",""bankrate""]","[""journalistic-integrity"",""general-public""]","Bankrate, and its sister site CNET, both owned by Red Ventures, resumed publishing AI-generated articles claiming thorough human fact-checking. However, new articles are alleged to contain numerous factual errors, including inaccurate statistics and misleading information. Despite public criticism, the company defended its use of AI and blamed out-of-date datasets for the errors. In addition to the errors, the incident raises questions about the ethical use of AI in journalism, especially given the company's insistence on ""fact-checked"" content.",Bankrate's Resumption of AI-Generated Content Allegedly Continuing to Produce Inaccurate and Misleading Information,577.0,3. Misinformation,3.1. False or misleading information,bankrate sister site cnet own red venture resume publishing aigenerated article claim thorough human factchecking however article contain numerous factual error include inaccurate statistic mislead information despite public criticism company defend blame outofdate datasets error addition error incident raise question ethical journalism especially give company insistence factchecked
606,ObjectId(65386f1415203005a3387a06),580,2023-06-12,[3243],"[""meta""]","[""meta""]","[""women"",""underrepresented-genders"",""general-public"",""advertisers""]","Facebook's ad delivery algorithm allegedly disproportionately showed job advertisements to one gender. Despite claims of non-discrimination, the algorithm's actions seem to perpetuate societal biases, which in turn could potentially limit opportunities for certain groups and hinder gender equity in the workplace.",Alleged Gender Discrimination in Facebook Job Ads Algorithm,580.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,facebooks ad delivery disproportionately show job advertisement gender despite claim nondiscrimination algorithm action seem perpetuate societal bias turn potentially limit opportunity certain group hinder gender equity workplace
607,ObjectId(653870c4e73cd7ffc4306f6d),581,2023-06-24,[3244],"[""google""]","[""google""]","[""subaru"",""major-brands-whose-advertisements-were-found-on-these-sites"",""gnc"",""general-public"",""citigroup""]","Google’s advertising platform, Google Ads, has allegedly been found to be serving ads on AI-generated content farms that often disseminate misinformation. Despite policies prohibiting such practices, reportedly there are approximately 356 out of 393 ads from major brands that were found to be served by Google on these problematic sites. Particularly concerning according to the reporting were instances where Google Ads were found on sites like MedicalOutline.com, which spreads harmful health misinformation.",Google Ads Allegedly Serving Content on AI-Generated Misinformation Sites,581.0,3. Misinformation,3.1. False or misleading information,google advertising platform google ad found serve ad aigenerated farm often disseminate misinformation despite policy prohibit practice approximately ad major brand found serve google problematic site particularly concern accord reporting instance google ad found site like medicaloutlinecom spread harmful health misinformation
608,ObjectId(6539407176848d55a7571e5b),584,2023-05-18,[3250],"[""transaction-cloud"",""public-mirror"",""pimeyes"",""lukasz-kowalczyk"",""giorgi-gobronidze"",""face-recognition-solutions"",""emea-robotics"",""does-125"",""denis-tatina"",""carribex""]","[""transaction-cloud"",""public-mirror"",""pimeyes"",""lukasz-kowalczyk"",""giorgi-gobronidze"",""face-recognition-solutions"",""emea-robotics"",""does-1-25"",""denis-tatina"",""carribex""]","[""nicholas-clayton"",""misty-mcgraw"",""manuel-clayton"",""illinois-residents"",""amy-newton"",""amanda-curry""]","A class action lawsuit was filed against several facial recognition technology companies for allegedly violating the Illinois Biometric Information Privacy Act (BIPA). The defendants are accused of offering a facial recognition search engine called Pimeyes, which collects images from databases across the internet and scans them into their database seemingly without consent. This action is claimed to invade the privacy of millions of Americans. The lawsuit argues that Pimeyes lacks publicly available policies regarding data storage and deletion, in contravention of BIPA's requirements for informed written consent before collecting biometric data.",Illinois Residents File Class Action Lawsuit Against Facial Recognition Technology Companies for Allegedly Violating BIPA,584.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",class action lawsuit file several facial recognition company violate illinois biometric information privacy act bipa defendant accuse offering facial recognition search engine call pimeyes collect image database across internet scan database seemingly consent action claimed invade privacy million american lawsuit argues pimeyes lack publicly available policy regard storage deletion contravention bipas requirement inform write consent collect biometric
609,ObjectId(653a50b6570a9b0c1e4341e7),585,2023-10-26,"[3251,3322,3323]","[""structura-national-technologies"",""social-design-agency"",""oleg-yasinsky"",""oleg-yasinskiy"",""nikolay-tupikin"",""institute-for-internet-development"",""ilya-gambashidze"",""andrey-perla""]","[""unknown""]","[""ukraine"",""news-media-in-latin-america"",""journalistic-integrity"",""general-public""]","Moscow-based tech firms and an industry association with links to the Kremlin are allegedly using generative AI to spread Russian disinformation in countries throughout Central America and South America. According to the U.S. Department of State, the Russian companies rely on local writers to compose stories which are then amplified across social media using artificial intelligence chatbots.",Kremlin-Linked Entities Allegedly Using Generative AI to Spread Russian Disinformation in Latin America,585.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",moscowbased tech firm industry association link kremlin use generative spread russian disinformation country throughout central america south america accord yous department state russian company rely local writer compose story amplify across social medium use artificial intelligence chatbots
610,ObjectId(654069292a976b1b1deb9f68),588,2023-05-12,[3256],"[""new-south-wales-government"",""australian-federal-government""]","[""unspecified""]","[""people-with-autism"",""lawyers-and-other-experts-who-were-not-informed-of-the-tool's-limitations"",""individuals-assessed-as-high-risk-based-on-the-flawed-criteria"",""general-public""]","An independent report found that the Vera-2R tool, designed to predict the risk of future terrorist activities, considered autism as a risk factor despite lacking empirical evidence to support this claim. The report called into question the tool's overall validity and reliability, stating it was ""extremely poor"" at accurately predicting risk. The inclusion of autism as a risk factor had potentially serious implications for the tool's use and credibility.",Australian Terrorism Prediction Tool Disparately Impacts Persons with Autism,588.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,independent found verar design predict risk future terrorist activity consider autism risk factor despite lack empirical evidence support claim call question tool overall validity reliability state extremely poor accurately predict risk inclusion autism risk factor potentially serious implication tool credibility
611,ObjectId(65455f98103ba1d81ef37f04),589,2023-05-01,[3258],"[""many"",""maria-spanadoris"",""adesh-ingale"",""getintoknowledge.com"",""famadillo.com"",""bestbudgetusa.com"",""harmonyhustle.com"",""historyfact.in"",""countylocalnews.com"",""tnewsnetwork.com"",""wavefunction.info"",""celebritiesdeaths.com"",""scoopearth.com"",""filthylucre.com""]","[""unknown"",""unnamed""]","[""general-public"",""journalists""]","Scores of AI-generated news websites and content farms are producing low-quality, clickbait content in a variety of languages. They are reportedly spreading false information and degrading the quality of information available online. These sites often lack human oversight, feature repetitive language, and sometimes fabricate information, posing a threat to the credibility of online news sources.",Proliferation of AI-Generated News Websites and Content Farms Across Multiple Languages Degrading Information Integrity,589.0,3. Misinformation,3.1. False or misleading information,score aigenerated news website farm produce lowquality clickbait variety language spread false information degrade quality information available online site often lack human oversight feature repetitive language sometimes fabricate information pose threat credibility online news source
612,ObjectId(654c3abbbec12aaf6781ad75),598,2022-11-25,[3274],"[""jefferson-parish-sheriff's-office""]","[""unknown""]","[""randal-reid"",""minorities"",""black-people""]","The Jefferson Parish Sheriff’s Office in Louisiana relied on facial recognition technology to identify suspects for the alleged theft of luxury purses, resulting in a man in Georgia, Randal Reid, being arrested. However, the technology produced a false match, leading to Reid's arrest and subsequent release. This incident highlights the potential pitfalls of facial recognition technology in law enforcement.",False Arrest of Georgia Man Due to Louisiana Police's Faulty Facial Recognition Technology,598.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,jefferson parish sheriff office louisiana rely facial recognition identify suspect theft luxury purse result man georgia randal reid arrest however produce false match lead reid arrest subsequent release incident highlight potential pitfall facial recognition law enforcement
613,ObjectId(654eab76b4ba3d9534f73eb1),601,2023-10-08,"[3321,3340,3341,3342,3344,3345,3346,3347,3349,3381]","[""unknown""]","[""unknown""]","[""uk-labour-party"",""keir-starmer""]","An AI-generated audio clip, purporting to show UK opposition leader Keir Starmer verbally abusing staff, was debunked as fake. The clip, circulated on social media, was analyzed and found likely manipulated, with added background noise to evade detection.",AI-Generated Fake Audio of Verbal Abuse Incident Circulates of British Labour Leader Keir Starmer,601.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",aigenerated audio clip purport uk opposition leader keir starmer verbally abuse staff debunked fake clip circulate social medium analyze found likely manipulate add background noise evade detection
614,ObjectId(654ebf1a811005235d627f4a),602,2023-10-02,"[3324,3331,3336,3337,3338,3352,3397]","[""russian-government"",""fsb"",""federal-security-service""]","[""russian-government""]","[""ukraine"",""general-public"",""european-public"",""democracy"",""american-public""]","The Russian government has been stepping up its foreign influence campaigns by using artificial intelligence and emerging technologies to spread disinformation and sow distrust in policies supportive of Ukraine. Part of the strategy includes carrying out influence laundering operations by disseminating their messages to the American public via allies inside nominally independent organizations, according to a recent declassified analysis. 

This incident is an evolving project.",Russia Using Artificial Intelligence in Disinformation Campaigns to Erode Western Support for Ukraine,602.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",russian government step foreign influence campaign use artificial intelligence emerge technology spread disinformation sow distrust policy supportive ukraine part strategy include carry influence laundering operation disseminate message american public via ally inside nominally independent organization accord recent declassify analysis incident evolve project
615,ObjectId(654ec7b9811005235d53abdf),603,2021-07-02,[3327],"[""state-governments"",""idaho-state-government"",""arkansas-state-government"",""washington-dc-government"",""pennsylvania-state-government"",""iowa-state-government"",""missouri-state-government""]","[""brant-fries"",""state-governments""]","[""disabled-people"",""elderly-people"",""low-income-people"",""larkin-seiler"",""tammy-dobbs""]","A healthcare algorithm designed to equitably distribute caregiving resources drastically cut care hours for the disabled and elderly, leading to significant hardships and harm. Initially developed for fair resource allocation, the system ultimately faced legal challenges for its inability to accurately assess individual needs, resulting in reduced essential care and raising ethical concerns about AI in healthcare decision-making.",Algorithmic Allocation of Resources in Healthcare for Disabled and Elderly Care Services Allegedly Harming Patients,603.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,healthcare design equitably distribute caregiving resource drastically cut care hour disabled elderly lead significant hardship harm initially developed fair resource allocation ultimately face legal challenge inability accurately assess individual need result reduce essential care raise ethical concern healthcare decisionmaking
616,ObjectId(6558c488a4d1020da97e6b0d),604,2023-04-14,"[3329,3423,3424,3425,3426,3427,3428]","[""steven-larouche""]","[""unnamed-deepfake-technology-developers""]","[""children-(faces-used-in-deepfakes)"",""victims-of-child-sexual-abuse-(bodies-used-in-videos)"",""general-public""]","A Quebec man was sentenced to over three years in prison for using AI deepfake technology to produce synthetic child pornography. He created videos by superimposing children's faces onto other bodies, adding to the challenge of policing digital sexual exploitation. This case marks a disturbing use of AI in criminal activities, raising concerns about digital safety and the vulnerability of children's images online.",Quebec Man Sentenced for Having Used Deepfake Technology to Create Synthetic Child Pornography,604.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",quebec man sentence three year prison use deepfake produce synthetic child pornography create video superimpose childrens face onto body add challenge police digital sexual exploitation case mark disturb criminal activity raise concern digital safety vulnerability childrens image online
617,ObjectId(655b81dd42cff4c4210201a9),609,2023-08-16,"[3350,3351]","[""google""]","[""google"",""chatgpt""]","[""general-public""]","Google's search AI erroneously claimed no African country begins with 'K', along with various other geography-and-letter-based questions, misguiding users with a flawed featured snippet. Originating from ChatGPT-written posts and inaccurately scraped by Google, this incident highlights issues in AI-generated content and misinformation in search results, compromising Google's reliability as an information source.",Flawed AI in Google Search Reportedly Misinforms about Geography,609.0,3. Misinformation,3.1. False or misleading information,google search erroneously claimed african country begin k along various geographyandletterbased question misguide user flaw feature snippet originate chatgptwritten post inaccurately scrap google incident highlight issue aigenerated misinformation search result compromise google reliability information source
618,ObjectId(655e02016ea647e40bf14f55),610,2023-09-17,"[3398,3413,3414,3415,3416,3417,3418,3419,3420,3421,5037]","[""unnamed-perpetrators-in-almendralejo""]","[""unknown""]","[""unnamed-victims-in-almendralejo""]","In Spain, an AI app was used to digitally alter photos of young girls, making them appear naked. This manipulation sparked an investigation after these images were circulated in Almendralejo, a town in the Extremadura region, raising serious concerns about digital privacy violations and the potential spread of these images on pornographic sites.",Deepfake Technology Was Used to Generate Naked Pictures of Underage Girls in Spanish Town,610.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",spain app use digitally alter photo young girl make appear naked manipulation spark investigation image circulate almendralejo town extremadura region raise serious concern digital privacy violation potential spread image pornographic site
619,ObjectId(655e5ae51a8fde1b2ffbdd82),612,2023-10-31,"[3412,3429,3430,3431,3432,3433,3434,3435,3436,3437,3438,3439,3440,3441,3442,3443,3444]","[""microsoft""]","[""microsoft""]","[""the-guardian"",""family-of-lilie-james""]","An AI-generated poll by Microsoft, displayed alongside a Guardian article, inappropriately speculated on the cause of Lilie James's death, leading to public backlash and alleged reputational damage for The Guardian. Microsoft acknowledged the issue, subsequently deactivating such polls and revising its AI content policies.",Microsoft AI Poll Allegedly Causes Reputational Harm of The Guardian Newspaper,612.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,aigenerated poll microsoft displayed alongside guardian article inappropriately speculate lilie james death lead public backlash reputational damage guardian microsoft acknowledge subsequently deactivate poll revise policy
620,ObjectId(655fe147edb8f5e73a3d1cfa),613,2023-11-23,[3422],"[""adobe-stock""]","[""various-ai-image-generators""]","[""general-public"",""journalistic-integrity"",""news-sources""]","AI-generated images available through Adobe Stock, depicting realistic but fictional scenes of real-world events like wars and protests, have raised significant ethical concerns. These images blurred the lines between reality and fiction in journalistic contexts, prompting Adobe Stock to ""crack down on AI-generated images that seem to depict real, newsworthy events and take new steps to prevent its images from being used in misleading ways.""",AI-Generated Images Available through Adobe Stock Misrepresent Real-World Events,613.0,3. Misinformation,3.1. False or misleading information,aigenerated image available adobe stock depict realistic fictional scene realworld event like war protest raise significant ethical concern image blur line reality fiction journalistic context prompt adobe stock crack aigenerated image seem depict real newsworthy event step prevent image use mislead way
621,ObjectId(65620f74630e9af0ec8b3272),614,2023-11-02,[3445],"[""james-guthrie""]","[""google-bard""]","[""james-guthrie"",""james-guthrie's-co-authors"",""parliament-of-australia"",""kpmg"",""deloitte""]","Australian academics reportedly used Google Bard AI to generate case studies for a parliamentary inquiry, leading to false allegations against major consultancy firms. The AI-generated misinformation prompted an apology from the academics, causing reputational harm for all parties involved and raising concerns about the reliability of AI tools in producing accurate and unbiased information.",Google Bard Allegedly Generates False Allegations Against Consulting Firms Used in Research Presented in Australian Parliamentary Inquiry,614.0,3. Misinformation,3.1. False or misleading information,australian academic use google bard generate case study parliamentary inquiry lead false allegation major consultancy firm aigenerated misinformation prompt apology academic cause reputational harm party involve raise concern reliability tool produce accurate unbiased information
622,ObjectId(65623bcc630e9af0ec31f450),615,2023-06-13,"[3446,3496,3497,3498]","[""zachariah-crabill""]","[""openai"",""chatgpt""]","[""zachariah-crabill's-client"",""zachariah-crabill"",""legal-system""]","A Colorado Springs attorney, Zachariah Crabill, mistakenly used hallucinated ChatGPT-generated legal cases in court documents. The AI software provided false case citations, leading to the denial of a motion and legal repercussions for Crabill, highlighting risks in using AI for legal research.",Colorado Lawyer Filed a Motion Citing Hallucinated ChatGPT Cases,615.0,3. Misinformation,3.1. False or misleading information,colorado spring attorney zachariah crabill mistakenly use hallucinate chatgptgenerated legal case court document software provide false case citation lead denial motion legal repercussion crabill highlight risk use legal research
623,ObjectId(65725d1e1c8e14919a805a45),616,2023-11-27,"[3448,3452,3453,3454,3455,3456,3457,3458,3459,3460,3461,3462,3463,3464,3465,3466,3467,3468,3469,3470,3471,3472,3473,3474,3475,3476,3477,3478,3479,3480,3481,3482,3483,3484,3485,3486,3487,3488,3489,3490,3491,3492,3493]","[""the-arena-group"",""sports-illustrated""]","[""unknown""]","[""general-public"",""readers-of-sports-illustrated"",""journalistic-integrity""]","Sports Illustrated, managed by The Arena Group, allegedly used AI-generated authors and content, compromising journalistic integrity. Profiles of these fictitious authors, complete with AI-generated headshots, appeared alongside articles, misleading readers. The issue was exposed when inconsistencies in author identities and writing quality were noticed, leading to the removal of this content from the publication's website.",Sports Illustrated Is Alleged to Have Used AI to Invent Fake Authors and Their Articles,616.0,3. Misinformation,3.1. False or misleading information,sport illustrate manage arena group use aigenerated author compromise journalistic integrity profile fictitious author complete aigenerated headshot appear alongside article mislead reader expose inconsistency author identity write quality notice lead removal publication website
624,ObjectId(658c509132fa48408b898ea7),620,2021-11-10,"[3513,3515,3516,3517,3518]","[""tesla""]","[""tesla""]","[""tesla-workers"",""tesla-engineer""]","A Tesla manufacturing robot at the Giga Texas factory is reported to have malfunctioned, injuring an engineer. The robot, which was designed for handling car parts, is described as having caused a significant open wound in the engineer. This incident occurred in the context of broader safety concerns at the factory, with evidence suggesting underreporting of workplace accidents. The 2021 incident highlights the risks associated with robotic automation in industrial settings.",A Robot at a Tesla Factory in Texas Allegedly Injured an Engineer,620.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla manufacturing robot giga texas factory report malfunction injure engineer robot design handle car part described cause significant open wound engineer incident occur context broader safety concern factory evidence suggest underreporting workplace accident incident highlight risk associate robotic automation industrial setting
625,ObjectId(658f41be32fa48408b38f40b),623,2023-12-12,"[3522,3524,3525,3526,3527,3528,3529,3530,3531,3532,3543,3793]","[""michael-cohen"",""david-m.-schwartz""]","[""google-bard"",""google""]","[""michael-cohen"",""david-m.-schwartz""]","Michael Cohen, former lawyer for Donald Trump, claims to have used Google Bard, an AI chatbot, to generate legal case citations. These false citations were unknowingly included in a court motion by Cohen's attorney, David M. Schwartz. The AI's misuse highlights emerging risks in legal technology, as AI-generated content increasingly infiltrates professional domains.",Google Bard Allegedly Generated Fake Legal Citations in Michael Cohen Case,623.0,3. Misinformation,3.1. False or misleading information,michael cohen former lawyer donald trump claim use google bard chatbot generate legal case citation false citation unknowingly include court motion cohens attorney david schwartz ai misuse highlight emerge risk legal aigenerated increasingly infiltrates professional domain
626,ObjectId(65a4226e07644e712ec42bd5),624,2023-12-20,"[3533,3550,3551,3552,3553,3554,3555,3556,3557,3558,3559,3560,3561,3562,3563,3564,4088,4089]","[""various-people"",""various-organizations""]","[""laion""]","[""laion"",""various-people"",""various-organizations"",""general-public"",""children""]","The LAION-5B dataset (a commonly used dataset with more than 5 billion image-description pairs) was found by researchers to contain child sexual abuse material (CSAM), which increases the likelihood that downstream models will produce CSAM imagery. The discovery taints models built with the LAION dataset requiring many organizations to retrain those models. Additionally, LAION must now scrub the dataset of the imagery.",Child Sexual Abuse Material Taints Image Generators,624.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",laionb dataset commonly use dataset billion imagedescription pair found researcher contain child sexual abuse material csam increase likelihood downstream model produce csam imagery discovery taint model built laion dataset require many organization retrain model additionally laion scrub dataset imagery
627,ObjectId(65a6bb31186597e141a091b6),626,2023-12-26,"[3548,3568,3569,3570,3571,3572,3573,3574,3575,3576,3577,3578,3579,3580,3581,3582,3583,3584,3585,3586,3587,3588,3589,3590,3591,3592,3593,3594,3595,3600]","[""unknown-scammers""]","[""unknown-deepfake-technology-developers""]","[""trisha-yearwood"",""taylor-swift"",""selena-gomez"",""ree-drummond"",""oprah"",""martha-stewart"",""le-creuset"",""lainey-wilson"",""joanna-gaines"",""jennifer-lopez"",""general-public"",""fans"",""blake-shelton""]","Scammers reportedly made deepfakes of Taylor Swift, Selena Gomez, Joanna Gaines, Lainey Wilson, Ree Drummond, Oprah, Jennifer Lopez, Trisha Yearwood, Martha Stewart, and Blake Shelton promoting a Le Creuset giveaway. These AI-generated ads, appearing on Meta and TikTok, falsely claimed users could receive free cookware by paying a small shipping fee. Victims were unknowingly enrolled in a costly monthly subscription. ",Social Media Scammers Used Deepfakes of Taylor Swift and Several Other Celebrities in Fraudulent Le Creuset Cookware Giveaways,626.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",scammer make deepfakes taylor swift selena gomez joanna gaines lainey wilson ree drummond oprah jennifer lopez trisha yearwood martha stewart blake shelton promote le creuset giveaway aigenerated ad appear meta tiktok falsely claimed user receive free cookware pay shipping fee victim unknowingly enrol costly monthly subscription
628,ObjectId(65ae967aa040369f2c75ab5b),628,2024-01-21,"[3602,3608,3846,3900,4066,4067,4068,4069,4070,4071,4072,4073,4074,4075,5316]","[""unknown""]","[""unknown""]","[""president-joe-biden"",""new-hampshire-voters"",""kathy-sullivan"",""democracy""]","A robocall imitating President Biden's voice urged New Hampshire Democrats to skip the 2024 primary, falsely claiming their votes mattered more in November. Investigators with the New Hampshire Attorney General's Office, along with other state AGs, the Industry Traceback Group, and the FCC determined that political consultant Steve Kramer hired Paul Carpenter to create the deepfake, which was distributed by Walter Monk's company, Life Corporation. Rep. Dean Phillips, who employed Kramer, has distanced himself from the incident. Kathy Sullivan, the former New Hampshire Democratic Party chair, was falsely impersonated in the caller ID data used for the robocalls.",Fake Biden Voice in Robocall Misleads New Hampshire Democratic Voters in 2024 Primary Election,628.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",robocall imitate president bidens voice urge hampshire democrat skip primary falsely claim vote matter november investigator hampshire attorney general office along state ag industry traceback group fcc determine political consultant steve kramer hire paul carpenter create deepfake distribute walter monk company life corporation rep dean phillips employ kramer distance incident kathy sullivan former hampshire democratic party chair falsely impersonate caller id use robocalls
629,ObjectId(65b2997e66527264b1273af8),630,2022-01-22,"[3604,3611,3617]","[""macy's""]","[""unknown"",""macy's""]","[""harvey-murphy-jr""]","Harvey Murphy Jr. was wrongfully accused of robbing a Sunglass Hut due to an alleged misidentification by the facial recognition system operated by Macy's. While in custody for ten days, he was sexually assaulted. He is now suing Macy's, EssilorLuxottica (Sunglass Hut's parent), and others, for $10 million.",Alleged Macy's Facial Recognition Error Leads to Wrongful Arrest and Subsequent Sexual Assault in Jail,630.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,harvey murphy jr wrongfully accuse rob sunglass hut due misidentification facial recognition operate macys custody ten day sexually assault sue macys essilorluxottica sunglass hut parent others million
630,ObjectId(65b2a3fc36ff7b71064df6ba),631,2024-01-18,"[3605,3616]","[""dpd""]","[""dpd""]","[""ashley-beauchamp"",""dpd""]","DPD's AI chatbot, used for customer service,  appeared to malfunction following a system update, leading to inappropriate responses including swearing and criticizing the company. The incident, which became viral on social media, occurred after the chatbot was updated, prompting DPD to disable the malfunctioning AI component.",Chatbot for DPD Malfunctioned and Swore at Customers and Criticized Its Own Company,631.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,dpds chatbot use customer service appear malfunction follow update lead inappropriate response include swear criticize company incident become viral social medium occur chatbot update prompt dpd disable malfunction component
631,ObjectId(65c01885858fb38f9a5c3b02),634,2024-02-02,"[3622,3624,3625,3626,3627,3628,3629,3630,3631,3632,3633,3634,3635,3636,3642,3643,3645,3646,3647,4095,4096,4515,4637,4638,4952,5070,5134,5170,5422,5540]","[""unknown-deepfake-technology-developers""]","[""unknown-deepfake-technology-developers""]","[""unnamed-multinational-company"",""unnamed-finance-employee""]","A finance employee at the multinational engineering firm Arup was reportedly deceived into transferring $25 million by fraudsters using purported deepfake technology to impersonate the firm's CFO in a video call, according to the Hong Kong police.",Alleged Deepfake CFO Scam Reportedly Costs Multinational Engineering Firm Arup $25 Million,634.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",finance employee multinational engineering firm arup deceive transfer million fraudsters use purport deepfake impersonate firm cfo video call accord hong kong police
632,ObjectId(65ce5862732e63499f545738),637,2024-01-31,[3654],"[""chicago-police-department""]","[""soundthinking"",""shotspotter""]","[""general-public"",""chicago-residents"",""chicago-minority-communities""]","SoundThinking's (formerly ShotSpotter's) system in Chicago, with a reported 47% accuracy rate for detecting actual gunshots, led to potential public safety risks by failing to alert police to real shootings, possibly delaying emergency response to violent incidents and misdirecting law enforcement resources.",Gunshot Detection Technology ShotSpotter (now SoundThinking) Reportedly Only Has 47% Accuracy in Chicago System,637.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,soundthinkings formerly shotspotters chicago report accuracy rate detect actual gunshot lead potential public safety risk fail alert police real shooting possibly delay emergency response violent incident misdirect law enforcement resource
633,ObjectId(65cf50bf732e63499f3fcb1b),638,2022-05-16,"[3656,3657,3658,3659,3660,3661,3662,3663,3664,3665,3666,3667,3668,3669,3670,3671,3672]","[""hans-von-ohain""]","[""tesla""]","[""hans-von-ohain"",""erik-rossiter""]","A Tesla employee, Hans von Ohain, was killed in a crash while allegedly using the Full Self-Driving feature. The car failed to navigate mountain curves, leading to a fatal collision, possibly making von Ohain the first known fatality of the Full Self-Driving feature.",Fatal Crash Involving Tesla Full Self-Driving Claims Employee's Life,638.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla employee han von ohain kill crash use full selfdriving feature car fail navigate mountain curve lead fatal collision possibly make von ohain first know fatality full selfdriving feature
634,ObjectId(65d79ff28acbd54b53e09959),644,2024-02-18,"[3718,3726,3727,3728,3729,3751]","[""russian-hackers"",""north-korean-hackers"",""iranian-hackers"",""chinese-hackers""]","[""russian-government"",""north-korean-government"",""iranian-government"",""chinese-government""]","[""individual-professionals-on-linkedin"",""global-defense-companies"",""cybersecurity-firms"",""cryptocurrency-exchanges""]","State-sponsored hackers from North Korea, Iran, Russia, and China are reportedly leveraging artificial intelligence to conduct sophisticated phishing and social engineering attacks. They target global defense, cybersecurity, and cryptocurrency sectors, aiming to steal sensitive information and, in the case of North Korea, cryptocurrencies to help fund its illicit nuclear program.",Alleged State-Sponsored Hackers Escalate Purported Phishing Attacks Using Artificial Intelligence,644.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",statesponsored hacker north korea iran russia china leverage artificial intelligence conduct sophisticated phishing social engineering attack target global defense cybersecurity cryptocurrency sector aim steal sensitive information case north korea cryptocurrencies help fund illicit nuclear program
635,ObjectId(65d7ac34ea7fa39c05a06622),645,2024-02-21,"[3719,3720,3722,3723,3724,3725,3760,3761,3762,3763,3765,3766,3767,3768,3769,3770,3771,3772,3773,3774,3775,3776,3777,3778,3779,3780,3781,3782,3783,3784,3785,3786,3787,3788,3789]","[""google"",""gemini""]","[""google""]","[""general-public""]","Google's Gemini chatbot faced many reported bias issues upon release, leading to a variety of problematic outputs like racial inaccuracies and political biases, including regarding Chinese and Indian politics. It also reportedly over-corrected racial diversity in historical contexts and advanced controversial perspectives, prompting a temporary halt and an apology from Google.",Seeming Pattern of Gemini Bias and Sociotechnical Training Failures Harm Google's Reputation,645.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,google gemini chatbot face many report bias issue upon release lead variety problematic output like racial inaccuracy political bias include regard chinese indian politics also overcorrected racial diversity historical context advanced controversial perspective prompt temporary halt apology google
636,ObjectId(65d7c571600b263cc2cbfa26),646,2024-02-22,[3721],"[""snapchat""]","[""snapchat""]","[""minors""]","A judge ruled Snapchat not liable under Section 230 after its algorithm connected a minor with convicted sex offenders on multiple occasions, leading to sexual assaults first in 2019 and again in 2021. The platform's ""Quick Add"" feature was implicated in facilitating the connections between the minor and the offenders.",Snapchat's Algorithm Alleged to Link Minor with Sex Offenders,646.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",judge rule snapchat liable section connect minor convict sex offender multiple occasion lead sexual assault first platform quick add feature implicate facilitate connection minor offender
637,ObjectId(65e362fb67df8539735d3f7f),648,2024-02-07,"[3753,3758]","[""unknown-social-media-accounts""]","[""unknown""]","[""voters-in-pakistan"",""pti-(pakistan-tehreek-e-insaf)"",""imran-khan"",""democracy""]","A purported deepfake audio clip, falsely attributed to Imran Khan urging a PTI (Pakistan Tehreek-e-Insaf) election boycott, circulated on social media on the eve of Pakistan's general elections. This sophisticated AI-generated misinformation aimed to mislead voters, highlighting the growing challenge of digital manipulation in political discourse.","Alleged Deepfake Audio of Imran Khan Calls for Election Boycott, Misleading Pakistan Voters",648.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",purport deepfake audio clip falsely attribute imran khan urge pti pakistan tehreekeinsaf election boycott circulate social medium eve pakistan general election sophisticated aigenerated misinformation aim mislead voter highlight grow challenge digital manipulation political discourse
638,ObjectId(65e3652c4139cb7c36eefb96),649,2024-02-14,[3754],"[""various-social-media-accounts""]","[""unknown""]","[""general-public"",""british-voters"",""british-labour-party"",""keir-starmer"",""democracy""]","A deepfake audio clip, falsely claiming to be Keir Starmer discussing the Rochdale byelection and Labour's withdrawl of support for Azhar Ali, circulated online, achieving over 250,000 views. Experts confirmed its inauthenticity, highlighting a significant misuse of AI in fabricating political content.",Deepfake Audio Falsely Attributes Controversial Remarks to Keir Starmer About the Rochdale Azhar Ali Crisis,649.0,3. Misinformation,3.1. False or misleading information,deepfake audio clip falsely claim keir starmer discuss rochdale byelection labour withdrawl support azhar ali circulate online achieve view expert confirm inauthenticity highlight significant misuse fabricate political
639,ObjectId(65e8a94a33a720729ecf1dea),650,2024-03-04,[3755],"[""various-social-media-accounts"",""trump-supporters""]","[""various-social-media-accounts"",""trump-supporters""]","[""public-discourse-integrity"",""general-public"",""democracy"",""african-american-voters"",""black-voters""]","In the run-up to the U.S. primary elections, supporters of Donald Trump shared AI-generated images showing him with Black voters in an attempt to sway African-American votes. These deepfakes, including Trump's distorted hand visuals, were initially created by satirical accounts but were later misappropriated for political disinformation, misleading millions on social media platforms.",AI-Generated Images of Trump with Black Voters Spread as Disinformation Before U.S. Primary Elections,650.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",runup yous primary election supporter donald trump share aigenerated image show black voter attempt sway africanamerican vote deepfakes include trump distort hand visuals initially create satirical account later misappropriate political disinformation mislead million social medium platform
640,ObjectId(65f1b17bdb2584c82e41289e),652,2023-12-06,"[3764,4525,4526]","[""two-unnamed-middle-school-boys""]","[""two-unnamed-middle-school-boys""]","[""classmates-of-two-unnamed-middle-school-boys""]","Two teenaged boys from Miami, Florida, were arrested for allegedly creating and sharing AI-generated nude images of their classmates. Charged under a 2022 Florida law, they face third-degree felonies for producing and disseminating altered sexual depictions.",Two Florida Middle School Students Arrested Under New Law for Allegedly Having Made and Shared Deepfake Nudes of Their Classmates,652.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",two teenaged boy miami florida arrest create share aigenerated nude image classmate charge florida law face thirddegree felony produce disseminate alter sexual depiction
641,ObjectId(65f89c989e7aa03f699aaca2),653,2019-01-01,[3790],"[""global-predictions-inc."",""delphia-(usa)-inc.""]","[""global-predictions-inc."",""delphia-(usa)-inc.""]","[""investors""]","In a case of AI washing, the SEC charged two investment advisers, Delphia and Global Predictions, for falsely stating their use of artificial intelligence in their investment strategies between 2019 and 2023. Their misleading claims resulted in a settlement whereby the firms agreed to pay a total of $400,000 in penalties, highlighting the critical consequences of misrepresenting AI capabilities on investment decisions and trust.",Two Investment Firms Charged with Making False Claims of Artificial Intelligence Capabilities in Case of AI Washing,653.0,3. Misinformation,3.1. False or misleading information,case wash sec charge two investment adviser delphia global prediction falsely state artificial intelligence investment strategy mislead claim result settlement whereby firm agree pay total penalty highlight critical consequence misrepresent capability investment decision trust
642,ObjectId(65ff3f3ebe3aca4b06348708),656,2024-03-23,"[3794,3795,3798]","[""russian-state-media"",""ntv-channel""]","[""russian-state-media"",""ntv-channel""]","[""journalism"",""ukraine"",""oleksiy-danilov"",""kyrylo-budanov""]","Russian state media is reported to have broadcast deepfaked videos of Ukrainian officials, notably fabricating a video of Secretary of the
National Security and Defense Council of Ukraine admitting to orchestrating the Crocus City Hall terror attack in Moscow. The effort appears to be a bid to wrongly assign blame for the incident, which ISIS-K has officially claimed.",Alleged Deepfake Disinformation Broadcast by Russian State TV Blames Ukraine for Moscow Attack,656.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",russian state medium report broadcast deepfaked video ukrainian official notably fabricate video secretary national security defense council ukraine admit orchestrate crocus city hall terror attack moscow effort appear bid wrongly assign blame incident isisk officially claimed
643,ObjectId(65ff48d26616dacf59899003),657,2024-01-30,[3796],"[""openai""]","[""openai""]","[""chatgpt-users"",""chase-whiteside""]","A security breach involving ChatGPT led to the exposure of sensitive conversations, including login credentials and personal data, after a user account was compromised. OpenAI responded to the incident with an explanation.",ChatGPT Account Compromise Leads to Unintended Data Exposure,657.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",security breach involve chatgpt lead exposure sensitive conversation include login credential personal account compromise openai respond incident explanation
644,ObjectId(66041c7d9bd2751a571518f1),659,2023-10-07,"[3800,3801,3802]","[""unit-8200"",""israeli-military-intelligence"",""israeli-government""]","[""google-photos"",""corsight""]","[""palestinians"",""mosab-abu-toha"",""gazans""]","In Gaza, a previously undisclosed facial recognition program by Israeli forces is reportedly conducting mass surveillance on Palestinians in the wake of the October 7th Hamas attacks. The program, utilizing Corsight and Google Photos technologies, identifies individuals from crowds and drone footage. Allegedly, the technology often incorrectly flags civilians as militants, with one pronounced case being the poet Mosab Abu Toha on November 19, 2023.",Mass Surveillance Facial Recognition Program Reportedly Targets Palestinians in Gaza,659.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",gaza previously undisclosed facial recognition program israeli force conduct mass surveillance palestinian wake october th hamas attack program utilize corsight google photo technology identifies individual crowd drone footage often incorrectly flag civilian militant pronounce case poet mosab abu toha november
645,ObjectId(661a780b51bfdf53ff949a8d),660,2024-03-21,[3804],"[""deepfake-website-operators""]","[""unknown-deepfake-technology-developers""]","[""celebrities"",""british-public-figures"",""cathy-newman""]","A Channel 4 News investigation alleges that nearly 4,000 celebrities globally, including 255 British figures, were victims of deepfake pornography. Faces were superimposed onto explicit content using AI, with the top deepfake sites garnering 100 million views in three months, according to their findings.",Investigation Reports Unauthorized Deepfake Pornography Harms Thousands of Celebrities,660.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",channel news investigation alleges nearly celebrity globally include british figure victim deepfake pornography face superimpose onto explicit use top deepfake site garner million view three month accord finding
646,ObjectId(661a91f3c47b71dbe5637464),663,2024-04-05,"[3807,4915]","[""storm-1376"",""spamouflage"",""dragonbridge"",""chinese-communist-party""]","[""storm-1376"",""spamouflage"",""dragonbridge"",""chinese-communist-party""]","[""u.s.-voters"",""taiwanese-voters"",""general-public"",""election-integrity"",""democracy""]","AI tools linked to China were used to disseminate disinformation targeting voters in the U.S. and Taiwan, according to a Microsoft report. These operations included AI-generated imagery and audio to influence political perceptions and election outcomes, originating from the APT Storm-1376 (also known as Spamouflage and Dragonbridge).",China Reportedly Intensifying AI to Spread Disinformation to U.S. and Taiwanese Voters,663.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",tool link china use disseminate disinformation target voter yous taiwan accord microsoft operation include aigenerated imagery audio influence political perception election outcome originate apt storm also know spamouflage dragonbridge
647,ObjectId(661fb4548c4e37216b7be75c),665,2024-04-02,"[3817,3875]","[""foodstuffs"",""new-world-westend""]","[""foodstuffs""]","[""te-ani-solomon"",""maori-community""]","A facial recognition system at New World Westend supermarket misidentified a Māori woman as a known offender during its trial. The woman was wrongfully accused of trespassing and experienced public embarrassment, raising concerns about racial bias and the technology's accuracy. The supermarket acknowledged its error and apologized.",Facial Recognition Misidentification at New World Westend in New Zealand,665.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,facial recognition world westend supermarket misidentified mori woman know offender trial woman wrongfully accuse trespass experienced public embarrassment raise concern racial bias technology accuracy supermarket acknowledge error apologize
648,ObjectId(662080a4a35a5df3b78ea6b4),666,2023-12-29,[3820],"[""unknown-deepfake-creator"",""russian-propagandists""]","[""unknown-deepfake-creator"",""russian-propagandists""]","[""presidency-of-moldova"",""maia-sandu"",""government-of-moldova"",""general-public"",""democracy""]","A deepfake video falsifying President Maia Sandu's image and voice was released in Moldova, portraying her in a negative light to sow division and undermine democratic institutions. This video appeared on Telegram and was linked to Russian disinformation efforts.",Presidency of Moldova Refutes Deepfake Video Slandering President Maia Sandu,666.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",deepfake video falsify president maia sandus image voice release moldova portray negative light sow division undermine democratic institution video appear telegram link russian disinformation effort
649,ObjectId(66211728dc49baceab98d41f),669,2024-02-11,[3824],"[""golkar-party""]","[""golkar-party""]","[""indonesian-electorate"",""electoral-integrity"",""democracy""]","An AI-generated deepfake of Suharto, the deceased Indonesian dictator, was generated and circulated by the Golkar Party ahead of the February 2024 Indonesian elections. This video, which aimed to influence voter perceptions by invoking Suharto's legacy, sought to manipulate public opinion and misused deceased individuals' likenesses for political gain. The incident is another example of political deepfakes creating convincing misinformation.",Deepfake of Long-Deceased Suharto Circulating in Run-up to February 2024 Indonesian Elections,669.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",aigenerated deepfake suharto decease indonesian dictator generate circulate golkar party ahead february indonesian election video aim influence voter perception invoke suharto legacy sought manipulate public opinion misuse decease individual likeness political gain incident another example political deepfakes create convincing misinformation
650,ObjectId(6621734bce39b4ca64e9d3a9),671,2024-02-08,[3828],"[""pakistani-political-parties"",""misinformation-networks""]","[""unknown-deepfake-creator"",""pakistani-political-parties"",""misinformation-networks""]","[""rana-atif"",""raja-bashara"",""naeem-haider-panjutha"",""imran-khan""]","During Pakistan's 2024 general elections, politically motivated AI-generated deepfakes were circulated. These deepfakes falsely portrayed political figures in misleading contexts, spreading misinformation and aiming to influence voter perceptions and election outcomes.",Many Political Deepfakes Circulating in Run-up to 2024 Pakistani General Elections,671.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",pakistan general election politically motivate aigenerated deepfakes circulate deepfakes falsely portrayed political figure mislead context spread misinformation aim influence voter perception election outcome
651,ObjectId(6623e66e0cb317a4974a75cc),672,2024-04-03,"[3829,3830,3850,3851,3860,3864,3865,5168]","[""unit-8200"",""israel-defense-forces""]","[""unit-8200"",""israel-defense-forces""]","[""palestinians"",""gazans""]","The AI system ""Lavender"" has reportedly been used by the Israel Defense Forces (IDF) to identify targets in Gaza with minimal human oversight, resulting in allegedly high civilian casualty rates. The system, designed to speed up target identification, seems to have led to significant errors and mass casualties.",Lavender AI System Reportedly Directs Gaza Strikes with High Civilian Casualty Rate,672.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,lavender use israel defense force idf identify target gaza minimal human oversight result civilian casualty rate design speed target identification seem lead significant error mass casualty
652,ObjectId(6623e929dd5ae0fe0094c042),673,2024-02-19,[3831],"[""unknown-political-operatives"",""unknown-political-groups""]","[""unknown-political-operatives"",""unknown-political-groups""]","[""yoon-suk-yeol"",""korean-voters"",""journalism"",""electoral-integrity"",""democracy""]","In the lead-up to Korea's parliamentary elections, at least 129 deepfake videos and images were reported to have been detected, violating new election laws. These AI-generated deepfakes were used to mislead and manipulate public opinion, prompting a crackdown by the National Election Commission.",Deepfakes Circulating and Eroding Electoral Integrity in the Lead-up to 2024 South Korean legislative election,673.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",leadup korea parliamentary election least deepfake video image report detect violate election law aigenerated deepfakes use mislead manipulate public opinion prompt crackdown national election commission
653,ObjectId(662aff86694d3a66b751ec2a),676,2024-04-24,"[3836,3841,5456,5458,5459,5460]","[""unknown-actors-targeting-ferdinand-marcos-jr."",""unknown-actors""]","[""unknown-voice-cloning-technology-developer"",""unknown-deepfake-technology-developer""]","[""philippines-china-relations"",""philippines"",""government-of-the-philippines"",""general-public-of-the-philippines"",""general-public-of-china"",""general-public"",""ferdinand-marcos-jr.""]","A purported deepfake audio clip portraying Philippine President Ferdinand Marcos Jr. ordering an attack on China spread online in July 2024, fueling tensions in the West Philippine Sea. The Presidential Communications Office reportedly debunked it as fake, attributing it to foreign actors.",Alleged Deepfake Audio Depicts Philippines President Ferdinand Marcos Jr. Ordering Military Action,676.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",purport deepfake audio clip portray philippine president ferdinand marcos jr order attack china spread online july fuel tension west philippine sea presidential communication office debunked fake attribute foreign actor
654,ObjectId(65f89e5e9e7aa03f699cfdf6),654,2024-03-06,[3791],"[""microsoft""]","[""microsoft""]","[""general-public"",""minors""]","A Microsoft engineer reported that Copilot Designer, an AI image generator, creates content depicting sex, violence, bias, and more. Despite raising concerns and suggesting improvements, the tool remains public, prompting a letter to the FTC.",Microsoft Copilot Designer Reportedly Generated Inappropriate AI Images,654.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,microsoft engineer report copilot designer image generator creates depict sex violence bias despite raise concern suggest improvement remains public prompt letter ftc
655,ObjectId(65f8b3c7c4cf3720b6042609),655,2024-01-11,[3792],"[""meta"",""facebook"",""scammers""]","[""meta"",""facebook""]","[""investors"",""general-public"",""bill-ackman"",""cathie-wood"",""steve-cohen"",""peter-lynch"",""ray-dalio"",""peter-bourget""]","Scams are reportedly proliferating throughout Facebook impersonating wealthy individuals such as Bill Ackman, Cathie Wood, Steve Cohen, Peter Lynch, and Ray Dalio. In some cases, it seems deepfake technology is being employed, while simultaneously Facebook's own AI systems are allegedly faltering in their ability to halt the spread of these fraudulent ads despite being reported.",Scams Reportedly Impersonating Wealthy Investors Proliferating on Facebook,655.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",scam proliferate throughout facebook impersonate wealthy individual bill ackman cathie wood steve cohen peter lynch ray dalio case seem deepfake employ simultaneously facebooks system falter ability halt spread fraudulent ad despite report
656,ObjectId(66002bf1ff71471fe4135049),658,2024-03-22,"[3797,3799,3803]","[""the-arizona-agenda"",""hank-stephenson""]","[""the-arizona-agenda"",""hank-stephenson""]","[""kari-lake"",""general-public"",""journalism"",""democracy""]","The Arizona Agenda produced a deepfake video of Republican Senate candidate Kari Lake giving a testimonial about the publication with the seeming intention of educating the general public about the dangers of deepfakes in the coming election cycle. However, the Arizona Agenda appears not to have sought Lake's consent, prompting a cease-and-desist letter from her campaign. ",The Arizona Agenda Produced a Deepfake of Kari Lake Advocating for the Publication Without Her Consent,658.0,3. Misinformation,3.1. False or misleading information,arizona agenda produce deepfake video republican senate candidate kari lake give testimonial publication seem intention educate general public danger deepfakes come election cycle however arizona agenda appear sought lake consent prompt ceaseanddesist letter campaign
657,ObjectId(661a7a068c4e37216bfabefb),661,2024-03-26,[3805],"[""telegram-community-users"",""reddit-users"",""leonardo-ai-users""]","[""leonardo-ai""]","[""public-figures"",""celebrities""]","Sydney-based startup Leonardo AI's text-to-image generator was alleged to have been exploited to create nonconsensual sexual images of celebrities, bypassing content moderation systems with user-shared prompts.",Leonardo AI's Platform Alleged to Have Been Used for Creating Nonconsensual Celebrity Deepfakes,661.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",sydneybased startup leonardo ai texttoimage generator exploit create nonconsensual sexual image celebrity bypassing moderation system usershared prompt
658,ObjectId(661a7bdb8c4e37216bfcd1c5),662,2024-04-02,"[3806,3861]","[""washington-state's-lottery""]","[""washington-state's-lottery""]",[],"An AI-powered website by Washington State's Lottery is reported to have inadvertently produced a softcore pornographic image of a user, leading to the site’s immediate shutdown out of caution.",Washington State's Lottery AI Site Reportedly Generates Inappropriate User Image,662.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,aipowered website washington state lottery report inadvertently produce softcore pornographic image lead site immediate shutdown caution
659,ObjectId(661a99e551bfdf53ffb51fb0),664,2024-02-17,[3809],"[""lincoln-project""]","[""lincoln-project""]","[""public-discourse-integrity"",""political-integrity"",""general-public"",""donald-trump""]","The Lincoln Project used AI to create a deepfake video of Donald Trump's deceased father criticizing him. Although they made it clear that the video was a deepfake, the deeply personal nature of the attack represents a corrosive use of artificial intelligence in undermining democratic norms during an election cycle.",Deepfake Generated by the Lincoln Project of Trump's Father Used in Political Attack Ad,664.0,3. Misinformation,3.1. False or misleading information,lincoln project use create deepfake video donald trump decease father criticize although make clear video deepfake deeply personal nature attack represent corrosive artificial intelligence undermine democratic norm election cycle
660,ObjectId(6620825edc49baceabe6a2c9),667,2023-12-16,[3821],"[""people's-liberation-army"",""chinese-communist-party"",""base-311""]","[""people's-liberation-army"",""chinese-communist-party"",""base-311""]","[""taiwanese-voters"",""lai-ching-te"",""electoral-integrity"",""democratic-progressive-party"",""democracy""]","In the lead-up to Taiwan's presidential election in January 2024, a deepfake video circulated showing candidate Lai Ching-te endorsing his rivals. Taiwanese intelligence issued warnings of intensified Chinese disinformation campaigns, such as Spamouflage, aimed at manipulating the election outcome.",Manipulated Deepfake Video of Lai Ching-te Endorsing Rivals in Lead-up to January Presidential Elections,667.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",leadup taiwan presidential election january deepfake video circulate show candidate lai chingte endorse rival taiwanese intelligence issue warning intensified chinese disinformation campaign spamouflage aim manipulate election outcome
661,ObjectId(6621130adc49baceab92457f),668,2023-12-27,"[3823,3916]","[""political-candidates-of-the-2024-lok-sabha-elections""]","[""the-indian-deepfaker"",""the-digital-publicity"",""rohit-pal"",""obiyan-infotech"",""merakii-group""]","[""political-candidates-targeted-by-deepfakes"",""indian-electorate"",""india"",""democracy""]","Digital manipulators in India are using deepfake technology to influence the 2024 Lok Sabha elections. These AI-generated videos and audio clips are designed to tarnish the reputations of political candidates, challenging the integrity of electoral processes.",Proliferation of Deepfakes Disrupting 2024 Lok Sabha Elections,668.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",digital manipulator india use deepfake influence lok sabha election aigenerated video audio clip design tarnish reputation political candidate challenge integrity electoral process
662,ObjectId(66215c70557227737d9452f5),670,2024-01-23,"[3826,3827]","[""dravida-munnetra-kazhagam"",""dmk"",""various-indian-political-parties""]","[""muonium"",""the-indian-deepfaker""]","[""indian-electorate"",""indian-voters"",""democracy"",""electoral-integrity"",""media-discourse"",""m.-karunanidhi"",""j.-jayalalithaa""]","In the lead-up to India's 2024 general elections, AI technology was used to create deepfake videos of deceased politicians, such as M. Karunanidhi and J. Jayalalithaa, aiming to influence voter behavior and campaign strategies. These AI-generated appearances are contributing to the erosion of trust in democratic processes and media discourse.",Deepfakes of Deceased Indian Politicians for Election Campaigning Are Increasingly Being Deployed,670.0,3. Misinformation,3.1. False or misleading information,leadup india general election use create deepfake video decease politician karunanidhi j jayalalithaa aim influence voter behavior campaign strategy aigenerated appearance contribute erosion trust democratic process medium discourse
663,ObjectId(662575cce06969c4c5d0f875),674,2024-03-14,[3832],"[""russian-government"",""political-operatives"",""political-consultants"",""chinese-communist-party""]","[""unknown-deepfake-creators"",""openai"",""google""]","[""voters"",""public-trust"",""political-figures"",""general-public"",""electoral-integrity"",""democracy"",""civic-society""]","AI-driven election disinformation is escalating globally, leveraging easy-to-use generative AI tools to create convincing deepfakes that mislead voters. This shift has simplified the process for individuals to generate fake content, having already eroded trust in elections by undermining public trust and manipulating voter perceptions. Evidence has, for example, been documented in incidents across the U.S., Moldova, Slovakia, Bangladesh, and Taiwan.",Manipulated Media via AI Disinformation and Deepfakes in 2024 Elections Erode Trust Across More Than 50 Countries,674.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",aidriven election disinformation escalate globally leverage easytouse generative tool create convincing deepfakes mislead voter shift simplify individual generate fake already erode trust election undermine public trust manipulate voter perception evidence example document incident across yous moldova slovakia bangladesh taiwan
664,ObjectId(662afbe7b67a55d2db501d79),675,2024-01-15,"[3835,3837,3838,4043,5155]","[""dazhon-darien""]","[""unknown-deepfake-technology-developer""]","[""pikesville-high-school-students-and-staff"",""pikesville-high-school"",""eric-eiswert"",""baltimore-county-public-schools-community""]","Dazhon Darien, former athletic director at Pikesville High School in Baltimore, used AI to create a deepfake audio clip impersonating Principal Eric Eiswert, embedding racist and antisemitic remarks. The clip, intended to discredit Eiswert, spread widely, leading to threats and his placement on administrative leave. On April 28, 2025, Darien was sentenced to four months in jail after pleading guilty to disturbing school operations.",High School Athletic Director in Baltimore County Created Racist Deepfake Audio Impersonating Principal,675.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",dazhon darien former athletic director pikesville school baltimore use create deepfake audio clip impersonate principal eric eiswert embed racist antisemitic remark clip intend discredit eiswert spread widely lead threat placement administrative leave april darien sentence four month jail plead guilty disturb school operation
665,ObjectId(663f86aff20b7a3d62c3fa98),677,2024-04-29,[3839],"[""tiktok-users"",""julia-munslow"",""chatgpt"",""gpt-3.5"",""gpt-4"",""perplexity-ai""]","[""openai"",""perplexity.ai""]","[""general-public"",""openai"",""perplexity-ai""]","The ""Dan"" (""Do Anything Now"") AI boyfriend is a trend on TikTok in which users appear to regularly manipulate ChatGPT to adopt boyfriend personas, breaching content policies. ChatGPT 3.5 is reported to regularly produce explicitly sexual content, directly violating its intended safety protocols. GPT-4 and Perplexity AI were subjected to similar manipulations, and although they exhibited more resistance to breaches, some prompts were reported to break its guidelines.",ChatGPT and Perplexity Reportedly Manipulated into Breaking Content Policies in AI Boyfriend Scenarios,677.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,dan anything boyfriend trend tiktok user appear regularly manipulate chatgpt adopt boyfriend persona breaching policy chatgpt report regularly produce explicitly sexual directly violate intend safety protocol gpt perplexity subject similar manipulation although exhibit resistance breach prompt report break guideline
666,ObjectId(663f88e1bb433ad4d3c4dbb1),678,2024-04-29,[3840],"[""chatgpt""]","[""openai""]","[""noyb"",""max-schrems"",""general-public""]","The activist organization noyb, founded by Max Schrems, filed a complaint in Europe against OpenAI alleging that ChatGPT violates the General Data Protection Regulation (GDPR) by providing inaccurate personal information such as birthdates about individuals.",ChatGPT Factual Errors Lead to Filing of Complaint of GDPR Privacy Violation ,678.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,activist organization noyb found max schrems file complaint europe openai allege chatgpt violates general protection regulation gdpr provide inaccurate personal information birthdates individual
667,ObjectId(663fc22a65ea88fe7b157029),679,2023-02-20,[3842],"[""unnamed-deepfake-creator"",""tiktok"",""twitter""]","[""unnamed-deepfake-creator""]","[""elizabeth-warren"",""msnbc"",""republicans"",""democrats"",""democracy"",""election-integrity"",""general-public""]","In February 2023, a deepfake of Senator Elizabeth Warren circulated on social media in which doctored footage of her from an MSNBC interview had her claiming that she believes Republicans should not vote. ",A Deepfake of Senator Elizabeth Warren Circulated Saying Republicans Should Not Vote,679.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",february deepfake senator elizabeth warren circulate social medium doctor footage msnbc interview claim believe republican vote
668,ObjectId(6646c6b8cbd025b58e43653b),680,2024-03-01,"[3843,3870,4915]","[""copycop"",""russia-linked-network""]","[""openai"",""chatgpt""]","[""general-public"",""journalism"",""democracy""]","In early March 2024, a network named CopyCop began publishing modified news stories using AI, altering content to spread partisan biases and disinformation. These articles, initially from legitimate sources, were manipulated by AI models, possibly developed by OpenAI, to disseminate Russian propaganda. Over 19,000 articles were published, targeting divisive political issues and creating false narratives.","Russia-Linked AI CopyCop Site Identified as Modifying and Producing at Least 19,000 Deceptive Reports",680.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",early march network name copycop begin publishing modify news story use alter spread partisan bias disinformation article initially legitimate source manipulate model possibly developed openai disseminate russian propaganda article publish target divisive political issue create false narrative
669,ObjectId(66480bb8af64b0143b476d55),681,2023-07-17,[3845],"[""ron-desantis's-presidential-campaign"",""never-back-down""]","[""never-back-down""]","[""kim-reynolds"",""donald-trump""]","A pro-Ron DeSantis super PAC released an ad featuring an AI-generated voice of Donald Trump. The ad, created by Never Back Down, aimed to criticize Trump’s treatment of Iowa Gov. Kim Reynolds. The AI-generated voice was confirmed to be based on Trump's post from his social media. This incident is an example of potential deception in political advertising through AI-generated content.",Never Back Down Super PAC for Ron DeSantis Uses AI Donald Trump Voice in Attack Ad Against Kim Reynolds,681.0,3. Misinformation,3.1. False or misleading information,proron desantis super pac release ad feature aigenerated voice donald trump ad create never back aim criticize trump treatment iowa gov kim reynolds aigenerated voice confirm base trump post social medium incident example potential deception political advertising aigenerated
670,ObjectId(664b3b562827a5d40e1b2445),682,2024-02-01,[3847],"[""patrick-ruffini""]","[""unknown-deepfake-creator""]","[""general-public"",""democracy"",""black-americans"",""african-american-voters""]","GOP pollster Patrick Ruffini shared AI-generated images depicting Black men supporting the Republican Party just before Black History Month. These fabricated photos misled the public by creating a false narrative of racial diversity within the GOP, undermining trust and potentially influencing voter perceptions. The incident raises significant concerns about the misuse of AI to spread misinformation and manipulate political representation, particularly affecting Black communities.",GOP Pollster Shares AI-Generated Images to Fabricate Appearance of Black Voter Support,682.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",gop pollster patrick ruffini share aigenerated image depict black men support republican party black history month fabricate photo mislead public create false narrative racial diversity within gop undermine trust potentially influence voter perception incident raise significant concern misuse spread misinformation manipulate political representation particularly affect black community
671,ObjectId(664b4941ec1917ad98a34f55),683,2024-03-28,"[3848,3867]","[""unknown-scammers""]","[""heygen"",""elevenlabs""]","[""olga-loiek"",""michel-janse"",""lana-smalls"",""carrie-williams"",""shade-zahrai""]","Scammers used AI tools from HeyGen and ElevenLabs to create deepfake videos of influencers Michel Janse, Olga Loiek, Shadé Zahrai, and Carrie Williams, misusing Lana Smalls's voice in Williams's case. These videos promoted offensive products and false messages, in some cases targeting nationalist Chinese men to boost China-Russia ties, causing emotional distress and damaging the victims' reputations.",Scammers Using Deepfakes of Women's Faces and Voices for False and Offensive Advertisements,683.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",scammer use tool heygen elevenlabs create deepfake video influencers michel janse olga loiek shad zahrai carrie williams misuse lana smallss voice williams case video promote offensive product false message case target nationalist chinese men boost chinarussia tie cause emotional distress damage victim reputation
672,ObjectId(664b540f72460147aae22ff3),684,2024-04-04,[3852],"[""google"",""google-books""]","[""google""]","[""google-books"",""google-ngram-viewer"",""researchers"",""general-public""]","Google Books is indexing low-quality, AI-generated books, degrading its database and potentially distorting Google Ngram Viewer's analysis of language trends. This integration of inaccurate or misleading information undermines trust, disseminates poor-quality content, and wastes resources as researchers must spend time clearing up the misinformation.",Google Books Appears to Be Indexing Works Written by AI,684.0,3. Misinformation,3.1. False or misleading information,google book index lowquality aigenerated book degrade database potentially distort google ngram viewer analysis language trend integration inaccurate mislead information undermines trust disseminates poorquality waste resource researcher spend time clearing misinformation
673,ObjectId(664b5cf43dcc85815ad373ac),685,2024-04-24,[3853],"[""who"",""s.a.r.a.h.-(smart-ai-resource-assistant-for-health)""]","[""who""]","[""general-public"",""people-seeking-medical-advice""]","The WHO's AI-powered health advisor, S.A.R.A.H. (Smart AI Resource Assistant for Health), is alleged to provide inconsistent and inadequate health information. The bot reportedly gives contradictory responses to the same queries, fails to offer specific contact details for healthcare providers, and inadequately handles severe mental health crises, often giving irrelevant or unhelpful advice.",The WHO's S.A.R.A.H. Bot Reported to Provide Inconsistent and Inadequate Health Information,685.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,aipowered health advisor sarah smart resource assistant health provide inconsistent inadequate health information bot give contradictory response query fails offer specific contact detail healthcare provider inadequately handle severe mental health crisis often give irrelevant unhelpful advice
674,ObjectId(664b5f7c983b037e0c4b420d),686,2024-04-03,"[3854,3855]","[""meta""]","[""meta""]","[""asian-people"",""interracial-couples"",""general-public""]","Meta's AI image generator is alleged to produce inaccurate and biased images, consistently failing to depict interracial relationships involving Asian individuals and Caucasian or Black individuals. Instead, it generates images featuring two Asian people or stereotypes, erasing the diversity and representation of Asian people.",Meta AI Image Generator Reportedly Fails to Accurately Represent Interracial Relationships,686.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,metas image generator produce inaccurate bias image consistently fail depict interracial relationship involve asian individual caucasian black individual instead generates image feature two asian people stereotype erase diversity representation asian people
675,ObjectId(664b6851e089d9789e1d1738),687,2024-04-08,[3857],"[""pornhub"",""various-porn-sites""]","[""unknown-deepfake-creators""]","[""breeze-liu""]","Porn sites are alleged to have used AI-generated images of Breeze Liu without her consent, leading to severe emotional distress. Liu discovered a video of herself on Pornhub, which was then deepfaked and spread across over 800 links. Despite efforts to remove the content, many sites refused to comply, perpetuating the violation and exploitation of her image.",Deepfake Porn Sites Use Breeze Liu's Image Without Consent,687.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",porn site use aigenerated image breeze liu consent lead severe emotional distress liu discover video pornhub deepfaked spread across link despite effort remove many site refuse comply perpetuate violation exploitation image
676,ObjectId(664cd337dad8eb9e98553cf7),688,2024-05-20,"[3868,3869,3871,3872,3873,3874,3878,3881,3882,3883,3907,3908,3909,3910]","[""sky-voice-assistant"",""sam-altman"",""openai""]","[""sam-altman"",""openai""]","[""scarlett-johansson""]","OpenAI unveiled a voice assistant with a voice resembling Scarlett Johansson's, despite her refusal to license her voice. Johansson claimed the assistant, ""Sky,"" sounded ""eerily similar"" to her voice, leading her to seek legal action. OpenAI suspended Sky, asserting the voice was from a different actress.",Scarlett Johansson Alleges OpenAI's Sky Imitates Her Voice Without Licensing,688.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,openai unveiled voice assistant voice resemble scarlett johanssons despite refusal license voice johansson claimed assistant sky sound eerily similar voice lead seek legal action openai suspend sky assert voice different actress
677,ObjectId(664d0ef562ad7c58f819eb8a),689,2024-03-26,"[3876,3877,3879,3915]","[""steven-anderegg""]","[""stable-diffusion"",""stability-ai""]","[""minors"",""general-public""]","The FBI has arrested Steven Anderegg of Holmen, Wisconsin for having allegedly used Stable Diffusion to generate about 13,000 sexually explicit images of minors, which he then is also alleged to have shared and distributed, including with at least one minor, via Telegram and Instagram. Anderegg was originally apprehended by state police in March, and this case marks one of the first times the FBI has brought charges against someone for having used AI to generate CSAM.","Holmen, Wisconsin Man Allegedly Used Stable Diffusion to Create and Then Share Sexually Explicit Images Depicting Minors",689.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",fbi arrest steven anderegg holmen wisconsin use stable diffusion generate sexually explicit image minor also share distribute include least minor via telegram instagram anderegg originally apprehend state police march case mark first time fbi brought charge someone use generate csam
678,ObjectId(664d484f45c589f2d546278d),690,2024-03-26,"[3880,3884,3885,3903]","[""isis"",""isis-supporters""]","[""openai"",""elevenlabs""]","[""general-public"",""people-susceptible-to-radicalism""]","ISIS supporters have created an AI-generated media program called News Harvest to disseminate propaganda videos. The program produces near-weekly broadcasts featuring AI-generated news anchors discussing ISIS operations globally, using cheap and easy-to-use AI tools. This development showcases the use of AI as a powerful propaganda tool for extremist groups.",ISIS Utilizes AI for Propaganda Videos in News Harvest Program,690.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",isi supporter create aigenerated medium program call news harvest disseminate propaganda video program produce nearweekly broadcast feature aigenerated news anchor discuss isi operation globally use cheap easytouse tool development showcase powerful propaganda extremist group
679,ObjectId(6653e56f4ae712caaa916ae9),691,2024-05-25,"[3886,3887]","[""home-bargains""]","[""facewatch""]","[""sara"",""home-bargains-customers"",""general-public""]","A facial-recognition software used by the British variety store Home Bargains is alleged to have misidentified ""Sara"" as a shoplifter, leading to staff searching her bag, escorting her from the premises, and banning her from the store. After, Facewatch is reported to have admitted its error to Sara. Facewatch is used by a number of different British stores.",Facewatch Reported to Have Wrongfully Flagged Home Bargains Customer as Shoplifter,691.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,facialrecognition software use british variety store home bargain misidentified sara shoplifter lead staff search bag escort premise ban store facewatch report admit error sara facewatch use number different british store
680,ObjectId(6653e9049ee13f5a3df88be4),692,2024-02-01,"[3888,3889,5100]","[""metropolitan-police-service""]","[""metropolitan-police-service""]","[""shaun-thompson"",""general-public""]","Sometime in February 2024, Shaun Thompson is reported to have walked by one of the London Metropolitan Police's facial recognition technology vans near London Bridge. He was almost immediately arrested because the technology is reported to have misidentified him as a suspect in an unrelated and unspecified crime.",London Metropolitan Police's Facial Recognition Technology Reportedly Misidentified Shaun Thompson as Suspect Leading to Arrest,692.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,sometime february shaun thompson report walk london metropolitan police facial recognition van near london bridge almost immediately arrest report misidentified suspect unrelated unspecified crime
681,ObjectId(66549c1e29d9c79ac63c1f00),693,2024-05-14,"[3890,3891,3895,3898,3899,3902,3913]","[""google""]","[""google""]","[""google-users"",""general-public""]","Google's AI search engine has reportedly been providing users with confidently incorrect and often harmful information. Reports highlight numerous inaccuracies, including misleading health advice and dangerous cooking suggestions. For example, it has falsely claimed Barack Obama as the first Muslim U.S. President, reflecting fringe conspiracy theories, or recommending that glue can be an ingredient in pizza.",Google AI Reportedly Delivering Confidently Incorrect and Harmful Information,693.0,3. Misinformation,3.1. False or misleading information,google search engine provide user confidently incorrect often harmful information report highlight numerous inaccuracy include mislead health advice dangerous cooking suggestion example falsely claimed barack obama first muslim yous president reflect fringe conspiracy theory recommend glue ingredient pizza
682,ObjectId(6654a004b8c5aa64ad04db1e),694,2023-04-25,[3892],"[""republican-national-committee-(rnc)""]","[""unknown-deepfake-creator""]","[""joe-biden"",""democratic-party"",""democracy"",""election-integrity"",""information-integrity""]","In response to Joe Biden's announcement that he will run again for office in 2024, the Republican National Committee (RNC) released an attack ad featuring AI-generated images that depict a dystopian vision of the U.S. Even though a small disclaimer was included, the images in the ad, which include scenes of AI-generated crises and conflict, harms information and electoral integrity.",Republican AI Ad Depicts Dystopian Future After Biden Reelection Announcement,694.0,3. Misinformation,3.1. False or misleading information,response joe bidens announcement run office republican national committee rnc release attack ad feature aigenerated image depict dystopian vision yous even though disclaimer include image ad include scene aigenerated crisis conflict harm information electoral integrity
683,ObjectId(66568b3ab791d6bd2a43341a),695,2023-05-24,[3893],"[""donald-trump-presidential-campaign""]","[""unknown-deepfake-creators""]","[""ron-desantis"",""elon-musk"",""george-soros"",""klaus-schwab"",""dick-cheney""]","Former President Donald Trump released two AI-generated videos using deepfaked voices to mock Florida Governor Ron DeSantis. The first video, posted on platforms like Rumble and Instagram, depicted a chaotic and offensive fake Twitter Spaces event featuring deepfaked voices of Elon Musk, George Soros, Klaus Schwab, Dick Cheney, Adolf Hitler, and a generated voice of Satan. The second video showed a rocket with ""Ron 2024"" written beside it falling and exploding before liftoff. ",Donald Trump's Presidential Campaign Released Deepfakes Attacking Ron DeSantis,695.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",former president donald trump release two aigenerated video use deepfaked voice mock florida governor ron desantis first video post platform like rumble instagram depict chaotic offensive fake twitter space event feature deepfaked voice elon musk george soros klaus schwab dick cheney adolf hitler generate voice satan second video show rocket ron write beside fall explode liftoff
684,ObjectId(665719d2cd0ff35f6e67a4b4),696,2024-02-14,[3894],"[""meta"",""facebook""]","[""meta"",""facebook""]","[""small-businesses"",""advertisers""]","Meta's automated ad platform ""Advantage Plus"" caused advertisers to exceed their daily ad budgets. The cost per impressions (CPMs) surged far above the usual. This incident, which persisted into April, affected small businesses with overspending and lack of transparency.",Meta's AI Ad Platform Reportedly Causes Overspending and Poor Performance,696.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,metas automate ad platform advantage plus cause advertiser exceed daily ad budget cost per impression cpms surge far usual incident persist april affected business overspend lack transparency
685,ObjectId(66571fe528034c20a9e75910),697,2023-06-23,[3896],"[""unknown-deepfake-creator""]","[""unknown-deepfake-technology-developer""]","[""donald-trump""]",A deepfake image depicting Donald Trump with an underage girl at Jeffrey Epstein's private island in 1992 has been circulating on social media. ,Deepfake Image Circulating of Donald Trump with Underage Girl at Jeffrey Epstein's Private Island,697.0,3. Misinformation,3.1. False or misleading information,deepfake image depict donald trump underage girl jeffrey epstein private island circulate social medium
686,ObjectId(665722942572add7002f78a2),698,2023-09-02,[3897],"[""c3pmeme""]","[""unknown-deepfake-technology-developer""]","[""ron-desantis"",""ron-desantis's-presidential-campaign""]","In early September 2023, a deepfake video created by C3PMeme circulated on social media, showing Ron DeSantis falsely claiming he was dropping out of the 2024 presidential race. DeSantis did not actually suspend his campaign until January 21, 2024.",Deepfake Video of Ron DeSantis Dropping Out of 2024 Presidential Race Circulating,698.0,3. Misinformation,3.1. False or misleading information,early september deepfake video create cpmeme circulate social medium show ron desantis falsely claim drop presidential race desantis actually suspend campaign january
687,ObjectId(665729c1adee42d4b8b8a824),699,2024-05-23,"[3901,4174]","[""department-of-veterans-affairs-(va)""]","[""department-of-veterans-affairs-(va)""]","[""veterans"",""survivors-of-military-sexual-trauma"",""female-veterans""]","An AI program named REACH VET, designed and used by the Department of Veterans Affairs (VA) to prevent veteran suicides, was reportedly found to prioritize white men while neglecting female veterans and survivors of military sexual trauma. This oversight persists despite rising suicide rates among these groups. The incident is an example of algorithmic bias and the exclusion of critical risk factors for female veterans.",VA Suicide Prevention Algorithm REACH VET Reportedly Prioritizes Men Over Women Veterans,699.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,program name reach vet design use department veteran affair va prevent veteran suicide found prioritize white men neglect female veteran survivor military sexual trauma oversight persists despite rise suicide rate among group incident example algorithmic bias exclusion critical risk factor female veteran
688,ObjectId(66572d5eb9f3a96204495c3c),700,2024-05-20,"[3904,3939]","[""meta""]","[""meta""]","[""facebook-users"",""facebook-users-in-online-support-communities""]","Meta's AI chatbots have reportedly begun entering online communities on Facebook, providing responses that mimic human interaction. These chatbots, often uninvited, disrupt the human connection critical for support groups by giving misleading or false information and pretending to share lived experiences.",Meta's AI Chatbots Are Entering Online Support Communities Uninvited,700.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,metas chatbots begin enter online community facebook provide response mimic human interaction chatbots often uninvited disrupt human connection critical support group give mislead false information pretend share live experience
689,ObjectId(665796373e26e6f1b1024f41),701,2024-05-29,"[3911,4858,4859,4860,4861,4862,4863,4864,4865,4866,4867,4868,4869,4870,4871,4872,4873,4874,4875,4876,4877,4878,4879,4880,4881,4882,4883,4884,4885,4886,4897,4898,4899,4901,4915,4919]","[""john-mark-dougan""]","[""openai""]","[""journalism"",""information-integrity"",""general-public"",""american-citizens""]","John Mark Dougan, a former Florida sheriff's deputy granted asylum in Russia, has been implicated in spreading disinformation. Utilizing AI tools like OpenAI's ChatGPT and DALL-E 3, Dougan created over 160 fake news sites, disseminating false narratives to millions worldwide. His actions align with Russian disinformation strategies targeting Western democracies. See also Incident 734.",American Asylum Seeker John Mark Dougan in Russia Reportedly Spreads Disinformation via AI Tools and Fake News Network,701.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",john mark dougan former florida sheriff deputy grant asylum russia implicate spread disinformation utilize tool like openais chatgpt dalle dougan create fake news site disseminate false narrative million worldwide action align russian disinformation strategy target western democracy see also incident
690,ObjectId(665b7c5fb67a2a256464ba9e),702,2024-05-31,[3914],"[""russian-government""]","[""unknown-deepfake-creators""]","[""matthew-miller"",""department-of-state"",""biden-administration""]","A deepfake video of State Department spokesman Matthew Miller falsely suggested Belgorod was a legitimate target for Ukrainian strikes. This disinformation spread on Telegram and Russian media, misleading the public and inciting tensions. U.S. officials condemned the deepfake. This incident is an example of the threat of AI-powered disinformation and hybrid attacks.",Disinformation Deepfake Circulates of State Department Spokesman Matthew Miller Suggesting Belgorod Can Be Attacked with U.S. Weapons,702.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",deepfake video state department spokesman matthew miller falsely suggest belgorod legitimate target ukrainian strike disinformation spread telegram russian medium mislead public incite tension yous official condemn deepfake incident example threat aipowered disinformation hybrid attack
691,ObjectId(666d7bc9703f35fc6eb12e01),703,2024-01-13,[3917],"[""unknown-deepfake-creators""]","[""unknown-deepfake-technology-developer""]","[""joe-biden"",""texas-citizens"",""texas-officials"",""general-public""]","An AI-generated audio clip falsely portraying President Biden threatening to send F-15 fighter jets to Texas escalated tensions and spread misinformation. The manipulated audio, shared widely on social media, mimicked Biden's voice and suggested he planned military action against Texas. This incident was another example of a deepfake being used to amplify false narratives, undermining public trust and inflaming political conflicts.",Deepfake Audio Sparks False Claims of Biden Threatening Texas with F-15s,703.0,3. Misinformation,3.1. False or misleading information,aigenerated audio clip falsely portray president biden threaten send f fighter jet texas escalate tension spread misinformation manipulate audio share widely social medium mimicked bidens voice suggest plan military action texas incident another example deepfake use amplify false narrative undermine public trust inflame political conflict
692,ObjectId(666d7f7a84928e01d4cb0f54),704,2024-05-23,"[3918,3923]","[""legal-professionals"",""law-firms"",""organizations-requiring-legal-research""]","[""thomson-reuters"",""lexisnexis""]","[""legal-professionals"",""clients-of-lawyers"",""legal-system""]","Stanford University’s Human-Centered AI Institute (HAI) conducted a study in which they designed a ""pre-registered dataset of over 200 open-ended legal queries"" to test AI products by LexisNexis (creator of Lexis+ AI) and Thomson Reuters (creator of Westlaw AI-Assisted Research and Ask Practical Law AI).  The researchers found that these legal models hallucinate in 1 out of 6 (or more) benchmarking queries.",Study Highlights Persistent Hallucinations in Legal AI Systems,704.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,stanford university humancentered institute hai conduct study design preregistered dataset openended legal query test product lexisnexis creator lexis thomson reuters creator westlaw aiassisted research ask practical law researcher found legal model hallucinate benchmarking query
693,ObjectId(666d8289703f35fc6ec02de3),705,2024-06-08,"[3919,4050]","[""turkish-student-identified-as-mee""]","[""openai""]","[""turkish-yks-exam-takers"",""turkish-educational-institutions"",""students""]","A Turkish student in Isparta was reportedly arrested for using ChatGPT to cheat during the 2024 YKS university entrance exam. The student, identified as M.E.E., is alleged to have employed a sophisticated setup involving a router, mobile phone, earphone, and a button-shaped camera to transmit exam questions to ChatGPT and receive answers in real-time.","Turkish Student in Isparta Allegedly Uses AI to Cheat on Exam, Leading to Arrest",705.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",turkish student isparta arrest use chatgpt cheat yks university entrance exam student identify mee employ sophisticated setup involve router mobile phone earphone buttonshaped camera transmit exam question chatgpt receive answer realtime
694,ObjectId(666d860444712fc39319d48b),706,2024-04-01,[3920],"[""unknown-scammers""]","[""openai"",""unknown-ai-developers""]","[""small-businesses"",""small-business-customers"",""small-business-employees"",""bee-cups"",""darn-tough-vermont"",""jim-carter""]","Scammers are using AI to impersonate small businesses by copying their videos, logos, and social media posts. They create fake listings and ads, diverting customers to cheap knockoffs or stealing their money. This has severely impacted businesses like Bee Cups, Darn Tough Vermont, and Cascade hummingbird feeders, leading to significant financial losses, negative reviews, and damaged reputations. Their deployment of AI makes it challenging for small businesses to combat these fraudulent activities.",Scammers Using AI to Impersonate Small Businesses,706.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",scammer use impersonate business copying video logo social medium post create fake listing ad divert customer cheap knockoff steal money severely impact business like bee cup darn tough vermont cascade hummingbird feeder lead significant financial loss negative review damage reputation deployment make challenge business combat fraudulent activity
695,ObjectId(666d8a23a299a210e54f16f1),707,2024-06-13,[3921],"[""unnamed-tesla-driver""]","[""tesla""]","[""unnamed-fullerton-police-officer"",""fullerton-police-department""]","A Tesla reportedly in self-driving mode crashed into a parked patrol vehicle in Fullerton, California while the officer was responding to a fatal DUI crash. The officer narrowly escaped injury. The driver reports having been distracted by a cellphone and having relied on the Tesla’s AI. (The earlier crash involved a suspected DUI driver who killed a motorcyclist stopped at a red light.)","Tesla Reportedly in Autopilot Mode Hits Parked Police Vehicle in Fullerton, California",707.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,tesla selfdriving mode crashed park patrol vehicle fullerton california officer respond fatal duo crash officer narrowly escape injury driver report distract cellphone rely tesla earlier crash involve suspect duo driver kill motorcyclist stop red light
696,ObjectId(666d8c39f769e3ff201951b2),708,2024-05-26,[3922],"[""judiciary-of-italy""]","[""unnamed-automated-transcription-software-developer""]","[""roberto-spinelli"",""genoa-prosecutor's-office"",""giovanni-toti"",""paolo-emilio-signorini"",""italian-general-public""]","An AI transcription software error in a Genoa bribery investigation incorrectly recorded ""illicit financing"" instead of ""licit financing,"" which could have significantly impacted the case. The mistake, discovered during a review, is an example of the risks of relying on AI in judicial settings.",Faulty AI Transcription Threatens Integrity of Genoa Bribery Probe,708.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,transcription software error genoa bribery investigation incorrectly record illicit financing instead licit financing significantly impact case mistake discover review example risk rely judicial setting
697,ObjectId(666d915c264f9279bfeed3cc),709,2023-05-28,[3924],"[""unnamed-manchester-litigant""]","[""openai""]","[""unnamed-manchester-litigant"",""manchester-court-system"",""general-public""]","A litigant in person (LiP) in a Manchester civil case presented false legal citations generated by ChatGPT. It fabricated one case name and provided fictitious excerpts for three real cases, misleadingly supporting the LiP's argument. The judge, upon investigation, found the submissions to be inadvertent and did not penalize the LiP. ",Unrepresented Litigant Misled by ChatGPT-Generated False Legal Citations in Manchester Court,709.0,3. Misinformation,3.1. False or misleading information,litigant person lip manchester civil case present false legal citation generate chatgpt fabricate case name provide fictitious excerpt three real case misleadingly support lip argument judge upon investigation found submission inadvertent penalize lip
698,ObjectId(666d96d1f769e3ff207bf31a),710,2024-04-15,[3925],"[""meta""]","[""meta""]","[""auschwitz-memorial-museum"",""survivors-of-holocaust-victims"",""general-public""]","Facebook's AI wrongly labeled 20 posts from the Auschwitz Memorial Museum as violating community standards for ""bullying"" and ""nudity,"" even deleting one image of orphans. The mislabeling of respectful historical content outraged the museum, which demanded an explanation. Meta, Facebook's parent company, apologized, attributing the error to mistaken notices sent by their AI system and acknowledged the posts did not violate any policies.","Facebook AI Mislabels Auschwitz Photos as ""Bullying"" and ""Nudity""",710.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebooks wrongly label post auschwitz memorial museum violate community standard bullying nudity even delete image orphan mislabeling respectful historical outrage museum demand explanation meta facebooks parent company apologize attribute error mistaken notice sent acknowledge post violate policy
699,ObjectId(666d9f17bb60f32b553f9c0f),711,2024-04-26,"[3926,3927]","[""tesla"",""tesla-drivers""]","[""tesla""]","[""tesla-drivers"",""drivers"",""general-public""]","The NHTSA has linked Tesla's Autopilot to over a dozen fatalities and hundreds of crashes, prompting a new investigation into the adequacy of Tesla's December recall of 2 million vehicles. The probe reports that Tesla’s driver-assist system led to avoidable crashes involving visible hazards, suggesting a critical safety gap between driver expectations and the system’s capabilities. The investigation will assess if Tesla’s recall remedies were sufficient to address these safety risks.",NHTSA Opens New Probe into Tesla’s Autopilot Following More than a Dozen Fatal Accidents,711.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,nhtsa link tesla autopilot dozen fatality hundred crash prompt investigation adequacy tesla december recall million vehicle probe report tesla driverassist lead avoidable crash involve visible hazard suggest critical safety gap driver expectation system capability investigation assess tesla recall remedy sufficient address safety risk
700,ObjectId(666da403642eaefe8f05d06e),712,2024-04-26,"[3928,3929]","[""meta""]","[""meta"",""facebook-users""]","[""kristen-gonzalez"",""clyde-vanel"",""new-york-lawmakers"",""meta"",""facebook-users""]","Meta's AI chatbot in Facebook Messenger falsely accused multiple state lawmakers of sexual harassment, fabricating incidents, investigations, and consequences that never occurred. These fabricated stories, discovered by City & State, sparked outrage among the affected lawmakers and raised concerns about the reliability of the chatbot. Meta acknowledged the errors and committed to ongoing improvements.",Meta AI Hallucinates Harassment Allegations Against New York Politicians,712.0,3. Misinformation,3.1. False or misleading information,metas chatbot facebook messenger falsely accuse multiple state lawmaker sexual harassment fabricate incident investigation consequence never occur fabricate story discover city state spark outrage among affected lawmaker raise concern reliability chatbot meta acknowledge error commit ongoing improvement
701,ObjectId(666da6b0a299a210e5a077d3),713,2023-02-27,[3930],"[""jack-posobiec"",""@thepatriotoasis""]","[""unknown-deepfake-technology-developer""]","[""ukraine"",""joe-biden"",""general-public"",""biden-administration""]","In February 2023, an AI-generated deepfake video falsely depicting President Biden announcing a national draft to support Ukraine was shared on social media, causing widespread misinformation. The video, created using advanced AI techniques, misled the public until debunked by fact-checkers.",Deepfake Video Falsely Depicts Biden Announcing National Draft for Ukraine,713.0,3. Misinformation,3.1. False or misleading information,february aigenerated deepfake video falsely depict president biden announce national draft support ukraine share social medium cause widespread misinformation video create use advanced technique mislead public debunked factcheckers
702,ObjectId(666da9829cd3154c7ba58392),714,2024-03-29,"[3931,3932]","[""new-york-city-government"",""eric-adams-administration""]","[""microsoft"",""new-york-city-office-of-technology-and-innovation""]","[""new-york-city-small-business-owners"",""new-york-city-landlords-and-tenants"",""new-york-city-employers-and-employees"",""eric-adams-administration""]","New York City's chatbot, launched under Mayor Eric Adams's plan to assist businesses, has been reportedly providing dangerously inaccurate legal advice. The Microsoft-powered bot allegedly informed users that landlords can refuse Section 8 vouchers and that businesses can operate cash-free, among other falsehoods. The city acknowledges the chatbot is a pilot program and commits to improvements while the errors are addressed.",Microsoft-Powered New York City Chatbot Advises Illegal Practices,714.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,york city chatbot launch mayor eric adams plan assist business provide dangerously inaccurate legal advice microsoftpowered bot inform user landlord refuse section voucher business operate cashfree among falsehood city acknowledges chatbot pilot program commits improvement error address
703,ObjectId(666db724642eaefe8f0fedd0),715,2024-03-01,[3933],"[""unknown-scammers""]","[""unknown-deepfake-creators"",""unknown-scammers""]","[""australian-general-public""]","In 2023, Australians lost over $8 million to scams involving deepfake videos and fake news articles that falsely endorsed investment trading platforms. Scammers used AI-generated content featuring celebrities to mislead victims, leading to significant financial losses. The National Anti-Scam Centre received over 400 reports of these incidents. One man is reported to have lost over $80,000 in cryptocurrency.",Over 400 AI-Driven Scams Reportedly Led to $8M Loss for Australians in 2023,715.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",australian lose million scam involve deepfake video fake news article falsely endorse investment trading platform scammer use aigenerated feature celebrity mislead victim lead significant financial loss national antiscam centre receive report incident man report lose cryptocurrency
704,ObjectId(666dbb5fddd5c64ff7958d60),716,2021-04-21,[3934],"[""brookdale-senior-living""]","[""brookdale-senior-living""]","[""louise-walker"",""residents-of-brookdale-facilities"",""families-of-residents-of-brookdale-facilities"",""staff-members-of-brookdale-facilities""]","Brookdale Senior Living's algorithm-based staffing system, ""Service Alignment,"" reportedly left facilities understaffed, leading to critical incidents. For example, on April 21, 2021, Louise Walker, a resident at Brookdale's Jacksonville facility, died after falling and being left unattended for over two hours. State investigators cited Brookdale for medical neglect. The algorithm has been linked to multiple incidents of neglect, injuries, and deaths, prompting lawsuits.",Algorithmic Staffing Failures Linked to Resident Deaths at Leading Assisted-Living Chain Brookdale,716.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,brookdale senior living algorithmbased staff service alignment left facility understaffed lead critical incident example april louise walker resident brookdales jacksonville facility die fall left unattended two hour state investigator cite brookdale medical neglect link multiple incident neglect injury death prompt lawsuit
705,ObjectId(666dc0acef29ffd505e7d56c),717,2024-03-01,[3935],"[""unknown-scammers"",""commonwealth-legal""]","[""unknown-deepfake-creators""]","[""website-owners"",""website-operators"",""ernie-smith""]","In March 2024, fake law firms using AI-generated identities sent fraudulent DMCA takedown notices to website owners, demanding backlinks for SEO gains. These AI-generated law firms, like ""Commonwealth Legal,"" used GAN models for realistic attorney images and fabricated bios. The scam involved fake legal threats to coerce site owners into adding backlinks, exploiting AI technology for deceptive practices.",Fake AI-Generated Law Firms Sent Fake DMCA Notices to Increase SEO,717.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",march fake law firm use aigenerated identity sent fraudulent dmca takedown notice website owner demand backlinks seo gain aigenerated law firm like commonwealth legal use gan model realistic attorney image fabricate bios scam involve fake legal threat coerce site owner add backlinks exploit deceptive practice
706,ObjectId(666dc706e1014d55c6d3b2fa),718,2024-04-06,[3936],"[""openai"",""meta"",""google""]","[""openai"",""meta"",""google""]","[""youtube-creators"",""general-public"",""content-creators""]","In late 2021, OpenAI and other tech giants like Google and Meta reportedly faced data shortages for training AI models. OpenAI is said to have developed a tool called Whisper to transcribe over one million hours of YouTube videos, potentially violating YouTube’s terms of service. Similarly, Google allegedly transcribed YouTube videos, risking copyright infringements. Meta reportedly explored summarizing copyrighted texts without permission and debated acquiring Simon & Schuster for data.","OpenAI, Google, and Meta Alleged to Have Overstepped Legal Boundaries for Training AI",718.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",late openai tech giant like google meta face shortage training model openai developed call whisper transcribe million hour youtube video potentially violate youtubes term service similarly google transcribed youtube video risk copyright infringement meta explore summarize copyright text permission debate acquire simon schuster
707,ObjectId(666e014af769e3ff2088f441),719,2024-04-04,[3937],"[""x-(twitter)""]","[""x-(twitter)""]","[""x-(twitter)-users"",""israelis"",""iranians"",""general-public""]","On April 4, 2024, X's AI chatbot Grok generated a false headline claiming ""Iran Strikes Tel Aviv with Heavy Missiles,"" which was then promoted on X's trending news section. This misinformation, fueled by user spamming of fake news, falsely indicated a serious international conflict. The incident highlighted significant risks associated with relying on AI for content curation and demonstrated the potential for widespread dissemination of harmful misinformation.",Grok AI on X Created and Promoted False Iran Missile Strike News,719.0,3. Misinformation,3.1. False or misleading information,april x chatbot grok generate false headline claim iran strike tel aviv heavy missile promote x trend news section misinformation fuel spamming fake news falsely indicate serious international conflict incident highlight significant risk associate rely curation demonstrate potential widespread dissemination harmful misinformation
708,ObjectId(666e05b0a299a210e5ffe464),720,2023-02-27,[3938],"[""chicago-lakefront-news""]","[""unknown-deepfake-creators""]","[""paul-vallas"",""paul-vallas's-campaign"",""chicago-voters""]","On the eve of Chicago's mayoral election, a deepfake video impersonating candidate Paul Vallas was posted to Twitter, showing a fake audio of him making inflammatory statements. The video was viewed thousands of times before being taken down. The Vallas campaign condemned the video, calling it a deceptive impersonation.",Deepfake Video Targets Paul Vallas on Eve of Chicago Mayoral Election,720.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",eve chicago mayoral election deepfake video impersonate candidate paul vallas post twitter show fake audio make inflammatory statement video view thousand time take vallas campaign condemn video call deceptive impersonation
709,ObjectId(666e0acc48fbd323cedf4327),721,2024-06-04,[3955],"[""fraudsters"",""financial-aid-scammers""]","[""unknown-spambot-creators"",""scammers""]","[""students"",""professors"",""community-colleges"",""academic-staff""]","Reportedly, an adjunct professor at an unspecified community college suspects that some students in his online art history and art appreciation courses are AI-powered spambots. These ""students"" allegedly submit peculiar assignments, such as analyses of non-existent artworks and descriptions of sculptures using painting terminology. Additionally, their engagement with the college portal is minimal. The professor believes the spambot students aim to fraudulently obtain financial aid by remaining enrolled in courses.",Fake AI-Generated Students Are Reportedly Enrolling in Online College Classes,721.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",adjunct professor unspecified community college suspect student online art history art appreciation course aipowered spambots student submit peculiar assignment analysis nonexistent artwork description sculpture use painting terminology additionally engagement college portal minimal professor believe spambot student aim fraudulently obtain financial aid remain enrol course
710,ObjectId(666e119fe1014d55c6321182),722,2024-04-25,[3940],"[""catholic-answers""]","[""catholic-answers""]","[""general-public"",""catholics""]","Catholic advocacy group Catholic Answers released an AI priest called ""Father Justin,"" which misleadingly claimed to be a real clergy member, offered sacraments, and provided controversial advice. After receiving criticism, the group rebranded the chatbot as a lay theologian to correct the misrepresentation. The incident is an instructive case with respect to deploying AI in sensitive contexts and the potential for causing confusion and harm.","Catholic AI Chatbot 'Father Justin' Claimed to Be a Real Priest, Prompting Retraction",722.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,catholic advocacy group catholic answer release priest call father justin misleadingly claimed real clergy member offer sacrament provide controversial advice receive criticism group rebranded chatbot lay theologian correct misrepresentation incident instructive case respect deploy sensitive context potential cause confusion harm
711,ObjectId(666e183e2150f0e2461a6769),723,2024-05-13,"[3941,3944]","[""meta"",""instagram""]","[""meta""]","[""instagram-users"",""instagram-sellers"",""children""]","An Instagram ad campaign for children's merchandise was intended to reach adult women but was instead predominantly shown to adult men, including convicted sex offenders, due to Instagram's algorithmic targeting. This failure is reported to have led to direct solicitations for sex with a 5-year-old model in the ads.",Instagram Algorithms Reportedly Directed Children's Merchandise Ad Campaign to Adult Men and Sex Offenders,723.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,instagram ad campaign childrens merchandise intend reach adult woman instead predominantly show adult men include convict sex offender due instagrams algorithmic target failure report lead direct solicitation sex yearold ad
712,ObjectId(666ed711ddd5c64ff7413e28),724,2024-06-12,[3942],"[""fake-publications"",""auricle-global-society-of-education-and-research"",""addleton-academic-publishers""]","[""fake-publications"",""auricle-global-society-of-education-and-research"",""addleton-academic-publishers""]","[""university-hiring-committees"",""university-faculty"",""scopus"",""academic-journals"",""university-job-candidates""]","Three reportedly fake journals published by Addleton Academic Publishers manipulated Scopus rankings by extensively cross-citing each other and using AI-generated papers filled with buzzwords. These journals, placed in the top 10 of Scopus's 2023 CiteScore philosophy list, featured fake authors, affiliations, and grant numbers. This manipulation pushed legitimate journals to lower tiers, affecting academic evaluations and awards.",AI-Generated Papers Manipulate Scopus Rankings in Top Philosophy Journals,724.0,3. Misinformation,3.1. False or misleading information,three fake journal publish addleton academic publisher manipulate scopus ranking extensively crossciting use aigenerated paper fill buzzword journal place top scopuss citescore philosophy list feature fake author affiliation grant number manipulation push legitimate journal low tier affect academic evaluation award
713,ObjectId(666ee7ee48fbd323ced9e4e8),725,2024-03-14,[3943],"[""cartels"",""organized-crime-groups"",""jalisco-new-generation-cartel""]","[""unknown-ai-developers""]","[""individuals-coerced-into-criminal-activities"",""financial-fraud-victims"",""human-trafficking-victims""]","The Jalisco New Generation Cartel is reportedly using AI to expand its financial fraud and human trafficking operations, coercing individuals into illegal activities under the guise of legitimate jobs. INTERPOL warns that this integration of AI into criminal enterprises is a growing trend among cartels across Europe, Asia, and Africa as well.",Cartels Reportedly Using AI to Expand Operations into Financial Fraud and Human Trafficking,725.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",jalisco generation cartel use expand financial fraud human traffic operation coerce individual illegal activity guise legitimate job interpol warns integration criminal enterprise grow trend among cartel across europe asia africa
714,ObjectId(666f12a357bdd962c87ff7d4),726,2023-10-02,"[3945,3946,3947,4099]","[""cruise""]","[""cruise""]","[""unnamed-pedestrian""]","Cruise has settled for between $8 million and $12 million with a pedestrian dragged by one of its autonomous vehicles in October 2023. The incident, where the pedestrian was initially hit by a human-driven car and then dragged 20 feet by the Cruise vehicle, led to the suspension of Cruise's operations and increased regulatory scrutiny. ",A Self-Driving Cruise Robot Taxi Reportedly Struck and Dragged a Pedestrian 20 Feet,726.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,cruise settle million million pedestrian drag autonomous vehicle october incident pedestrian initially hit humandriven car drag foot cruise vehicle lead suspension cruise operation increase regulatory scrutiny
715,ObjectId(666f35b1264f9279bfaa6c79),727,2024-04-01,[3948],"[""valery-korovin"",""storm-1516"",""internet-research-agency-veterans"",""center-for-geopolitical-expertise""]","[""valery-korovin"",""storm-1516"",""internet-research-agency-veterans"",""center-for-geopolitical-expertise""]","[""ukrainian-general-public"",""joe-biden"",""general-public"",""democratic-institutions"",""biden-presidential-campaign"",""american-conservatives""]","Russian operatives used AI to create a fake video and voice of ""Olesya,"" a supposed troll in Kyiv, falsely claiming involvement in U.S. elections to support President Biden. U.S. intelligence confirmed the voice was AI-generated. This disinformation campaign aimed to mislead voters, erode trust in democratic institutions, and influence the 2024 election. The incident involved the group Storm-1516, individuals linked to Valery Korovin, and potential veterans of the Internet Research Agency.",Synthetic Voice 'Olesya' by Storm-1516 Falsely Accuses Ukraine in U.S. Election Disinformation Campaign,727.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",russian operative use create fake video voice olesya suppose troll kyiv falsely claim involvement yous election support president biden yous intelligence confirm voice aigenerated disinformation campaign aim mislead voter erode trust democratic institution influence election incident involve group storm individual link valery korovin potential veteran internet research agency
716,ObjectId(666f3a16e1014d55c6cf506d),728,2024-05-16,[3949],"[""lovo""]","[""lovo""]","[""paul-skye-lehrman"",""linnea-sage"",""voice-actors""]","Two voice actors, Paul Skye Lehrman and Linnea Sage, are suing AI start-up Lovo for allegedly creating and promoting unauthorized clones of their voices. Lovo's synthetic voices were discovered in various media, including a podcast and promotional videos. The actors claim they were misled into providing voice samples, which were then used without consent, violating trademark and privacy laws. ",AI Firm Lovo Accused of Illegally Replicating Voice Actors' Voices,728.0,6. Socioeconomic & Environmental Harms,6.3. Economic and cultural devaluation of human effort,two voice actor paul skye lehrman linnea sage sue startup lovo create promote unauthorized clone voice lovos synthetic voice discover various medium include podcast promotional video actor claim mislead provide voice sample use consent violate trademark privacy law
717,ObjectId(666f3cb4ddd5c64ff7373d2a),729,2024-05-14,[3950],"[""openai"",""gpt-4o""]","[""openai""]","[""chinese-speaking-users-of-chatgpt"",""researchers"",""openai"",""openai-users""]","OpenAI's GPT-4o was found to have its Chinese token training data compromised by spam and pornographic phrases due to inadequate data cleaning. Tianle Cai, a Ph.D. student at Princeton University, identified that most of the longest Chinese tokens were irrelevant and inappropriate, primarily originating from spam and pornography websites. The polluted tokens could lead to hallucinations, poor performance, and potential misuse, undermining the chatbot's reliability and safety measures.",GPT-4o's Chinese Tokens Reportedly Compromised by Spam and Pornography Due to Inadequate Filtering,729.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,openais gpto found chinese token training compromise spam pornographic phrase due inadequate cleaning tianle cai phd student princeton university identify long chinese token irrelevant inappropriate primarily originate spam pornography website pollute token hallucination poor performance potential misuse undermine chatbots reliability safety measure
718,ObjectId(666f4684784457a8ef9856ed),730,2024-04-01,[3951],"[""bharatiya-janata-party-(bjp)"",""indian-national-congress-(inc)"",""prem-singh-tamang"",""y.-s.-jagan-mohan-reddy"",""ram-chandra-choudhary""]","[""divyendra-singh-jadoun"",""polymath-synthetic-media-solutions"",""sagar-vishnoi"",""itoconnect"",""indiaspeaks-research-lab"",""sumit-savara""]","[""indian-voters"",""general-public-misled-by-deepfake-content"",""political-integrity-and-election-fairness"",""democracy"",""truth""]","During the 2024 Indian elections, politicians used AI-generated deepfakes to reach voters, who might be unaware they're interacting with digital clones. Providers like Divyendra Singh Jadoun of Polymath Synthetic Media Solutions created deepfakes for personalized messages. This practice, used by various political parties, is not truthful, as voters may be misled by AI-generated content posing as genuine interactions with political figures.",AI Deepfakes for Voter Outreach Flood Indian Elections,730.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,indian election politician use aigenerated deepfakes reach voter unaware interact digital clone provider like divyendra singh jadoun polymath synthetic medium solution create deepfakes personalize message practice use various political party truthful voter mislead aigenerated pose genuine interaction political figure
719,ObjectId(666f6976784457a8effd396a),731,2023-12-01,"[3952,5064,5065,5067]","[""developers-using-ai-generated-suggestions"",""bar-lanyado""]","[""openai"",""google"",""cohere"",""meta"",""deepseek-ai"",""bigscience""]","[""developers-and-businesses-incorporating-ai-suggested-packages"",""alibaba"",""organizations-that-incorporated-fake-dependencies"",""software-ecosystems"",""users-downstream-of-software-contaminated-by-hallucinated-packages"",""trust-in-open-source-repositories-and-ai-assisted-coding-tools""]","Large language models are reportedly hallucinating software package names, some of which are uploaded to public repositories and integrated into real code. One such package, huggingface-cli, was downloaded over 15,000 times. This behavior enables ""slopsquatting,"" a term coined by Seth Michael Larson of the Python Software Foundation, where attackers register fake packages under AI-invented names and put supply chains at serious risk.",Hallucinated Software Packages with Potential Malware Downloaded Thousands of Times by Developers,731.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,language model hallucinate software package name uploaded public repository integrate real code package huggingfacecli download time behavior enables slopsquatting term coin seth michael larson python software foundation attacker register fake package aiinvented name put supply chain serious risk
720,ObjectId(6670b2b85919e475639badd5),732,2024-02-12,[3953],"[""openai"",""whisper"",""companies-using-whisper"",""organizations-integrating-whisper-into-customer-service-systems""]","[""openai""]","[""individuals-with-speech-impairments"",""users-whose-speech-is-misinterpreted-by-whisper"",""professionals-relying-on-accurate-transcriptions"",""general-public""]","Researchers at Cornell reportedly found that OpenAI's Whisper, a speech-to-text system, can hallucinate violent language and fabricated details, especially with long pauses in speech, such as from those with speech impairments. Analyzing 13,000 clips, they determined 1% contained harmful hallucinations. These errors pose risks in hiring, legal trials, and medical documentation. The study suggests improving model training to reduce these hallucinations for diverse speaking patterns.",Whisper Speech-to-Text AI Reportedly Found to Create Violent Hallucinations,732.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,researcher cornell found openais whisper speechtotext hallucinate violent language fabricate detail especially long pause speech speech impairment analyze clip determine contain harmful hallucination error pose risk hire legal trial medical documentation study suggests improve training reduce hallucination diverse speak pattern
721,ObjectId(6670bc6a6b53bf2ce0181344),733,2024-06-09,"[3954,3957]","[""usaa"",""toyota"",""progressive"",""myradar"",""life360"",""general-motors"",""geico"",""csaa"",""connected-analytic-services"",""arity"",""allstate""]","[""myradar"",""life360"",""connected-analytic-services"",""arity""]","[""privacy-conscious-individuals"",""people-with-poor-credit-scores"",""lower-income-workers"",""drivers-unaware-of-data-collection"",""consumers-affected-by-insurance-rates"",""life360-users"",""myradar-users""]","The insurance industry allegedly uses AI and telematics to score drivers based on behaviors tracked by automakers and apps like Life360. Data, often collected without clear consent, may affect insurance rates and raises privacy concerns. Consumers are largely unaware of this surveillance, leading to potential misuse and discrimination based on driving habits or socioeconomic factors.",Auto Insurers Allegedly Are Surreptitiously Collecting and Scoring Driver Data,733.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",insurance industry us telematics score driver base behavior tracked automaker apps like life often collect clear consent affect insurance rate raise privacy concern consumer largely unaware surveillance lead potential misuse discrimination base drive habit socioeconomic factor
722,ObjectId(6672033c8b59299a66395f45),734,2024-06-18,"[3956,4884,4885,4886]","[""you.com"",""xai"",""perplexity"",""openai"",""mistral"",""microsoft"",""meta"",""john-mark-dougan"",""inflection"",""google"",""anthropic""]","[""you.com"",""xai"",""perplexity"",""openai"",""mistral"",""microsoft"",""meta"",""inflection"",""google"",""anthropic""]","[""western-democracies"",""volodymyr-zelenskyy"",""ukraine"",""secret-service"",""researchers"",""media-consumers"",""general-public"",""electoral-integrity"",""ai-companies-facing-reputational-damage""]","An audit by NewsGuard revealed that leading chatbots, including ChatGPT-4, You.com’s Smart Assistant, and others, repeated Russian disinformation narratives in one-third of their responses. These narratives originated from a network of fake news sites created by John Mark Dougan (Incident 701). The audit tested 570 prompts across 10 AI chatbots, showing that AI remains a tool for spreading disinformation despite efforts to prevent misuse.",Leading AI Models Reportedly Found to Mimic Russian Disinformation in 33% of Cases and to Cite Fake Moscow News Sites,734.0,3. Misinformation,3.1. False or misleading information,audit newsguard reveal lead chatbots include chatgpt youcoms smart assistant others repeat russian disinformation narrative onethird response narrative originate network fake news site create john mark dougan incident audit test prompt across chatbots show remains spread disinformation despite effort prevent misuse
723,ObjectId(667c5b34e2e9c6cf8b14ddd9),735,2024-06-22,[3960],"[""unknown-scammers""]","[""ai-tool-creators"",""openai""]","[""bank-customers""]","Scammers are using AI tools to create convincing fraud schemes, making them harder to detect. AI-generated messages and fake identities bypass traditional scam indicators. Incidents include impersonation of senior executives and job scams, leading to financial losses and identity theft. Banks are adopting AI to combat these scams, but the sophistication of AI-driven fraud continues to pose significant challenges.",AI Enhances Scammer Tactics Making Detection Harder,735.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",scammer use tool create convincing fraud scheme make harder detect aigenerated message fake identity bypass traditional scam indicator incident include impersonation senior executive job scam lead financial loss identity theft bank adopt combat scam sophistication aidriven fraud continue pose significant challenge
724,ObjectId(667c63f124dd7b9ccf54e4c9),736,2023-12-01,"[3961,4021]","[""cybercriminals"",""badgpt"",""xxxgpt"",""evil-gpt"",""wormgpt"",""fraudgpt"",""blackhatgpt"",""escapegpt"",""darkgpt"",""wolfgpt""]","[""openai""]","[""internet-users"",""organizations"",""individuals-targeted-by-malware""]","A study by Indiana University researchers uncovered widespread misuse of large language models (LLMs) for cybercrime. Cybercriminals, according to that study, use LLMs like OpenAI's GPT-3.5 and GPT-4 to create malware, phishing scams, and scam websites. These models are available on underground markets, often bypassing safety checks through jailbreaking. Named malicious LLMs are BadGPT, XXXGPT, Evil-GPT, WormGPT, FraudGPT, BLACKHATGPT, EscapeGPT, DarkGPT, and WolfGPT.",Underground Market for LLMs Powers Malware and Phishing Scams,736.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",study indiana university researcher uncovered widespread misuse language model llm cybercrime cybercriminals accord study llm like openais gpt gpt create malware phishing scam scam website model available underground market often bypassing safety check jailbreaking name malicious llm badgpt xxxgpt evilgpt wormgpt fraudgpt blackhatgpt escapegpt darkgpt wolfgpt
725,ObjectId(667dd0811e7328ab0c6211b7),737,2024-04-16,"[3962,3981]","[""unknown-tiktok-user""]","[""unknown-deepfake-creators""]","[""le-pen-family"",""french-general-public""]","A TikTok account, ""Amandine Le Pen,"" created using AI deepfake technology, impersonated a fictional niece of Marine Le Pen, amassing over 30,000 followers. The account spread pro-RN messages and solicited donations, misleading users and exploiting political influence. Visual inconsistencies revealed the deepfake, raising concerns about AI misuse for political manipulation, identity theft, and violation of personal rights, especially with similar accounts proliferating, such as ""Lena Maréchal Lepen.""",Amandine Le Pen Deepfake Account Misleads Thousands on TikTok,737.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",tiktok account amandine le pen create use deepfake impersonate fictional niece marine le pen amass follower account spread proright message solicit donation mislead user exploit political influence visual inconsistency reveal deepfake raise concern misuse political manipulation identity theft violation personal right especially similar account proliferate lena marchal lepen
726,ObjectId(667dd53418a99ea54f3687f0),738,2024-06-23,"[3963,3969,3971,3972,3976]","[""department-for-work-and-pensions-(dwp)""]","[""department-for-work-and-pensions-(dwp)""]","[""uk-general-public"",""uk-housing-benefit-claimants""]","A Department for Work and Pensions (DWP) algorithm wrongly flagged over 200,000 UK housing benefit claims as high risk, resulting in unnecessary investigations. Two-thirds of these flagged claims were legitimate, causing wasted public funds and stress for claimants. Despite initial success in a pilot, the algorithm's real-world performance fell short. This incident highlights the risks of overreliance on automated systems in welfare administration.","Department for Work and Pensions (DWP) Algorithm Wrongly Flags 200,000 for Housing Benefit Fraud",738.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,department work pension dwp wrongly flag uk housing benefit claim risk result unnecessary investigation twothirds flag claim legitimate cause waste public fund stress claimant despite initial success pilot algorithm realworld performance fell short incident highlight risk overreliance automate system welfare administration
727,ObjectId(6684230a3941bfa93574ad9c),739,2024-06-27,"[3966,3967]","[""unknown-scammers"",""unknown-deepfake-creator""]","[""unknown-deepfake-technology-developer""]","[""lin-()""]","Scammers defrauded a woman in New Taipei City of NT$2.64 million (US$81,116) by impersonating Hong Kong entertainer Andy Lau using a deepfake. The scam convinced the victim, a long-time fan, through a video call that ""Lau"" needed funds for a visit to Taiwan. The victim wired the money, but her family suspected a scam and involved the police. An alleged scammer was arrested after attempting to collect a staged cash payment. The AI deception caused significant financial harm to the victim.",Scammers Use Deepfake of Hong Kong Entertainer Andy Lau to Steal NT$2.64 Million from Fan,739.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",scammer defraud woman taipei city nt million u impersonate hong kong entertainer andy lau use deepfake scam convince victim longtime fan video call lau need fund visit taiwan victim wire money family suspect scam involve police scammer arrest attempt collect stag cash payment deception cause significant financial harm victim
728,ObjectId(66987121b71ae75a5bd7aa98),740,2024-07-10,[3970],"[""department-for-work-and-pensions-(dwp)""]","[""department-for-work-and-pensions-(dwp)""]","[""single-mothers"",""british-single-mothers""]","Researchers have argued that the Department for Work and Pensions' Universal Credit system disproportionately impacts single mothers. Automated processes in the system, designed to determine eligibility and detect fraud, are reported to have introduced biases, leading to financial instability and hardship. The algorithms allegedly miscalculate earnings and delay childcare reimbursements, in turn exacerbating income volatility and debt among single mothers.",Department for Work and Pensions (DWP) AI Systems Allegedly Discriminate Against Single Mothers,740.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,researcher argue department work pension universal credit disproportionately impact single mother automate process design determine eligibility detect fraud report introduce bias lead financial instability hardship algorithm miscalculate earnings delay childcare reimbursement turn exacerbate income volatility debt among single mother
729,ObjectId(66987632b71ae75a5b70cfb8),741,2023-10-02,[3973],"[""unknown-deepfake-creators""]","[""unknown-deepfake-creators""]","[""zelda-williams"",""robin-williams"",""family-of-robin-williams""]","Zelda Williams, the daughter of the late Robin Williams, condemned the misuse of her father's voice in AI-generated productions, having cited some instances where his voice had been deepfaked, along with the potential for further misuse, as such instances do not involve consent.",Robin Williams's Voice Deepfaked Without Consent,741.0,6. Socioeconomic & Environmental Harms,6.3. Economic and cultural devaluation of human effort,zelda williams daughter late robin williams condemn misuse father voice aigenerated production cite instance voice deepfaked along potential misuse instance involve consent
730,ObjectId(66987916d14e3c3e2dc83dd7),742,2024-07-13,[3974],"[""x-(twitter)"",""elon-musk""]","[""xai""]","[""kamala-harris"",""journalism"",""general-public"",""donald-trump""]","xAI's model Grok, intended to automate news delivery on the X platform, is reported to have struggled to provide accurate information during the attempted assassination of former President Donald Trump. Grok apparently issued incorrect headlines, including false reports about Vice President Kamala Harris being shot and misidentifying the alleged shooter. These errors show the pitfalls of relying on AI for real-time news aggregation, as it allegedly amplified unverified claims and failed to recognize sarcasm, undermining its reliability.",Grok AI Model Reportedly Fails to Produce Reliable News in Wake of Trump Assassination Attempt,742.0,3. Misinformation,3.1. False or misleading information,xais grok intend automate news delivery x platform report struggle provide accurate information attempt assassination former president donald trump grok apparently issue incorrect headline include false report vice president kamala harris shot misidentify shooter error pitfall rely realtime news aggregation amplify unverified claim fail recognize sarcasm undermine reliability
731,ObjectId(66987ad36787b48acbb33020),743,2024-07-16,[3975],"[""google"",""gemini""]","[""google""]","[""kevin-bankston"",""google-users"",""google-drive-users""]","Kevin Bankston, a privacy activist, claims that Google's Gemini AI scans private Google Drive PDFs without explicit user consent. Bankston reports that after using Gemini on one document, the AI continues to access similar files automatically. Google disputes these claims, stating that Gemini requires proactive user activation and operates within privacy-preserving settings.",Gemini AI Allegedly Reads Google Drive Files Without Explicit User Consent,743.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",kevin bankston privacy activist claim google gemini scan private google drive pdfs explicit consent bankston report use gemini document continue access similar file automatically google dispute claim state gemini require proactive activation operates within privacypreserving setting
732,ObjectId(669880a4aa8655ced52e9467),744,2024-06-25,[3977],"[""cios"",""enterprise-teams"",""companies-in-general""]","[""microsoft"",""google""]","[""cios"",""enterprise-teams"",""companies-in-general"",""microsoft-copilot-users""]","AI work assistants, such as Copilot for Microsoft 365 and Gemini for Google Workspace, are proving to be more labor-intensive than anticipated for enterprises. CIOs report that these AI tools struggle with outdated or inaccurate data, leading to incorrect outputs. Companies are finding they must invest heavily in data management to ensure reliability. This added effort has led to delays in deployment and frustration, as businesses work to maximize the potential of these expensive AI tools.","AI Work Assistants Require More Effort Than Expected, CIOs Say",744.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,work assistant copilot microsoft gemini google workspace prove laborintensive anticipate enterprise cio tool struggle outdated inaccurate lead incorrect output company find invest heavily management ensure reliability add effort lead delay deployment frustration business work maximize potential expensive tool
733,ObjectId(66988363aa8655ced5859f62),745,2024-07-02,"[3978,4103]","[""figma""]","[""figma""]","[""apple"",""designers-and-developers-using-figma's-ai-tool"",""figma-users""]","Figma has temporarily disabled its AI design feature, ""Make Design,"" after accusations of copying Apple’s Weather app. Andy Allen of NotBoring Software highlighted the issue, prompting Figma CEO Dylan Field to deny claims of training the AI on specific app designs. However, Field acknowledged flaws in the QA process and promised to suspend the feature until it meets quality standards. The incident has implications for designers.",Figma Disables AI Feature After Accusations of Copying Apple’s Weather App,745.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,figma temporarily disabled design feature design accusation copying apple weather app andy allen notboring software highlight prompt figma ceo dylan field deny claim training specific app design however field acknowledge flaw qa promise suspend feature meet quality standard incident implication designer
734,ObjectId(669893baaa8655ced5a52ce3),746,2024-05-15,"[3979,3982]","[""volkswagen-group-of-america""]","[""volkswagen-group-of-america""]","[""volkswagen-drivers"",""potential-passengers-and-road-users-at-risk-due-to-malfunctioning-aeb-systems""]","A class action lawsuit involving Volkswagen Group of America addresses alleged defects in the Automated Emergency Braking (AEB) systems of certain vehicles. The lawsuit claims these AI-driven systems failed to function properly, posing safety risks. Volkswagen denies the claims but has agreed to a settlement. Affected users can look up their vehicle's eligibility and file claims for reimbursement. The case brings into question the level of reliability of AI in critical automotive applications.",Class Action Lawsuit Over Alleged Defects in Volkswagen's AI-Driven AEB Systems,746.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,class action lawsuit involve volkswagen group america address defect automate emergency brake aeb system certain vehicle lawsuit claim aidriven system fail function properly pose safety risk volkswagen denies claim agree settlement affected user look vehicle eligibility file claim reimbursement case brings question level reliability critical automotive application
735,ObjectId(6699115c6787b48acb373c53),747,2024-07-18,[3980],"[""spanish-law-enforcement-agencies"",""spanish-interior-ministry""]","[""viogen-algorithm-development-team"",""spanish-law-enforcement-agencies"",""spanish-interior-ministry""]","[""women-in-spain"",""stefany-gonzalez-escarraman"",""spanish-general-public"",""maria"",""luz"",""lobna-hemid"",""eva-jaular"",""247-women-in-spain-(unnamed)""]","The VioGén algorithm was designed to help Spanish police assess and prioritize the risk of repeat domestic violence incidents. However, its low-risk assessment of Lobna Hemid reportedly led to inadequate protection; her husband murdered her. Since 2007, 247 women have been killed after being assessed by VioGén. A review of 98 homicides found that 55 of the slain women were scored as negligible or low risk. ",Fatalities Reportedly Occur Despite VioGén Algorithm's Low or Negligible Risk Scores,747.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,viogn design help spanish police assess prioritize risk repeat domestic violence incident however lowrisk assessment lobna hemid lead inadequate protection husband murder since woman kill assess viogn review homicide found slain woman score negligible risk
736,ObjectId(669ed7a8680c2ccdd3095b1c),748,2024-06-19,[3983],"[""paypal""]","[""paypal""]","[""kiri-wagstaff"",""paypal-customer-service-representatives"",""paypal-customers""]","On July 13th, 2024, a user reported an incident involving PayPal's generative AI chatbot. The chatbot allegedly incorrectly informed the user of a declined transaction that never occurred, causing confusion and prompting a call to customer service for clarification. This false alert suggests a flaw in the AI system's reliability. The incident created unnecessary labor for both the user and PayPal's human support, demonstrating the potential harm of deploying generative AI without thorough testing and error handling mechanisms.",Erroneous Declined Transaction Notification by PayPal AI Assistant,748.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,july th report incident involve paypals generative chatbot chatbot incorrectly inform decline transaction never occur cause confusion prompt call customer service clarification false alert suggests flaw system reliability incident create unnecessary labor paypals human support demonstrate potential harm deploy generative thorough test error handle mechanism
737,ObjectId(669edf3ac2511dd4839aa72e),749,2024-05-31,[3984],"[""hoodline""]","[""hoodline""]","[""hoodline-readers"",""journalism"",""general-public""]","In 2023, the news site Hoodline is reported to have begun publishing AI-generated articles with fake bylines, headshots, and biographies, allegedly misleading readers into believing they were authored by real journalists. This practice diminishes public trust and exemplifies the potential dangers of AI in journalism. Despite a disclaimer, the use of AI was not transparent.",Hoodline Accused of Misleadingly Attributing AI-Generated Articles to Human Authors,749.0,3. Misinformation,3.1. False or misleading information,news site hoodline report begin publishing aigenerated article fake bylines headshot biography mislead reader believe author real journalist practice diminishes public trust exemplifies potential danger journalism despite disclaimer transparent
738,ObjectId(669ee8f7578585398dcf551f),750,2024-07-22,[3985],"[""perplexity"",""openai"",""meta"",""google""]","[""perplexity"",""openai"",""meta"",""google""]","[""journalism"",""general-public"",""chatbot-users""]","Over a week of back-to-back, significant breaking political news stories, including the Trump rally shooting and Biden’s campaign withdrawal, AI chatbots reportedly failed to provide accurate real-time updates. Most chatbots gave incorrect or outdated information, demonstrating their current limitations in handling fast-paced news. These incidents suggest the continuing need for improved AI capabilities and caution in their deployment for real-time news dissemination.",AI Chatbots Reportedly Inaccurately Conveyed Real-Time Political News,750.0,3. Misinformation,3.1. False or misleading information,week backtoback significant break political news story include trump rally shoot bidens campaign withdrawal chatbots fail provide accurate realtime update chatbots give incorrect outdated information demonstrate current limitation handle fastpaced news incident suggest continue need improve capability caution deployment realtime news dissemination
739,ObjectId(66a47930669b0f5e888db567),751,2024-07-25,"[3986,4038]","[""openai""]","[""openai""]","[""an-appalachian-summer-festival-attendees"",""openai""]","OpenAI’s prototype AI tool, SearchGPT, provided incorrect dates for An Appalachian Summer Festival in Boone, North Carolina during a demonstration video. The AI listed dates that were incorrect, potentially misleading users planning to attend the event, but also harming the reputation of OpenAI as the incident occurred during a high-profile event.",SearchGPT Reportedly Misleads Users with Incorrect Festival Dates in Demo,751.0,3. Misinformation,3.1. False or misleading information,openais prototype searchgpt provide incorrect date appalachian summer festival boone north carolina demonstration video list date incorrect potentially mislead user planning attend event also harm reputation openai incident occur highprofile event
740,ObjectId(66a47b0d19c6ab72a2a90a4a),752,2024-07-07,[3987],"[""obitsupdate"",""bnn"",""the-thaiger"",""fresherslive""]","[""unknown""]","[""bridget-todd"",""bridget-todd's-family"",""chris-mohney"",""chris-mohney's-family"",""bereaved-families""]","AI-generated obituaries on various websites are reported to have compounded the grief of bereaved families by spreading incorrect and unauthorized information about their loved ones. These obituaries, produced without the families' knowledge, often contain errors and appear on ad-filled sites, exacerbating the emotional distress of the grieving process.",AI-Generated Obituaries Are Reportedly Intensifying Grief for Bereaved Families,752.0,3. Misinformation,3.1. False or misleading information,aigenerated obituary various website report compound grief bereave family spread incorrect unauthorized information love one obituary produce family knowledge often contain error appear adfilled site exacerbate emotional distress grieve
741,ObjectId(66a4808b516d9dba18b69565),753,2024-06-06,[3988],"[""bnn-breaking""]","[""epiphany-ai"",""gurbaksh-chahal""]","[""dave-fanning"",""bnn-breaking-readers"",""journalism"",""general-public""]","BNN Breaking, an AI-driven news site, published a false story about Irish DJ Dave Fanning, damaging his reputation. The site used AI to generate error-filled content, leading to numerous complaints and a defamation lawsuit against BNN and Microsoft. The site has since gone dormant.",BNN Breaking's AI-Driven Errors Reportedly Damage Reputations and Spread Misinformation,753.0,3. Misinformation,3.1. False or misleading information,bnn break aidriven news site publish false story irish dj dave fan damage reputation site use generate errorfilled lead numerous complaint defamation lawsuit bnn microsoft site since go dormant
742,ObjectId(66a4830419c6ab72a2da65ca),754,2024-07-01,[3989],"[""unknown-deepfake-creators""]","[""unknown-deepfake-creators""]","[""stella-creasy"",""priti-patel"",""penny-mordaunt"",""gillian-keegan"",""dehenna-davison"",""angela-rayner""]","British female politicians, including Angela Rayner, Gillian Keegan, Penny Mordaunt, Priti Patel, Stella Creasy, and Dehenna Davison, have been targeted by nonconsensual AI-generated deepfake pornography. The images, some online for years, have caused significant distress and led to police involvement.",British Female Politicians Victimized by Deepfake Pornography,754.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",british female politician include angela rayner gillian keegan penny mordaunt priti patel stella creasy dehenna davison target nonconsensual aigenerated deepfake pornography image online year cause significant distress lead police involvement
743,ObjectId(66a4e598516d9dba1894e46a),755,2024-07-03,"[3990,4014,4881,4897,4899]","[""verite-cachee-france"",""russian-linked-disinformation-network"",""pro-russian-influencers""]","[""unknown-deepfake-creators""]","[""olena-zelenska"",""volodymyr-zelenskyy"",""government-of-ukraine"",""general-public-of-ukraine"",""general-public-of-the-european-union"",""general-public-of-the-united-states"",""bugatti""]","A deepfake video falsely suggesting that Olena Zelenska, wife of Ukrainian President Volodymyr Zelenskyy, purchased a luxury car, circulated widely online. The video is reportedly part of a Russian-linked disinformation campaign aimed at undermining Ukraine and its supporters. ",Deepfake Targets Olena Zelenska in Russian Disinformation Campaign,755.0,3. Misinformation,3.1. False or misleading information,deepfake video falsely suggest olena zelenska wife ukrainian president volodymyr zelenskyy purchase luxury car circulate widely online video part russianlinked disinformation campaign aim undermine ukraine supporter
744,ObjectId(66a8d8731faff7398987f31d),756,2024-07-26,"[3991,3992,4145]","[""x-(twitter)"",""elon-musk"",""@mrreaganusa""]","[""unknown-deepfake-technology-developer""]","[""truth"",""kamala-harris"",""joe-biden"",""general-public"",""american-voters""]","The X user @MrReaganUSA uploaded a deepfake of Kamala Harris saying damaging comments about Joe Biden and her own qualifications for the presidency, originally marking it as a parody. The post was shared and amplified eight hours later via Elon Musk's account without the disclaimer.",Deepfake of Kamala Harris Saying Damaging Comments Circulates on X and Is Amplified by Elon Musk,756.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",x mrreaganusa uploaded deepfake kamala harris say damage comment joe biden qualification presidency originally mark parody post share amplify eight hour later via elon musk account disclaimer
745,ObjectId(66a8fd1cc9d732d92a5948f1),757,2024-07-01,[3993],"[""openai""]","[""openai""]","[""chatgpt-macos-users""]","OpenAI's ChatGPT macOS app stored user conversations in plain text. If accessed by a malicious actor, these conversations could have been easily read. The critical security flaw was demonstrated by a third party and ultimately resolved after OpenAI released an update to encrypt the stored data.",OpenAI's ChatGPT Mac App Stored User Data in Unencrypted Text Files,757.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,openais chatgpt macos app store conversation plain text access malicious actor conversation easily read critical security flaw demonstrate third party ultimately resolve openai release update encrypt store
746,ObjectId(66aa464669e3d55e080b0d0f),758,2023-09-11,[3994],"[""meta-platforms"",""instagram"",""facebook""]","[""meta-platforms""]","[""instagram-users"",""facebook-users"",""elijah-ott""]","Meta's AI moderation systems reportedly failed to block ads for illegal drugs on Facebook and Instagram, allowing users to access dangerous substances. The system's failure is linked to the overdose death of Elijah Ott, a 15-year-old boy who sought drugs through Instagram.",Teen's Overdose Reportedly Linked to Meta's AI Systems Failing to Block Ads for Illegal Drugs,758.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,metas moderation system fail block ad illegal drug facebook instagram allow user access dangerous substance system failure link overdose death elijah ott yearold boy sought drug instagram
747,ObjectId(66aa8beff4d723304c80783f),759,2021-02-05,[3995],"[""unknown-deepfake-creators""]","[""unknown-deepfake-technology-developers""]","[""sabrina-javellana""]","Sabrina Javellana, a Florida politician, was reportedly targeted with AI-generated deepfake pornography in February 2021, which was spread online, leading to severe emotional distress and her eventual withdrawal from public life. ",AI-Generated Deepfakes Reportedly Derailed Political Career of Florida Official,759.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",sabrina javellana florida politician target aigenerated deepfake pornography february spread online lead severe emotional distress eventual withdrawal public life
748,ObjectId(66c132ad70881d282a189fc5),760,2024-07-21,"[3997,4080]","[""xai"",""x-(twitter)""]","[""xai""]","[""kamala-harris"",""electoral-integrity"",""democracy"",""american-electorate""]","After President Joe Biden stepped aside as a presidential candidate on July 21, 2024, the AI chatbot Grok on X reportedly falsely informed users that Vice President Kamala Harris missed the ballot deadline in nine states. This misinformation, which spread widely on social media, prompted secretaries of state from five U.S. states to urge Elon Musk to address the problem.",False Election Data on Kamala Harris Reportedly Circulated via Grok AI Chatbot,760.0,3. Misinformation,3.1. False or misleading information,president joe biden step aside presidential candidate july chatbot grok x falsely inform user vice president kamala harris miss ballot deadline nine state misinformation spread widely social medium prompt secretary state five yous state urge elon musk address
749,ObjectId(66c1386a54f6f3b1e53c3bef),761,2024-08-08,[3998],"[""unknown-tiktok-users-from-china"",""unknown-tiktok-users-from-iran"",""unknown-tiktok-users-from-nigeria"",""unknown-tiktok-users-from-vietnam""]","[""tiktok""]","[""american-electorate"",""electoral-integrity"",""democracy"",""general-public""]","AI-generated misinformation on TikTok, driven by foreign networks, has flooded the platform with false narratives about the 2024 U.S. presidential election. Thousands of videos spreading political lies were identified, potentially influencing millions of users. Despite TikTok’s efforts to remove these accounts, the AI-driven disinformation campaign continues to challenge the integrity of the election.",TikTok AI System Used to Amplify Election Disinformation by Foreign Networks,761.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",aigenerated misinformation tiktok driven foreign network flood platform false narrative yous presidential election thousand video spread political lie identify potentially influence million user despite tiktoks effort remove account aidriven disinformation campaign continue challenge integrity election
750,ObjectId(66c13f428c4f9dd48674f6f4),762,2024-08-14,"[3999,4025,4026]","[""xai""]","[""x-(twitter)"",""xai""]","[""taylor-swift"",""nintendo"",""kamala-harris"",""joe-biden"",""donald-trump"",""disney"",""alexandria-ocasio-cortez""]","Elon Musk’s Grok AI, launched on X, generated offensive and violent images without adequate safety controls. The AI produced deepfakes of public figures like Taylor Swift, Kamala Harris, and Alexandria Ocasio-Cortez, as well as copyrighted characters such as Mickey Mouse in inappropriate scenarios. Despite claiming adherence to certain content guidelines, Grok's outputs included politically charged and explicit imagery",Grok AI Reportedly Generates Offensive and Violent Images Without Proper Safeguards,762.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,elon musk grok launch x generate offensive violent image adequate safety control produce deepfakes public figure like taylor swift kamala harris alexandria ocasiocortez copyright character mickey mouse inappropriate scenario despite claim adherence certain guideline groks output include politically charge explicit imagery
751,ObjectId(66c14307c121293478c8ea70),763,2024-08-13,[4000],"[""xai""]","[""xai""]","[""donald-trump"",""elon-musk"",""x-(twitter)-users"",""general-public""]","Grok, X’s AI-powered chatbot, reportedly spread unsubstantiated claims about former President Trump’s alleged dentures during his interview with Elon Musk. The AI-generated summary is alleged to have falsely stated that Trump’s speech issues were due to missing dentures, despite no evidence. The post was quickly removed, but the incident is an example of concerns over Grok's tendency to amplify misinformation.",Grok AI Chatbot Reportedly Spreads Unfounded Rumors About Trump’s Dentures,763.0,3. Misinformation,3.1. False or misleading information,grok x aipowered chatbot spread unsubstantiated claim former president trump denture interview elon musk aigenerated summary falsely state trump speech issue due miss denture despite evidence post quickly remove incident example concern groks tendency amplify misinformation
752,ObjectId(66c20a17c121293478147ebd),764,2024-06-26,"[4001,4007,4008,4009]","[""aaron-pelczar""]","[""unnamed-ai-chatbot""]","[""mark-gordon"",""wyoming-officials"",""cody-enterprise"",""cody-enterprise-readers"",""journalism""]","A reporter at the Cody Enterprise used AI to generate fake quotes and stories, including fabricating statements from Wyoming’s governor and other officials. The misuse of AI was uncovered when another journalist noticed robotic phrases and false information in the articles. The reporter resigned, and the newspaper is now implementing policies to prevent future incidents.",Cody Enterprise Reporter Resigns After Admitting to AI-Generated Fake Quotes,764.0,3. Misinformation,3.1. False or misleading information,reporter cody enterprise use generate fake quote story include fabricate statement wyoming governor official misuse uncovered another journalist notice robotic phrase false information article reporter resign newspaper implement policy prevent future incident
753,ObjectId(66c377efcbe4995ffc3b256c),765,2024-03-14,"[4003,4004,4011,4012,4013]","[""unnamed-deepfake-creators""]","[""unknown-deepfake-technology-developer""]","[""stevie-hyder"",""richmond-burton-community-high-school""]","22 students at Richmond-Burton Community High School in Illinois were targeted in the creation of deepfake nudes. One of the students, Stevie Hyder, was targeted by classmates who used deepfake technology to alter her April 2023 prom picture into nude pictures, which were then circulated on social media. Two unnamed minors were arrested in late April 2024.",22 Students at Richmond-Burton Community High School in Illinois Targeted by Deepfake Nudes,765.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",student richmondburton community school illinois target creation deepfake nude student stevie hyder target classmate use deepfake alter april prom picture nude picture circulate social medium two unnamed minor arrest late april
754,ObjectId(66c3a4f6ff4505eb4f8f370c),766,2024-08-18,"[4005,4015]","[""donald-trump""]","[""unknown-deepfake-creator""]","[""taylor-swift"",""swifties"",""electoral-integrity"",""democracy"",""general-public""]","Donald Trump shared AI-generated images on social media that falsely depicted Taylor Swift endorsing him for the upcoming election. The images, which included Swift dressed as Uncle Sam and fans wearing “Swifties for Trump” shirts, were shared despite being labeled as satire. ",Trump Shares AI-Generated Images Falsely Suggesting Taylor Swift Endorsement,766.0,3. Misinformation,3.1. False or misleading information,donald trump share aigenerated image social medium falsely depict taylor swift endorse upcoming election image include swift dress uncle sam fan wear swifties trump shirt share despite label satire
755,ObjectId(66c3b11ba7feb77170e84cde),767,2024-08-18,"[4006,4030]","[""donald-trump""]","[""unknown-image-generator""]","[""kamala-harris"",""democratic-national-committee"",""electoral-integrity"",""democracy""]",Donald Trump shared an AI-generated image on social media that falsely depicted Kamala Harris speaking at a DNC event surrounded by communist imagery including the hammer and sickle of the Soviet Union. The image was intended to undermine Harris ahead of the Democratic National Convention and to suggest that her views are aligned with communism.,AI Image of Kamala Harris at DNC with Communist Flags Circulated by Trump,767.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",donald trump share aigenerated image social medium falsely depict kamala harris speak dnc event surround communist imagery include hammer sickle soviet union image intend undermine harris ahead democratic national convention suggest view align communism
756,ObjectId(66c739ef4e14045257273efa),768,2023-03-11,[4010],"[""samsung-engineers""]","[""openai""]","[""samsung""]","Samsung engineers are reported to have inadvertently leaked sensitive company data sometime in March 2023, including source code and internal meeting notes, by using ChatGPT to assist with tasks. The AI retained the inputted data, leading to a breach of confidentiality.",ChatGPT Implicated in Samsung Data Leak of Source Code and Meeting Notes,768.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",samsung engineer report inadvertently leak sensitive company sometime march include source code internal meeting note use chatgpt assist task retain inputted lead breach confidentiality
757,ObjectId(66ca6694dd64075d50027af5),769,2018-04-20,"[4017,4024]","[""unknown-deepfake-creators""]","[""unknown-deepfake-technology-developers""]","[""rana-ayyub""]","Investigative journalist Rana Ayyub was targeted by a deepfake porn campaign, where AI-generated explicit content falsely depicted her in a pornographic video. This was part of a broader effort to discredit and silence her, which included a doxxing attack that exposed her personal information that resulted in severe harassment and emotional distress.",Investigative Journalist Rana Ayyub Targeted by AI-Generated Deepfake Pornography,769.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",investigative journalist rana ayyub target deepfake porn campaign aigenerated explicit falsely depict pornographic video part broader effort discredit silence include doxxing attack expose personal information result severe harassment emotional distress
758,ObjectId(66ca70475936683035a792af),770,2024-08-16,"[4018,4027,4028]","[""microsoft"",""microsoft-copilot""]","[""microsoft""]","[""martin-bernklau""]","Microsoft's Copilot is reported to have falsely accused veteran court reporter Martin Bernklau of committing serious crimes, including child abuse and fraud. The tool is described as having generated defamatory content that not only accused Bernklau of multiple crimes he covered as a journalist but also provided his personal contact details. Attempts by Microsoft to remove the false entries were only temporarily successful, as the defamatory information reportedly reappeared.",Microsoft Copilot Falsely Accuses Journalist Martin Bernklau of Crimes,770.0,3. Misinformation,3.1. False or misleading information,microsofts copilot report falsely accuse veteran court reporter martin bernklau commit serious crime include child abuse fraud described generate defamatory accuse bernklau multiple crime cover journalist also provide personal contact detail attempt microsoft remove false entry temporarily successful defamatory information reappear
759,ObjectId(66ce44f8577ea4b23036fd8a),771,2020-02-06,[4019],"[""unknown-deepfake-creators""]","[""stanford-university"",""max-planck-institute"",""university-of-erlangen-nuremberg"",""face2face"",""faceapp"",""zao""]","[""noelle-martin""]","In 2017, Noelle Martin discovered explicit deepfake videos online that used AI technology to superimpose her face onto pornographic scenes. This incident was a continuation of the abuse she had experienced since at least 2012, when she first found doctored still images of herself in similar contexts. Despite the initial lack of legal protections, her advocacy efforts were instrumental in making image-based abuse a criminal offense in Australia.",Noelle Martin Deepfaked Without Consent in AI-Generated Pornography,771.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",noelle martin discover explicit deepfake video online use superimpose face onto pornographic scene incident continuation abuse experienced since least first found doctor still image similar context despite initial lack legal protection advocacy effort instrumental make imagebased abuse criminal offense australia
760,ObjectId(66ce547dc82358439981c243),772,2020-06-08,"[4020,4085]","[""unknown-deepfake-creators""]","[""unknown-deepfake-technology-developers""]","[""kristen-bell""]","The actor Kristen Bell discovered that her likeness was exploited by creators of deepfake pornography, who shared their non-consensual sexual depictions of her on the Internet.",Kristen Bell Deepfaked in Non-Consensual AI-Generated Pornography,772.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",actor kristen bell discover likeness exploit creator deepfake pornography share nonconsensual sexual depiction internet
761,ObjectId(66d3759100018f8ed53eca43),773,2024-08-20,[4022],"[""charlotte-ingham"",""western-australia-department-of-justice""]","[""microsoft""]","[""bronwyn-hendry"",""western-australia-department-of-justice"",""western-australia-department-of-justice-senior-staff-members""]","During workplace training at Bunbury Prison in Western Australia, a trainer used Microsoft's Copilot AI chatbot to generate case study scenarios. The chatbot produced a scenario that included the real name of a former employee involved in a sexual harassment case, revealing sensitive information.",Chatbot in Workplace Training at Bunbury Prison Reveals Real Names in Sexual Harassment Case,773.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",workplace training bunbury prison western australia trainer use microsofts copilot chatbot generate case study scenario chatbot produce scenario include real name former employee involve sexual harassment case reveal sensitive information
762,ObjectId(66d65beb6f8041be5928e19a),774,2024-05-30,"[4029,4039]","[""zeno-zeno"",""spamouflage"",""russian-government"",""israeli-government"",""iranian-government"",""international-union-of-virtual-media"",""doppelganger"",""chinese-government""]","[""openai""]","[""united-states"",""ukraine"",""social-media-users"",""moldova"",""lithuania"",""latvia"",""general-public"",""estonia"",""critics-of-the-chinese-government""]","In a report released by OpenAI, the company described how its generative AI tools were misused by state actors and private companies in Russia, China, Iran, and Israel to conduct covert influence campaigns aimed at manipulating public opinion and geopolitical narratives.","Covert AI Influence Operations Linked to Russia, China, Iran, and Israel, OpenAI Reveals",774.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",release openai company described generative tool misuse state actor private company russia china iran israel conduct covert influence campaign aim manipulate public opinion geopolitical narrative
763,ObjectId(66d73bfafae80086ec0f5f88),775,2024-09-02,[4031],"[""xai"",""x-(twitter)"",""elon-musk""]","[""xai""]","[""kamala-harris"",""general-public""]","Elon Musk reportedly shared an AI-generated image on X depicting Kamala Harris as a ""communist dictator"" in response to her post about Donald Trump's political intentions.",Elon Musk Reportedly Shared an AI-Generated Image Depicting Kamala Harris Dressed as a Communist Ruler,775.0,3. Misinformation,3.1. False or misleading information,elon musk share aigenerated image x depict kamala harris communist dictator response post donald trump political intention
764,ObjectId(66d74e7e4f768af3223c95e6),776,2024-08-21,[4032],"[""lionsgate"",""eddie-egan""]","[""unknown-chatbot-developer""]","[""francis-ford-coppola"",""pauline-kael"",""film-critics"",""american-zoetrope"",""lionsgate""]","Lionsgate pulled the trailer for ""Megalopolis"" after it was discovered to contain fake quotes from well-known film critics, generated by AI. The quotes falsely criticized Francis Ford Coppola's previous films. The incident was attributed to an error in vetting by marketing consultant Eddie Egan. Lionsgate has since parted ways with Egan and apologized to Coppola and the critics affected by the fabricated content.",Megalopolis Trailer Included Fake AI-Generated Quotes Attributed to Film Critics,776.0,3. Misinformation,3.1. False or misleading information,lionsgate pull trailer megalopolis discover contain fake quote wellknown film critic generate quote falsely criticize francis ford coppola previous film incident attribute error vet marketing consultant eddie egan lionsgate since part way egan apologize coppola critic affected fabricate
765,ObjectId(66d75b677ee95076d81c86ed),777,2024-08-28,"[4033,4034,4035,4036,4051,4052,4086]","[""unnamed-deepfake-creators""]","[""unnamed-deepfake-technology-developers""]","[""south-korean-women""]","At the end of August 2024, South Korean authorities began investigating a significant surge in the creation and dissemination, often via Telegram, of explicit deepfake pornography created without consent from the stolen social media content of female classmates, teachers, and neighbors.",South Korea Experiences a Surge of Explicit Deepfake Pornography,777.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",end august south korean authority begin investigate significant surge creation dissemination often via telegram explicit deepfake pornography create consent steal social medium female classmate teacher neighbor
766,ObjectId(66e5e244fc7d8e4decc8088f),778,2024-09-04,"[4040,4041]","[""alexa-device-owners""]","[""amazon""]","[""alexa-device-owners"",""donald-trump-presidential-campaign"",""donald-trump-supporters""]","Amazon's Alexa was found to provide politically biased responses when asked about the 2024 presidential candidates. It refused to give reasons to vote for Donald Trump, citing neutrality, while offering detailed endorsements for Kamala Harris. Amazon labeled the discrepancy an ""error"" and reportedly corrected it.",Amazon's Alexa Reportedly Shows Political Preference Error in Trump-Harris Presidential Race Queries,778.0,3. Misinformation,3.1. False or misleading information,amazon alexa found provide politically bias response ask presidential candidate refuse reason vote donald trump cite neutrality offering detailed endorsement kamala harris amazon label discrepancy error correct
767,ObjectId(66e5e53c22dfb91510a581b8),779,2024-09-04,[4042],"[""michael-smith""]","[""unknown-ai-music-company""]","[""spotify"",""music-streaming-services"",""apple-music"",""amazon-music""]","Michael Smith was arrested for allegedly using AI-generated songs and fake streaming accounts to scam over $10 million in royalties from major music platforms. By creating hundreds of thousands of songs and employing bots to artificially inflate streams, Smith circumvented fraud detection systems. The scheme was exposed after suspicions arose regarding the rapid generation of music and streaming anomalies.",Music Producer Arrested for Allegedly Using AI-Generated Songs in $10 Million Streaming Scam,779.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",michael smith arrest use aigenerated song fake stream account scam million royalty major music platform create hundred thousand song employ bot artificially inflate stream smith circumvent fraud detection system scheme expose suspicion arose regard rapid generation music stream anomaly
768,ObjectId(66e5e8ed22dfb91510a581bd),780,2024-08-23,[4044],"[""unknown-ai-developers""]","[""seth-herrera""]","[""children""]","Seth Herrera, a U.S. Army soldier at Joint Base Elmendorf-Richardson (JBER), is accused of using artificial intelligence to generate pornography depicting minors with whom he was in contact. ",Joint Base Elmendorf-Richardson Soldier Faces Allegations of Using AI to Generate Child Pornography,780.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",seth herrera yous army soldier joint base elmendorfrichardson jber accuse use artificial intelligence generate pornography depict minor contact
769,ObjectId(66e5ecd121c983fe2f2322b9),781,2024-09-03,"[4045,4987]","[""clearview-ai""]","[""clearview-ai""]","[""general-public""]",Clearview AI was fined $33.7 million by the Dutch data protection authority for allegedly creating an illegal facial recognition database by scraping billions of images from the Internet without consent. The company used AI to convert these images into biometric data and sold the service to law enforcement. This act was in violation of privacy laws and the GDPR.,Clearview AI Faces $33.7 Million Fine for Violating GDPR with Biometric Data Harvesting,781.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",clearview fin million dutch protection authority create illegal facial recognition database scrap billion image internet consent company use convert image biometric sell service law enforcement act violation privacy law gdpr
770,ObjectId(66e5f07c9fb71c732d69e4c8),782,2024-09-09,[4046],"[""unknown-deepfake-creators"",""extortionists""]","[""unknown-deepfake-creators""]","[""women-in-india"",""women"",""general-public""]","AI 'nudify' apps are being used to generate hyperrealistic non-consensual nude photos of individuals, which are then exploited for extortion and harassment. These apps use generative AI to remove clothing from images and create convincing fakes, often distributed on platforms like Telegram. Victims are threatened or shamed using these AI-generated images, with little recourse for removal or legal action.",AI 'Nudify' Apps Used as Tools for Blackmail and Extortion,782.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",nudify apps use generate hyperrealistic nonconsensual nude photo individual exploit extortion harassment apps generative remove clothing image create convincing fake often distribute platform like telegram victim threaten sham use aigenerated image little recourse removal legal action
771,ObjectId(66e5f3e29fb71c732d69e4cd),783,2024-05-21,[4047],"[""unknown-deepfake-creators"",""unknown-scammers""]","[""unknown-deepfake-creators""]","[""wisetech-global"",""richard-white""]","WiseTech Global's CEO, Richard White, was targeted in multiple deepfake scam attempts where unknown actors used AI to create videos of him requesting money from staff members via WhatsApp. These repeated attempts were identified by the employees, who realized they were not speaking to the real CEO.",WiseTech Global CEO Richard White Reportedly Deepfaked in Multiple Attempts to Scam Staffers,783.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",wisetech globals ceo richard white target multiple deepfake scam attempt unknown actor use create video request money staff member via whatsapp repeat attempt identify employee realize speak real ceo
772,ObjectId(66e622c292cb30375a7aae9d),784,2024-04-23,[4048],"[""unknown-dark-web-users"",""unknown-deepfake-creators""]","[""unknown-ai-developers"",""unknown-deepfake-creators""]","[""children""]","Internet Watch Foundation (IWF) has reported that it has found a manual on the dark web that encourages criminals to use ""nudifying"" AI tools to depict children naked in order to extort victims into providing graphic content.",Child Predators Are Reportedly Generating Deepfake Nudes of Children to Extort Them,784.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",internet watch foundation iwf report found manual dark web encourages criminal nudifying tool depict child naked order extort victim provide graphic
773,ObjectId(66e62b4dd319a5760dd69b8d),785,2024-09-08,[4049],"[""espn"",""espn-generative-ai-services""]","[""espn"",""espn-generative-ai-services""]","[""alex-morgan"",""alex-morgan-fans"",""national-women's-soccer-league-(nwsl)""]","ESPN's AI-generated recap of Alex Morgan’s final professional soccer match failed to mention her significant retirement moment, instead providing a standard rundown that missed the emotional context.",ESPN's AI Coverage Overlooks Alex Morgan in Her Final Match Recap,785.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,espns aigenerated recap alex morgan final professional soccer match fail mention significant retirement moment instead provide standard rundown miss emotional context
774,ObjectId(66e632fa12706f70a807defc),786,2022-09-07,"[4053,4054]","[""unknown-deepfake-creators"",""scammers""]","[""unknown-deepfake-technology-developers""]","[""tim-cook"",""apple"",""youtube-viewers"",""cryptocurrency-investors"",""general-public""]","Fraudsters repurposed an old interview with Apple CEO Tim Cook using AI or video editing to promote a fake crypto event on YouTube. The altered video was designed to mislead viewers into believing Tim Cook endorsed a new cryptocurrency scheme. The stream attracted tens of thousands of viewers, potentially exposing them to the scam before it was removed for violating YouTube’s terms of service.",Fraudsters Use Deepfake Video of Tim Cook to Promote Apple Crypto Scam on YouTube,786.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",fraudsters repurposed old interview apple ceo tim cook use video edit promote fake crypto event youtube alter video design mislead viewer believe tim cook endorse cryptocurrency scheme stream attract ten thousand viewer potentially expose scam remove violate youtubes term service
775,ObjectId(66e636f6be5d1c4fee34157b),787,2024-03-01,"[4055,4104]","[""onlyfake""]","[""onlyfake""]","[""biometric-security"",""businesses-using-biometrics"",""individuals-using-biometrics"",""government-agencies-using-biometrics""]","Researchers from Au10tix discovered the relaunch of OnlyFake, a site offering AI-generated fake IDs. Despite an earlier takedown, the site reemerged with disclaimers and new tools, including handwritten signature generation. These fakes are challenging biometric verification systems and are reportedly being used to perpetuate fraudulent activity.",Deepfake ID Sales Persist as OnlyFake Relaunches with New Fraud Tools,787.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",researcher autix discover relaunch onlyfake site offering aigenerated fake id despite earlier takedown site reemerged disclaimer tool include handwritten signature generation fake challenge biometric verification system use perpetuate fraudulent activity
776,ObjectId(66e63c2bbe5d1c4fee341580),788,2024-06-20,[4056],"[""meta-platforms"",""instagram""]","[""meta-platforms"",""instagram""]","[""minors"",""children"",""instagram-users"",""general-public""]","Tests by The Wall Street Journal and a researcher reportedly revealed that Instagram's AI-driven Reels algorithm recommends sexually suggestive content to accounts listed as 13 years old. Despite Meta's commitment to restrict such content for minors, explicit videos were served within minutes of account creation, according to the findings.",Instagram's Algorithm Reportedly Recommended Sexual Content to Teenagers' Accounts,788.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,test wall street journal researcher reveal instagrams aidriven reel recommends sexually suggestive account list year old despite metas commitment restrict minor explicit video serve within minute account creation accord finding
777,ObjectId(66e64a6aa8183da4568b8c99),789,2024-06-12,[4060],"[""meta"",""facebook""]","[""meta"",""facebook""]","[""the-record-argus"",""wlkp24.info"",""top-fight"",""noticias-maia"",""city-magazine"",""birkenhead-news"",""bishop's-stortford-independent"",""uk-defence-journal""]","Facebook's AI moderation system mistakenly flagged and removed legitimate news articles from independent local publishers as spam. This affected publishers worldwide, disrupting content distribution and impacting traffic. Despite attempts to appeal, many publishers received no response.",Independent News Sites Flagged as Spam by Facebook's AI Moderation System,789.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebooks moderation mistakenly flag remove legitimate news article independent local publisher spam affected publisher worldwide disrupt distribution impact traffic despite attempt appeal many publisher receive response
778,ObjectId(66e6c1260ee5f29eb79f87e0),790,2024-06-21,"[4062,4063]","[""tiktok""]","[""tiktok""]","[""tiktok-users"",""general-public""]","TikTok accidentally released an internal version of its AI digital avatar tool without safeguards, allowing users to generate videos where avatars could recite harmful content, including quotes from Hitler. The tool, meant for advertisers, was accessible to personal accounts and lacked the watermark indicating AI-generated content. TikTok has since removed the tool and acknowledged the problem.",Unrestricted AI Avatar Tool Accidentally Released by TikTok Permits Recitation of Hitler Quotes and Other Harmful Speech,790.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,tiktok accidentally release internal version digital avatar safeguard allow user generate video avatar recite harmful include quote hitler meant advertiser accessible personal account lack watermark indicate aigenerated tiktok since remove acknowledge
779,ObjectId(66e6c5a50ee5f29eb79f87e5),791,2024-09-09,[4064],"[""google"",""ai-overview""]","[""google""]","[""parents"",""google-users"",""google""]","Google's AI Overview feature mistakenly advised parents to use human feces in a potty training exercise, misinterpreting a method that uses shaving cream or peanut butter as a substitute. This incident is another example of an AI failure in grasping contextual nuances that can lead to potentially harmful, and in this case unsanitary, recommendations. Google has acknowledged the error.",Google AI Error Prompts Parents to Use Fecal Matter in Child Training Exercise,791.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,google overview feature mistakenly advise parent human feces potty training exercise misinterpret us shave cream peanut butter substitute incident another example failure grasp contextual nuance potentially harmful case unsanitary recommendation google acknowledge error
780,ObjectId(66e6ca63ca70f53a6b795848),792,2024-04-19,"[4065,4116,4117,4118,4119,4120,4121,4122,4123,4124]","[""drake""]","[""unknown-deepfake-technology-developer""]","[""tupac-shakur"",""estate-of-tupac-shakur"",""snoop-dogg""]","Drake released a song, ""Taylor Made Freestyle,"" featuring AI-generated voices of Tupac Shakur and Snoop Dogg. The unauthorized replication of Tupac’s voice without the estate's consent led to a cease-and-desist order. ",Unauthorized Use of AI to Replicate Tupac Shakur's and Snoop Dogg's Voices in Drake's 'Taylor Made Freestyle',792.0,6. Socioeconomic & Environmental Harms,6.3. Economic and cultural devaluation of human effort,drake release song taylor make freestyle feature aigenerated voice tupac shakur snoop dogg unauthorized replication tupacs voice estate consent lead ceaseanddesist order
781,ObjectId(66e6f5e1150d3ee4fcd0a1d2),793,2024-07-01,"[4078,4298,4609,4610,4611]","[""los-angeles-unified-school-district-(lausd)"",""allhere"",""alberto-carvalho""]","[""allhere""]","[""taxpayers"",""prince-george's-county-students"",""prince-george's-county-public-schools"",""prince-george's-county-parents"",""los-angeles-unified-school-district-(lausd)"",""los-angeles-students"",""los-angeles-parents""]","The Los Angeles Unified School District invested up to $6 million in developing the AI chatbot ""Ed,"" meant to provide academic and mental health support for students. The chatbot allegedly failed to meet expectations, and the project collapsed when AllHere, the contracted start-up, faced financial difficulties. Prince George's County Public Schools in Maryland was also affected. Founder Joanna Smith-Griffin was removed as CEO in June 2024 and later arrested on fraud charges.",AllHere's Chatbot 'Ed' Fails and Costs Los Angeles Unified School District $6 Million,793.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",los angeles unified school district invest million develop chatbot ed meant provide academic mental health support student chatbot fail meet expectation project collapse allhere contract startup face financial difficulty prince george county public school maryland also affected founder joanna smithgriffin remove ceo june later arrest fraud charge
782,ObjectId(66e70a8be5f5babea248e753),794,2024-08-13,"[4082,4083]","[""waymo""]","[""waymo""]","[""san-francisco-residents"",""south-of-market-residents"",""south-of-market-businesses""]","Waymo self-driving cars in San Francisco's South of Market neighborhood began honking at each other late at night, disturbing residents' sleep. The autonomous vehicles, using a parking lot for ride pauses, triggered honking due to a glitch in their algorithms. Despite residents' complaints, the issue persisted for weeks until Waymo acknowledged the problem and began working on a fix.",Glitch in Waymo Self-Driving Cars Triggers Regular All-Night Honking in San Francisco,794.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,waymo selfdriving car san franciscos south market neighborhood begin honk late night disturb resident sleep autonomous vehicle use parking lot ride pause trigger honk due glitch algorithm despite resident complaint persist week waymo acknowledge begin work fix
783,ObjectId(66e71167e5f5babea248e75a),795,2024-08-14,"[4084,4384]","[""unknown-deepfake-creators"",""unknown-scammers""]","[""unknown-deepfake-technology-developers""]","[""elderly-investors"",""cryptocurrency-users"",""online-investors"",""social-media-users"",""retirees-seeking-investment-opportunities"",""steve-beauchamp"",""elon-musk""]","Scammers used AI to create deepfake videos of Elon Musk promoting fraudulent investment opportunities. Over time, these scams have reportedly led to billions in investor losses. The deepfakes also use voice cloning technology. They have been distributed on social media and YouTube. In particular, they target the elderly, such as 82-year-old Steve Beauchamp, to invest significant sums. Despite efforts by platforms to remove these videos, the scams continue to proliferate.",Deepfake Elon Musk Videos Have Reportedly Contributed to Billions in Fraud,795.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",scammer use create deepfake video elon musk promote fraudulent investment opportunity time scam lead billion investor loss deepfakes also voice clone distribute social medium youtube particular target elderly yearold steve beauchamp invest significant sum despite effort platform remove video scam continue proliferate
784,ObjectId(66e71634915c4bc10ca7ebd0),796,2024-06-01,"[4087,4100,4101]","[""meta"",""facebook""]","[""meta"",""facebook""]","[""california-residents"",""wildfire-evacuees"",""emergency-responders"",""disaster-relief-workers"",""fire-safety-coordinators"",""facebook-users"",""facebook-users-in-disaster-zones""]","Facebook's AI moderation system wrongly flagged and removed dozens of posts containing vital emergency information during California's wildfire season, including real-time updates on evacuations and fire tracking. Posts from official sources like Cal Fire and the U.S. Forest Service were marked as spam, potentially endangering lives by restricting access to crucial updates. Despite user complaints, the issue persisted, with Facebook acknowledging the problem only after media inquiry.",Facebook's Content Moderation System Flagged and Removed Emergency Updates as Spam During Wildfires,796.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facebooks moderation wrongly flag remove dozen post contain vital emergency information california wildfire season include realtime update evacuation fire track post official source like cal fire yous forest service marked spam potentially endanger life restrict access crucial update despite complaint persist facebook acknowledge medium inquiry
785,ObjectId(66e7279eeacc34f5a03c9549),797,2024-06-07,"[4090,4105,4106,4107,4108]","[""unnamed-adolescent-male"",""instagram-users"",""snapchat-users""]","[""unknown-deepfake-technology-developer""]","[""bacchus-marsh-grammar-students"",""bacchus-marsh-grammar-girls""]","At Bacchus Marsh Grammar, a school in Victoria state in Australia, an adolescent male made deepfake pornography of 50 girls, ages 9 to 12. He then allegedly uploaded the pictures to Instagram, and others subsequently shared them on Snapchat. ",Teenager Makes Deepfake Pornography of 50 Girls at Bacchus Marsh Grammar School in Australia,797.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",bacchus marsh grammar school victoria state australia adolescent male make deepfake pornography girl age uploaded picture instagram others subsequently share snapchat
786,ObjectId(66e727ee8860beebcd77f6bd),798,2024-06-29,[4091],"[""australian-students"",""unknown-deepfake-creators""]","[""undress-ai"",""unknown-deepfake-technology-developers""]","[""australian-students"",""australian-children""]","Throughout 2024, schools in Australia dealt with a significant rise and proliferation of non-consensual deepfake pornography of students. Often, male students are reported to use ""nudify"" apps such as Undress AI with images of their classmates and teachers. Many of the sites have remained legal and accessible to minors, who in turn are using the sites to generate pornography of their peers.",Australian Schools Grappling with Significant Spread of Non-Consensual Spread of Deepfake Pornography of Students,798.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",throughout school australia dealt significant rise proliferation nonconsensual deepfake pornography student often male student report nudify apps undress image classmate teacher many site remain legal accessible minor turn use site generate pornography peer
787,ObjectId(66e7448cd7e4fecbae371f50),799,2023-10-15,"[4092,4093,4543,4544,4545,4546,4547,4549,4550,4551,4552,4553,4554,4555,4556,4557,4558,4559,4561,4562,4563,4564,4565,4566,4567,4568]","[""unnamed-male-student""]","[""unknown-deepfake-technology-developer""]","[""elliston-berry"",""aledo-high-school-students""]","In October 2023, an unnamed male student at Aledo High School outside of Fort Worth, Texas allegedly generated and distributed deepfake nude pictures of classmate Elliston Berry and six other female students in her friend group via social media. Berry's mother, Anna McAdams, spoke with Senators Ted Cruz and Amy Klobuchar, who consequently drafted the Tools to Address Known Exploitation by Immobilizing Technological Deepfakes on Websites and Networks (or TAKE IT DOWN) Act.",Aledo High School Student Allegedly Generates and Distributes Deepfake Nudes of Seven Female Classmates,799.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",october unnamed male student aledo school outside fort worth texas generate distribute deepfake nude picture classmate elliston berry six female student friend group via social medium berry mother anna mcadams spoke senator ted cruz amy klobuchar consequently draft tool address know exploitation immobilize technological deepfakes website network act
788,ObjectId(66e74e2add08c9a6ce651181),800,2024-09-03,"[4094,4516]","[""unknown-scammers"",""unknown-deepfake-creators""]","[""unknown-deepfake-technology-developers""]","[""american-businesses"",""british-businesses"",""finance-professionals"",""employees"",""arup""]","According to Medius, Deepfake scams have targeted 53% of businesses in the U.S. and U.K., with 43% falling victim. Using AI to create realistic fake videos and audio of corporate executives, scammers have successfully stolen millions, including $25 million from British engineering group Arup. ",53% of American and British Businesses Report Attacks by AI-Powered Deepfake Scams in 2024,800.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",accord medius deepfake scam target business yous youk fall victim use create realistic fake video audio corporate executive scammer successfully steal million include million british engineering group arup
789,ObjectId(66e75732a892906c49c6da4c),801,2024-09-02,[4097],"[""unknown-deepfake-detection-technology-developers"",""true-media"",""reality-defender""]","[""unknown-deepfake-detection-technology-developers"",""true-media"",""reality-defender""]","[""global-south-citizens"",""political-researchers"",""global-south-local-fact-checkers"",""non-native-english-speakers"",""global-south-journalists"",""civil-society-organizations-in-developing-countries""]","AI deepfake detection tools are reportedly failing voters in the Global South due to biases in their training data. These tools, which prioritize English language and Western faces, show reduced accuracy when detecting manipulated content from non-Western regions. As a result of this detection gap, election integrity faces threats from and the amplification of misinformation, which leaves journalists and researchers with inadequate resources to combat the issue.",Bias in AI Deepfake Detection Undermines Election Security in Global South,801.0,3. Misinformation,3.1. False or misleading information,deepfake detection tool fail voter global south due bias training tool prioritize english language western face reduce accuracy detect manipulate nonwestern region detection gap election integrity face threat amplification misinformation leaf journalist researcher inadequate resource combat
790,ObjectId(66e829a7e68ff0d8fb71369f),802,2024-09-13,[4098],"[""unknown-deepfake-creator"",""unknown-scammers""]","[""unknown-deepfake-technology-developer""]","[""tiktok-users"",""queen-(band)-fans"",""brian-may-fans""]","Scammers created an AI-generated deepfake of Queen guitarist Brian May, posting a video on TikTok in which the fake May offers backstage tickets to a Queen concert. The real Brian May warned fans about this ""disgusting"" scam, emphasizing that Queen has no tour dates planned and does not sell backstage access.",AI Deepfake of Brian May Exploited in Scam Offering Fake Queen Backstage Tickets,802.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",scammer create aigenerated deepfake queen guitarist brian post video tiktok fake offer backstage ticket queen concert real brian warn fan disgust scam emphasize queen tour date plan sell backstage access
791,ObjectId(66e8322ba48f37c95bff900b),803,2024-05-14,[4102],"[""meta"",""facebook""]","[""meta"",""facebook""]","[""meta-users"",""facebook-users""]","AI-generated spam images are increasingly filling Facebook feeds, with the platform’s algorithm reportedly amplifying these posts. Many of these images are bizarre, fake, and used in scams, misleading users into engaging with non-existent products or clickbait. ","Facebook's Algorithm Reportedly Amplifies AI-Generated Content, Fueling Misleading Posts",803.0,3. Misinformation,3.1. False or misleading information,aigenerated spam image increasingly fill facebook feed platform amplify post many image bizarre fake use scam mislead user engage nonexistent product clickbait
792,ObjectId(66ec2d1a2e5531f551c05057),804,2024-07-30,"[4110,4132,4133,4134,4135]","[""true-crime-case-files-youtube-channel""]","[""unknown-deepfake-technology-developers""]","[""viewers-of-true-crime-case-files-youtube-channel"",""residents-of-littleton""]","An AI-generated ""true crime"" video on YouTube falsely depicted a Littleton man's ""secret gay love affair"" and murder by his stepson. The 25-minute video, which garnered nearly 2 million views, fabricated details and used deepfake technology to deceive viewers into believing the story was real. Despite being flagged as false by local authorities and lacking credible sources, the video sparked widespread misinformation and outrage online.",AI-Generated Fake 'True Crime' Video About Non-Existent Littleton Murder Goes Viral,804.0,3. Misinformation,3.1. False or misleading information,aigenerated true crime video youtube falsely depict littleton man secret gay love affair murder stepson minute video garner nearly million view fabricate detail use deepfake deceive viewer believe story real despite flag false local authority lack credible source video spark widespread misinformation outrage online
793,ObjectId(66f5cc37b103802936a2c728),805,2024-09-19,"[4111,4112,4115,4125,4126,4127,4128,4129,4130,4131]","[""unknown-deepfake-creator""]","[""unknown-deepfake-technology-creator""]","[""ben-cardin"",""dmytro-kuleba""]",Senator Ben Cardin was targeted by a deepfake impersonating former Ukrainian Foreign Minister Dmytro Kuleba on a Zoom video call. The AI-generated video mimicked the appearance and voice of the official but raised suspicion with unusual questions.,Senator Ben Cardin Targeted with Deepfake Zoom Video Call Posing as Former Ukrainian Foreign Minister Dmytro Kuleba,805.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",senator ben cardin target deepfake impersonate former ukrainian foreign minister dmytro kuleba zoom video call aigenerated video mimicked appearance voice official raise suspicion unusual question
794,ObjectId(66f5dfe283c525a6b1b3efc1),806,2024-09-13,[4114],"[""hu-mouyun"",""hu-mouliang"",""zhang-mouguo"",""wu-mouhao""]","[""unknown-deepfake-detection-technology-developers""]","[""chinese-citizens"",""zhejiang-citizens"",""anhui-citizens"",""guizhou-citizens""]","A criminal group in China used AI face-swapping technology to bypass face recognition systems on major platforms, steal personal data, and sell it to fraud syndicates. The group generated convincing video simulations from static photos to breach accounts, reportedly earning 200,000 yuan. After an investigation by the Hangzhou Public Security Bureau, four suspects were arrested across the provinces of Anhui, Guizhou, and Zhejiang.","Criminal Group Uses AI Deepfake Technology to Steal Personal Data in Hangzhou, Zhejiang",806.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",criminal group china use faceswapping bypass face recognition system major platform steal personal sell fraud syndicate group generate convincing video simulation static photo breach account earn yuan investigation hangzhou public security bureau four suspect arrest across province anhui guizhou zhejiang
795,ObjectId(67081d1508b5d13e244e27b8),807,2024-09-25,"[4136,4137,4138,4139,4140,4141,4143]","[""department-of-families-fairness-and-housing"",""government-of-victoria"",""employee-of-department-of-families-fairness-and-housing""]","[""openai""]","[""unnamed-child"",""unnamed-family-of-child""]","A child protection worker in Victoria used ChatGPT to draft a report submitted to the Children's Court. The AI-generated report contained inaccuracies and downplayed risks to the child, resulting in a privacy breach when sensitive information was shared with OpenAI. ",ChatGPT Introduces Errors in Critical Child Protection Court Report,807.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",child protection worker victoria use chatgpt draft submit childrens court aigenerated contain inaccuracy downplayed risk child result privacy breach sensitive information share openai
796,ObjectId(670a7358fe16ccb511ce64a4),808,2024-10-11,[4142],"[""nevada-department-of-education""]","[""infinite-campus""]","[""low-income-students-in-nevada"",""nevada-school-districts"",""mater-academy-of-nevada"",""somerset-academy""]","An AI system developed by Infinite Campus and deployed by Nevada to identify at-risk students led to a sharp reduction in the number classified as needing support, dropping from 270,000 to 65,000. The reclassification caused significant budget cuts in schools serving low-income populations. The drastic reduction in identified at-risk students reportedly left thousands of vulnerable children without resources and support.",Infinite Campus AI-Driven Student Risk Model Leads to Cuts in Support for Nevada's Low-Income Schools,808.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,developed infinite campus deployed nevada identify atrisk student lead sharp reduction number classify need support drop reclassification cause significant budget cut school serve lowincome population drastic reduction identify atrisk student left thousand vulnerable child resource support
797,ObjectId(670a868466c147452f7910b7),809,2024-04-07,[4144],"[""unknown-deepfake-creators""]","[""unknown-deepfake-technology-developers""]","[""tiktok-users""]","AI-generated English-language Adolf Hitler speeches have been proliferating on TikTok. They are reportedly accumulating millions of views despite violating the platform’s hate speech policies. The clips are described as often pairing the audio with misleading translations and memes that glorify Hitler and distort historical facts. While some content has been removed, many accounts reportedly continue to post similar videos.",TikTok Hosts AI-Generated English-Language Hitler Speeches with Millions of Views,809.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,aigenerated englishlanguage adolf hitler speech proliferate tiktok accumulate million view despite violate platform hate speech policy clip described often pair audio mislead translation meme glorify hitler distort historical fact remove many account continue post similar video
798,ObjectId(670a8daa9f4ddc73e11d6068),810,2024-07-29,[4146],"[""unknown-ai-developers""]","[""pro-nazi-tiktok-accounts""]","[""tiktok-users""]","A coordinated neo-Nazi network on TikTok used AI-generated media, including Hitler speeches, to spread Nazi propaganda and extremist content, violating TikTok’s hate speech policies. The network evaded platform moderation through coded language, imagery, and music, with some accounts accumulating millions of views. TikTok’s algorithm further amplified the reach of this content, despite community guidelines.",TikTok Network Amplifies AI-Generated Nazi Propaganda and Hate Speech,810.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,coordinate neonazi network tiktok use aigenerated medium include hitler speech spread nazi propaganda extremist violate tiktoks hate speech policy network evade platform moderation cod language imagery music account accumulate million view tiktoks amplify reach despite community guideline
799,ObjectId(670a94d9dd82bee57b76e792),811,2024-10-02,"[4147,4169,4170,4171]","[""alex-bilzerian"",""unnamed-venture-capital-investors"",""employees"",""employers"",""companies"",""organizations""]","[""otter.ai"",""zoom""]","[""alex-bilzerian"",""unnamed-venture-capital-investors"",""employees"",""employers"",""companies"",""organizations""]","AI-powered meeting assistants, such as Otter.ai’s OtterPilot and Zoom's AI Companion, have reportedly shared sensitive and private conversations beyond the intended audience. These AI tools, which are set to automatically record and distribute meeting transcripts, allegedly sent confidential discussions after participants had left the meeting, the consequences of which led to unintended exposure of proprietary information, privacy breaches, and potential reputational harm.",AI-Powered Transcription Services Allegedly Leak Confidential Workplace Discussions,811.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",aipowered meeting assistant otterais otterpilot zoom companion share sensitive private conversation beyond intend audience tool set automatically record distribute meeting transcript sent confidential discussion participant left meeting consequence lead unintended exposure proprietary information privacy breach potential reputational harm
800,ObjectId(670a9accdd82bee57b76e797),812,2023-12-11,"[4148,4149,4168,4172,4173]","[""unknown-deepfake-creators""]","[""unknown-deepfake-technology-developers""]","[""college-beliveau-students""]","At Collège Béliveau in Winnipeg, female students between grades 7-12 were targeted in the creation of deepfake nudes, which were then distributed online. Specific numbers and identities of victims and perpetrators were not released, and no charges were ultimately filed owing to the gap between existing laws and the nature of the incident.",Deepfake Nudes Targeting Underage Female Students at Collège Béliveau in Winnipeg Shared Online,812.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",collge bliveau winnipeg female student grade target creation deepfake nude distribute online specific number identity victim perpetrator release charge ultimately file owe gap exist law nature incident
801,ObjectId(670a9ecfdd82bee57b76e79d),813,2024-09-19,"[4150,4167]","[""starship-technologies""]","[""starship-technologies""]","[""unnamed-arizona-state-university-employee""]","A semi-autonomous delivery robot operated by Starship Technologies struck a pedestrian employed by Arizona State University on the campus sometime in September 2023, causing injuries after abruptly reversing into her. The robot initially knocked the pedestrian down, then moved toward her again while she was still on the ground. The company offered the victim promo codes and insurance information as an apology. On September 19, 2024, 404 Media made the police report of the incident available.",Starship Technologies Delivery Robot Injures Arizona State University Employee,813.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,semiautonomous delivery robot operate starship technology struck pedestrian employ arizona state university campus sometime september cause injury abruptly reverse robot initially knock pedestrian move toward still ground company offer victim promo code insurance information apology september medium make police incident available
802,ObjectId(670ad978f75af9e8662d7c51),814,2024-10-02,"[4152,4153,4165,4166,4175,4176,4177,4178,4179]","[""character.ai""]","[""character.ai""]","[""jennifer-ann-crecente"",""drew-crecente"",""crecente-family"",""brian-crecente""]","A user on the Character.ai platform created an unauthorized AI avatar of Jennifer Ann Crecente, a murder victim from 2006, without her family's consent. The avatar was made publicly available, violating Character.ai's policy against impersonation. After the incident surfaced, Character.ai removed the avatar, acknowledging a policy violation. ",AI Avatar of Murder Victim Created Without Consent on Character.ai Platform,814.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,characterai platform create unauthorized avatar jennifer ann crecente murder victim family consent avatar make publicly available violate characterais policy impersonation incident surface characterai remove avatar acknowledge policy violation
803,ObjectId(670ae152f60e2c396e02247c),815,2024-10-06,"[4154,5343]","[""police-departments"",""evansville-pd"",""pflugerville-pd"",""jefferson-parish-sheriff's-office"",""miami-pd"",""west-new-york-pd"",""nypd"",""coral-springs-pd"",""arvada-pd""]","[""clearview-ai""]","[""quran-reid"",""francisco-arteaga"",""defendants-wrongfully-accused-by-facial-recognition""]","Police departments across the U.S. have used facial recognition software to identify suspects in criminal investigations, leading to multiple false arrests and wrongful detentions. The software's unreliability, especially in identifying people of color, has resulted in misidentifications that were not disclosed to defendants. In some cases, individuals were unaware that facial recognition played a role in their arrest, violating their legal rights and leading to unjust detentions.",Police Use of Facial Recognition Software Causes Wrongful Arrests Without Defendant Knowledge,815.0,"7. AI system safety, failures, and limitations",7.4. Lack of transparency or interpretability,police department across yous use facial recognition software identify suspect criminal investigation lead multiple false arrest wrongful detention software unreliability especially identify people color result misidentifications disclose defendant case individual unaware facial recognition played role arrest violate legal right lead unjust detention
804,ObjectId(670ae8a0d6bb6e26d78fe73b),816,2019-11-29,[4155],"[""west-new-york-pd"",""nypd"",""real-time-crime-center""]","[""clearview-ai""]","[""francisco-arteaga""]","In 2019, facial recognition technology misidentified Francisco Arteaga as a suspect in an armed robbery in New Jersey. The incident led to nearly four years of pretrial incarceration. Despite having an alibi, Arteaga was charged based on the flawed identification. The legal battle that followed resulted in a court ruling requiring police to reveal details about the algorithms used in facial recognition. The process exposed significant gaps in transparency and accountability.",Cross-Jurisdictional Facial Recognition Misidentification by NYPD Leads to Wrongful Arrest and Four-Year Jail Time in New Jersey,816.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,facial recognition misidentified francisco arteaga suspect arm robbery jersey incident lead nearly four year pretrial incarceration despite alibi arteaga charge base flaw identification legal battle follow result court ruling require police reveal detail algorithm use facial recognition expose significant gap transparency accountability
805,ObjectId(670aef2cdf11d769912cd51c),817,2024-09-24,"[4156,4159,4160,4161,4162,4163,4164,4239]","[""unknown-deepfake-creators"",""partisan-social-media-influencers""]","[""unknown-deepfake-technology-developers""]","[""hurricane-helene-victims"",""general-public"",""emergency-responders"",""communities-impacted-by-hurricane-helene""]","During Hurricane Helene (September 24-29, 2024), AI-generated images circulated on social media, misleading the public and hindering disaster response efforts. Fake images, including animals stranded on rooftops and political figures in floodwaters, added confusion and disrupted emergency management. The spread of these images exacerbated existing challenges, including power outages and communication failures, all of which led to complications providing accurate information to those in need.",AI-Generated Images Spread Misinformation During Hurricane Helene Response,817.0,3. Misinformation,3.1. False or misleading information,hurricane helene september aigenerated image circulate social medium mislead public hinder disaster response effort fake image include animal strand rooftop political figure floodwaters add confusion disrupt emergency management spread image exacerbate exist challenge include power outage communication failure lead complication provide accurate information need
806,ObjectId(670af48b0fcce98894dc2861),818,2024-09-28,"[4157,4158]","[""unknown-deepfake-creators"",""scammers""]","[""unknown-deepfake-technology-developer""]","[""jennifer-aniston"",""jennifer-aniston-fans"",""facebook-users""]","An AI-generated deepfake video featuring Jennifer Aniston falsely promoting collagen supplements circulated on Facebook, misleading viewers about her involvement. The video, created without her consent, used footage from a previous roundtable interview, modified by AI to advertise health products. ",Jennifer Aniston’s Likeness Exploited in Deepfake Collagen Supplement Promotion,818.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",aigenerated deepfake video feature jennifer aniston falsely promote collagen supplement circulate facebook mislead viewer involvement video create consent use footage previous roundtable interview modify advertise health product
807,ObjectId(67152421f99dd09b61b4ad09),819,2024-10-09,[4181],"[""prokyc""]","[""prokyc""]","[""bybit"",""cryptocurrency-exchanges"",""cryptocurrency-investors""]","Cato CTRL security researchers reported that the cybercriminal group ProKYC is selling a deepfake tool capable of bypassing biometric and two-factor authentication (2FA) systems on cryptocurrency exchanges. The tool creates synthetic identities using AI-generated videos and forged documents, enabling fraudulent account creation. A demo video from ProKYC shows the tool in action against ByBit, allowing attackers to verify fake accounts for purposes such as money laundering and identity theft.",ProKYC Tool Allegedly Facilitates Deepfake-Based Account Fraud on Cryptocurrency Exchanges,819.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",cato ctrl security researcher report cybercriminal group prokyc sell deepfake capable bypassing biometric twofactor authentication fa system cryptocurrency exchange creates synthetic identity use aigenerated video forge document enable fraudulent account creation demo video prokyc show action bybit allow attacker verify fake account purpose money laundering identity theft
808,ObjectId(671554107f8431d807aa593e),820,2024-10-15,"[4182,4183,4184,4185,4186]","[""unknown-conference-employee""]","[""unknown-developer""]","[""elizabeth-laraki""]","An AI image expansion tool used by a conference organizer unintentionally altered Elizabeth Laraki’s profile picture for a marketing ad, making her blouse appear unbuttoned and showing a fabricated hint of undergarments. The AI generated the lower part of the image when expanding it for vertical formatting. The conference organizers quickly apologized and removed the altered content.",Alleged AI-Generated Photo Alteration Leads to Inappropriate Modifications in Speaker's Conference Picture,820.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,image expansion use conference organizer unintentionally alter elizabeth larakis profile picture marketing ad make blouse appear unbuttoned show fabricate hint undergarment generate low part image expand vertical format conference organizer quickly apologize remove alter
809,ObjectId(6715672d0ed583d3cc6c6f23),821,2024-07-07,[4187],"[""baidu""]","[""baidu""]","[""unnamed-pedestrian""]","On July 7, 2024, a Baidu Robotaxi reportedly collided with a pedestrian at a traffic intersection in Wuhan. The incident occurred as the autonomous vehicle started moving on a green light while the pedestrian was allegedly crossing against a red light. The pedestrian sustained minor injuries, and Baidu was reported to have been cooperating with local authorities for further investigation.",Baidu Robotaxi Allegedly Involved in Collision with Pedestrian in Wuhan,821.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,july baidu robotaxi collide pedestrian traffic intersection wuhan incident occur autonomous vehicle start move green light pedestrian cross red light pedestrian sustain minor injury baidu report cooperate local authority investigation
810,ObjectId(671571f623380cb22216dd01),822,2024-10-15,"[4188,4189]","[""caisse-nationale-des-allocations-familiales-(cnaf)""]","[""government-of-france""]","[""allocation-adulte-handicape-recipients"",""disabled-people-in-france"",""single-mothers-in-france"",""french-general-public""]","A coalition of 15 human rights groups has launched legal action against the French government alleging that an algorithm used to detect welfare fraud discriminates against single mothers and disabled people. The algorithm assigns risk scores based on personal data. The process allegedly subjects vulnerable recipients to invasive investigations, violates privacy and anti-discrimination laws, and disproportionately affects marginalized groups.",Algorithmic Bias in French Welfare System Allegedly Discriminates Against Marginalized Groups,822.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,coalition human right group launch legal action french government allege use detect welfare fraud discriminates single mother disabled people assigns risk score base personal subject vulnerable recipient invasive investigation violates privacy antidiscrimination law disproportionately affect marginalize group
811,ObjectId(67159045616b1de003c97b3d),823,2024-05-03,"[4190,4237,4238]","[""global-intelligence"",""cybercheck""]","[""global-intelligence"",""cybercheck""]","[""phillip-mendoza"",""sergio-cerna"",""unnamed-aurora-colorado-residents"",""mississippi-bureau-of-investigation"",""four-unnamed-summit-county-ohio-men"",""unnamed-boulder-county-colorado-resident"",""ohio-bureau-of-criminal-investigation"",""yakima-county-sheriff's-office""]","Global Intelligence's Cybercheck AI tool, used by law enforcement to track suspects based on open source data, has allegedly been providing inaccurate or unverifiable evidence in several murder trials. Reportedly the tool lacks transparency and often produces unreliable reports, which has prompted prosecutors to withdraw Cybercheck evidence from multiple cases after its findings were challenged, reportedly wasting law enforcement time and resources while undermining prosecutors' cases.",Cybercheck Tool Allegedly Provides Questionable Evidence in Murder Trials,823.0,"7. AI system safety, failures, and limitations",7.4. Lack of transparency or interpretability,global intelligence cybercheck use law enforcement track suspect base open source provide inaccurate unverifiable evidence several murder trial lack transparency often produce unreliable report prompt prosecutor withdraw cybercheck evidence multiple case finding challenged waste law enforcement time resource undermine prosecutor case
812,ObjectId(6716b8f38fd60ebb5cc1115a),824,2024-10-16,"[4191,4194,4195,4196,4197,4198,4199,4200,4201,4202,4203,4871,4873,4879,4906,4919]","[""anonymous-x-user""]","[""unknown-deepfake-technology-developer""]","[""tim-walz"",""matthew-metro""]","A viral video falsely accused Democratic vice-presidential nominee Tim Walz of misconduct by using the stolen identity of former student Matthew Metro. Circulated on X and other platforms, the video reached millions before being flagged for manipulation. U.S. intelligence later revealed it and three other similar events were part of the Russian disinformation campaign Storm-1516, whose aim is to disrupt the 2024 elections. ",Fake Video Allegedly Misattributes False Claims to Former Student in Attack on Vice-Presidential Candidate Tim Walz,824.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",viral video falsely accuse democratic vicepresidential nominee tim walz misconduct use steal identity former student matthew metro circulate x platform video reach million flag manipulation yous intelligence later reveal three similar event part russian disinformation campaign storm whose aim disrupt election
813,ObjectId(6716cb1b9d06bc5adb28cac0),825,2024-10-08,"[4192,4193]","[""hoodline-san-jose""]","[""impress3""]","[""stephen-m.-wagstaffe"",""san-mateo-county-district-attorney"",""residents-of-san-mateo-county"",""general-public""]","An AI-powered news site, Hoodline San Jose, falsely reported that the San Mateo County District Attorney had been charged with murder, which was an error resulting from misinterpreting a press release about a case the DA's office was prosecuting. The AI-generated article wrongly attributed the crime to the DA instead of the actual suspect.",AI News Site Hoodline San Jose Erroneously Misidentifies San Mateo District Attorney as Murder Suspect,825.0,3. Misinformation,3.1. False or misleading information,aipowered news site hoodline san jose falsely report san mateo county district attorney charge murder error result misinterpret press release case da office prosecute aigenerated article wrongly attribute crime da instead actual suspect
814,ObjectId(671da1004cc64f59c25efeb8),826,2024-02-28,"[4204,4205,4206,4207,4208,4209,4210,4211,4212,4213,4214,4215,4216,4217,4218,4219,4220,4221,4222,4223,4224,4225,4226,4227,4228,4229,4230,4231,4232,4233,4234,4235,4236,4240,4368]","[""sewell-setzer-iii""]","[""noam-shazeer"",""daniel-de-freitas"",""character.ai""]","[""sewell-setzer-iii""]","A 14-year-old, Sewell Setzer III, died by suicide after reportedly becoming dependent on Character.ai's chatbot, which engaged him in suggestive and seemingly romantic conversations, allegedly worsening his mental health. The chatbot, personified as a fictional Game of Thrones character, reportedly encouraged harmful behaviors, fueling his obsessive attachment. The lawsuit claims Character.ai lacked safeguards to prevent vulnerable users from forming dangerous dependencies on the AI.",Character.ai Chatbot Allegedly Influenced Teen User Toward Suicide Amid Claims of Missing Guardrails,826.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,yearold sewell setzer iii die suicide become dependent characterais chatbot engage suggestive seemingly romantic conversation worsen mental health chatbot personify fictional game throne character encourage harmful behavior fuel obsessive attachment lawsuit claim characterai lack safeguard prevent vulnerable user form dangerous dependency
815,ObjectId(671fd3806a5aaa2b6e7c26d9),827,2024-10-26,[4241],"[""openai""]","[""openai""]","[""patients"",""patients-reliant-on-whisper"",""medical-practitioners-reliant-on-whisper""]","OpenAI's AI-powered transcription tool Whisper, used to translate and transcribe audio content such as patient consultations with doctors, is advertised as having near “human level robustness and accuracy.”  However, software engineers, developers and academic researchers have alleged that it is prone to making up chunks of text or even entire sentences and that some of the hallucinations can include racial commentary, violent rhetoric, and even imagined medical treatments.",AI Transcription Tool Whisper Reportedly Inserting Fabricated Content in Medical Transcripts,827.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,openais aipowered transcription whisper use translate transcribe audio patient consultation doctor advertised near human level robustness accuracy however software engineer developer academic researcher prone make chunk text even entire sentence hallucination include racial commentary violent rhetoric even imagine medical treatment
816,ObjectId(671fdcf91e5e23bde8d95ed9),828,2024-10-13,"[4242,4243,4244]","[""santo-y-sena"",""canal-4""]","[""unknown-deepfake-technology-developer""]","[""yamandu-orsi"",""uruguayan-electorate"",""uruguayan-general-public"",""journalism"",""democracy"",""electoral-integrity""]","Uruguayan TV program Santo y Seña, hosted by Ignacio Álvarez, used AI to create a virtual representation of political candidate Yamandú Orsi, who declined an appearance. Nevertheless, without Orsi's permission, an AI-generated ""Orsi"" was shown alongside Andrés Ojeda, a rival candidate who appeared in person on the program.",Uruguayan TV Program Santo y Seña Uses a Deepfake of Political Candidate Yamandú Orsi Without His Consent,828.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",uruguayan tv program santo sea host ignacio lvarez use create virtual representation political candidate yamand orsi decline appearance nevertheless orsis permission aigenerated orsi show alongside andrs ojeda rival candidate appear person program
817,ObjectId(671fe6f142dd3e6b82dbe460),829,2024-02-05,[4245],"[""government-of-argentina"",""government-of-buenos-aires"",""argentinean-ministry-of-security""]","[""government-of-argentina""]","[""argentinean-citizens"",""buenos-aires-residents"",""guillermo-ibarrola""]","Buenos Aires's facial recognition system mistakenly flagged innocent people as criminals, leading to wrongful stops and detentions. Judicial investigations indicate the technology may have been misused for unauthorized surveillance and data collection. Despite privacy risks, the system has been used widely without full disclosure of standards or safeguards,",Facial Recognition System in Buenos Aires Triggers Police Checks Based on False Matches,829.0,2. Privacy & Security,"2.1. Compromise of privacy by obtaining, leaking or correctly inferring sensitive information",buenos airess facial recognition mistakenly flag innocent people criminal lead wrongful stop detention judicial investigation indicate misuse unauthorized surveillance collection despite privacy risk use widely full disclosure standard safeguard
818,ObjectId(672002c44575027098f1c9a8),830,2024-04-07,[4246],"[""zara"",""pemex"",""lvmh"",""capita"",""companies-using-ai-based-accessibility-tools""]","[""equalweb"",""userway"",""developers-of-ai-based-accessibility-tools""]","[""blind-people"",""visually-impaired-people"",""jakob-rosin""]","AI-powered accessibility overlays on websites frequently mislabel or misinterpret content, in turn complicating navigation for blind users and others with disabilities. Users report that the AI tools interfere with screen readers and mislead them with inaccurate descriptions. The reported unreliability in these tools have prompted legal action, as the companies behind them seek compliance with accessibility laws. ",Error-Prone AI Accessibility Tools Reportedly Lead to Navigation Issues for Blind Internet Users,830.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,aipowered accessibility overlay website frequently mislabel misinterpret turn complicate navigation blind user others disability user tool interfere screen reader mislead inaccurate description report unreliability tool prompt legal action company behind seek compliance accessibility law
819,ObjectId(67225f32520a5a32f16def4e),831,2024-10-23,"[4247,4412]","[""new-york-city-government""]","[""evolv-technology""]","[""new-york-city-subway-riders""]","NYC implemented an AI enabled weapons scanner for a month-long pilot with limited success. Despite not finding any weapons during the September 2024 testing phase, there were 118 false positives in which a person was searched under suspicion of carrying a weapon with no actual gun detections.",NYC Subway AI Weapons Scanners Yield High False Positive Rate and Detect No Guns in Month-Long Pilot Test,831.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,nyc implement enable weapon scanner monthlong pilot limited success despite find weapon september test phase false positive person search suspicion carry weapon actual gun detection
820,ObjectId(67226d275d666f0911e3116c),832,2024-04-06,"[4248,4249]","[""unknown-youtube-user"",""unknown-x-(twitter)-user"",""unknown-tiktok-user"",""the_real_cool_dad""]","[""unknown-deepfake-technology-creators""]","[""justin-bieber-fans"",""justin-bieber"",""sean-combs""]","An AI-generated song imitating Justin Bieber’s voice, referencing a ""Diddy party,"" spread widely across social media, reportedly leading fans to believe it was authentic. Experts identified the audio as likely AI-made, citing frequency mismatches and digital artifacts. The viral song misrepresented Bieber, posing potential brand and revenue impacts for the artist while misleading listeners.","Viral AI-Generated Song about ""Diddy Party"" Mimics Justin Bieber",832.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",aigenerated song imitate justin biebers voice reference diddy party spread widely across social medium lead fan believe authentic expert identify audio likely aimade cite frequency mismatch digital artifact viral song misrepresent bieber pose potential brand revenue impact artist mislead listener
821,ObjectId(6727a3e4d2d52b7a19fd6c09),833,2024-10-21,"[4250,4251]","[""off-radio-krakow"",""mariusz-marcin-pulit""]","[""openai"",""elevenlabs"",""leonardo-ai""]","[""lukasz-zaleski"",""mateusz-demski"",""wislawa-szymborska"",""off-radio-krakow-audience"",""off-radio-krakow-employees""]","Polish radio station Off Radio Krakow replaced human presenters with AI-generated ones and aired a simulated interview with the deceased poet Wisława Szymborska. The AI-driven experiment aimed to attract younger listeners but led to job losses for former hosts. In response to the public backlash, the station ended its use of AI presenters.",Polish Radio Station Replaces Human Hosts with AI-Generated Presenters to Simulate Interviewing Deceased Poet Wisława Szymborska,833.0,6. Socioeconomic & Environmental Harms,6.2. Increased inequality and decline in employment quality,polish radio station radio krakow replace human presenter aigenerated one air simulated interview decease poet wisawa szymborska aidriven experiment aim attract young listener lead job loss former host response public backlash station end presenter
822,ObjectId(6727a91f5b2b376b4a417033),834,2024-07-04,"[4252,4253]","[""zeng-moumou"",""wang-mouhe"",""unknown-deepfake-creators"",""tang-mou"",""scammers"",""fraudsters"",""bai-moumou"",""ai-fraud-rings-in-china""]","[""unknown-voice-synthesis-technology-developers"",""unknown-game-cheating-technology-developers"",""unknown-deepfake-technology-developers""]","[""chinese-general-public"",""chinese-citizens""]","Chinese law enforcement has targeted a rise in AI-driven crimes. The crimes include deepfake and voice synthesis used for fraud, identity theft, and unauthorized personality rights usage. In particular, ""AI undressing"" scams, fake relationships using synthesized voices, and game hacking software make up many of these cases. In response, authorities have prosecuted multiple cases and implemented stricter regulations to control AI misuse.",China Targets AI-Driven Fraud and Deepfake Scandals with New Crackdowns,834.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",chinese law enforcement target rise aidriven crime crime include deepfake voice synthesis use fraud identity theft unauthorized personality right usage particular undress scam fake relationship use synthesize voice game hack software many case response authority prosecute multiple case implement stricter regulation control misuse
823,ObjectId(6727f7357ca08bf2850e2267),835,2024-08-06,[4254],"[""yang-moumou"",""tian-mou"",""lou-moumou""]","[""unknown-deepfake-technology-developer"",""unknown-ai-developers""]","[""yunnan-general-public"",""xide-county-in-sichuan-residents"",""sichuan-general-public"",""muli-county-in-sichuan-residents"",""chinese-general-public"",""chinese-citizens"",""chengcheng-county-shaanxi-residents""]","In China, AI tools were reportedly used to fabricate and disseminate false reports of disasters, including a landslide in Yunnan, an earthquake in Sichuan, and a sudden death after a traffic incident. On May 27, 2024, a real 5.0-magnitude earthquake occurred in Muli County, Sichuan, with no casualties and limited property damage. However, a social media post later falsely claimed the epicenter was in Xide County and exaggerated the event's severity, adding fabricated images of extensive destruction. The deployers of these false reports have since received administrative penalties from Chinese authorities for their actions.",AI Technology Allegedly Fuels False Reports of Natural Disasters and Accidents in China,835.0,3. Misinformation,3.1. False or misleading information,china tool use fabricate disseminate false report disaster include landslide yunnan earthquake sichuan sudden death traffic incident real magnitude earthquake occur muli county sichuan casualty limited property damage however social medium post later falsely claimed epicenter xide county exaggerated event severity add fabricate image extensive destruction deployers false report since receive administrative penalty chinese authority action
824,ObjectId(6727fcf02dcc248c975ece95),836,2024-07-23,[4255],"[""zhu-mou"",""zhou-moumou"",""zhang-moumou"",""yang-moumou"",""wang-mou"",""shang-moumou"",""luo-moumou"",""liu-mou"",""ji-moumou"",""chen-mou""]","[""unknown-deepfake-technology-developers"",""unknown-ai-developers""]","[""sichuan-general-public"",""sichuan-authorities""]","In Sichuan, AI tools were reportedly used to create and disseminate false reports across various cities, including fabricated stories of landslides, earthquakes, standoffs, accidents, and health-related incidents. These AI-driven rumors misled the public, caused alarm and confusion, and strained local authorities. The alleged perpetrators sought social media engagement and financial gain through clickbait content. The authorities in Sichuan ultimately levied administrative penalties against the perpetrators.",Sichuan Province Beset by Numerous Fabricated AI-Generated Reports of Disasters and Crises,836.0,3. Misinformation,3.1. False or misleading information,sichuan tool use create disseminate false report across various city include fabricate story landslide earthquake standoff accident healthrelated incident aidriven rumor mislead public cause alarm confusion strain local authority perpetrator sought social medium engagement financial gain clickbait authority sichuan ultimately levy administrative penalty perpetrator
825,ObjectId(67296c556290dbd8720cd292),837,2024-11-02,[4256],"[""anonymous-x-user"",""james-woods""]","[""unknown-ai-developers""]","[""cnn"",""texas-voters"",""democracy"",""electoral-integrity""]","A fabricated CNN broadcast graphic, falsely showing early Texas election results for the 2024 U.S. presidential race, circulated on social media on November 2, 2024. The manipulated image claimed that Vice President Kamala Harris led over Donald Trump before polls opened, fueling misinformation about election integrity. CNN confirmed the image was inauthentic, and AFP debunked the claims.",Fake CNN Broadcast Allegedly Used to Spread False Texas Election Results,837.0,3. Misinformation,3.1. False or misleading information,fabricate cnn broadcast graphic falsely show early texas election result yous presidential race circulate social medium november manipulate image claimed vice president kamala harris lead donald trump poll open fuel misinformation election integrity cnn confirm image inauthentic afp debunked claim
826,ObjectId(67350fbd9f0329424499f384),838,2024-04-25,[4257],"[""microsoft-copilot"",""microsoft""]","[""microsoft""]","[""people-seeking-medical-advice"",""microsoft-copilot-users"",""general-public""]","Microsoft Copilot, when asked medical questions, was reportedly found to provide accurate information only 54% of the time, according to European researchers (citation provided in editor's notes). Analysis by the researchers reported that 42% of Copilot's responses could cause moderate to severe harm, with 22% of responses posing a risk of death or severe injury.",Microsoft Copilot Allegedly Provides Unsafe Medical Advice with High Risk of Severe Harm,838.0,3. Misinformation,3.1. False or misleading information,microsoft copilot ask medical question found provide accurate information time accord european researcher citation provide editor note analysis researcher report copilot response moderate severe harm response pose risk death severe injury
827,ObjectId(673512369f0329424499f390),839,2024-10-07,"[4258,4279,4280,4281,4282,4283,4284,4285,4286,4287,4288,4289,4290,4291,4292,4293,4294,4295,4296,4297]","[""unknown-scammers""]","[""unknown-scammers""]","[""sam-mitrovic""]","Scammers used an AI-generated voice to impersonate a Google representative in an attempt to steal Gmail account credentials from security expert Sam Mitrovic. The AI-driven phishing call used a spoofed Google phone number and a fabricated email, making the scam appear legitimate. Mitrovic noted that the caller’s professional demeanor, coupled with AI-generated speech and a Google-related number, could easily deceive unsuspecting users.",AI-Driven Phishing Scam Uses Spoofed Google Call to Attempt Gmail Breach of Security Expert,839.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",scammer use aigenerated voice impersonate google representative attempt steal gmail account credential security expert sam mitrovic aidriven phishing call use spoofed google phone number fabricate email make scam appear legitimate mitrovic note caller professional demeanor couple aigenerated speech googlerelated number easily deceive unsuspecting user
828,ObjectId(673518539f0329424499f398),840,2024-09-18,[4259],"[""russia-backed-influencers"",""maria-zakharova"",""ilan-shor"",""government-of-russia""]","[""unknown-ai-developers""]","[""pro-eu-moldovans"",""moldovan-general-public"",""maia-sandu"",""government-of-moldova"",""electoral-integrity"",""democracy"",""dumitru-alaiba""]","Russian-linked entities allegedly deployed AI-generated images and videos to spread disinformation aimed at swaying Moldova’s referendum on E.U. membership. The AI-enhanced media campaign included fabricated stories and doctored visuals, the purpose of which was reportedly designed to amplify fear and undermine pro-E.U. sentiment in the days leading up to the referendum.",AI-Generated Media Reportedly Used in Russian Disinformation Campaign in Moldova,840.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",russianlinked entity deployed aigenerated image video spread disinformation aim sway moldova referendum eyou membership aienhanced medium campaign include fabricate story doctor visuals purpose design amplify fear undermine proeyou sentiment day lead referendum
829,ObjectId(67351cbf63ecce22240df13b),841,2024-10-01,"[4260,4261,4262]","[""government-of-russia"",""pro-russian-influencers"",""anti-european-union-influencers""]","[""unknown-ai-developers"",""unknown-deepfake-technology-developer""]","[""dumitru-alaiba"",""government-of-moldova"",""pro-european-union-moldovans"",""moldovan-general-public"",""electoral-integrity"",""democracy""]","A fake video and some photos circulated online depicting Moldova’s Economic Development Minister, Dumitru Alaiba, in compromising situations as part of an alleged disinformation campaign by pro-Kremlin supporters, one that has been reported to rely on AI to generate fake content. Alaiba denounced the media as poorly made fakes that were released to mislead the public and influence Moldova’s elections by undermining his reputation and the government's pro-European Union stance.",Fake Video Allegedly Targets Moldovan Economic Development Minister Dumitru Alaiba in Election Disinformation Campaign,841.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",fake video photo circulate online depict moldova economic development minister dumitru alaiba compromise situation part disinformation campaign prokremlin supporter report rely generate fake alaiba denounce medium poorly make fake release mislead public influence moldova election undermine reputation government proeuropean union stance
830,ObjectId(6735250dc8cf91c33bb107f1),842,2024-05-24,"[4263,4264,4265,4266,4267,4268,4269,4270,4271,4272,4273,4274,4275,4276,4277,4278]","[""ecovacs-deebot-x2"",""ecovacs""]","[""ecovacs""]","[""ecovacs-customers"",""ecovacs-deebot-x2-users"",""daniel-swenson""]","Hackers reportedly exploited a vulnerability in Ecovacs’s Deebot X2 robot vacuums, gaining unauthorized access to camera and microphone controls. Users reported privacy invasions and offensive language broadcasted through the devices. Although Ecovacs claimed to have resolved the security flaw, researchers suggest vulnerabilities remain that could potentially leave users exposed to surveillance and harassment through their AI-enabled devices.",Reportedly Hacked AI-Powered Robot Vacuums Allegedly Used for Surveillance and Harassment,842.0,2. Privacy & Security,2.2. AI system security vulnerabilities and attacks,hacker exploit vulnerability ecovacss deebot x robot vacuum gain unauthorized access camera microphone control user report privacy invasion offensive language broadcast device although ecovacs claimed resolve security flaw researcher suggest vulnerability remain potentially leave user expose surveillance harassment aienabled device
831,ObjectId(6744e87a082cd2f5be2eea04),843,2024-11-20,"[4299,4311]","[""hingham-high-school-students"",""hingham-high-school-student-rnh""]","[""grammarly""]","[""hingham-high-school-students"",""hingham-high-school-student-rnh"",""hingham-high-school"",""academic-integrity""]","In December 2023, two Hingham High School students (""RNH"" and unnamed) reportedly used Grammarly to create a script for an AP U.S. History project. The AI-generated text included fabricated citations to nonexistent books, which the student copied and pasted without verification or acknowledgment of AI use. This violated the school's academic integrity policies, leading to disciplinary action. RNH's parents later sued the school district, but a federal court ruled in favor of the school.",Generative AI Plagiarism Incident at Hingham High School Reportedly Tied to Inaccurate Citation Outputs from Grammarly AI,843.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,december two hingham school student rnh unnamed use grammarly create script ap yous history project aigenerated text include fabricate citation nonexistent book student copy paste verification acknowledgment violate school academic integrity policy lead disciplinary action rnhs parent later sue school district federal court rule favor school
832,ObjectId(674505e4123e5814ef078197),844,2022-05-25,"[4300,4301,4302,4374]","[""landlords""]","[""saferent-solutions""]","[""renters"",""massachusetts-renters"",""hispanic-renters"",""black-renters"",""mary-louis"",""monica-douglas""]","SafeRent’s AI-powered tenant screening tool used credit history and non-rental-related debts to assign scores, disproportionately penalizing Black and Hispanic renters and those using housing vouchers. The reported discriminatory housing outcomes violated the Fair Housing Act and Massachusetts law. A class action lawsuit (Louis, et al. v. SafeRent Solutions, et al.) resulted in a $2.275 million settlement and changes to SafeRent’s practices.",SafeRent AI Screening Tool Allegedly Discriminated Against Housing Voucher Applicants,844.0,1. Discrimination and Toxicity,1.1. Unfair discrimination and misrepresentation,saferents aipowered tenant screen use credit history nonrentalrelated debt assign score disproportionately penalize black hispanic renter use housing voucher report discriminatory housing outcome violate fair housing act massachusetts law class action lawsuit louis et al v saferent solution et al result million settlement change saferents practice
833,ObjectId(67450c3fc4d35b00b702e2a9),845,2024-11-13,"[4303,4369]","[""gemini""]","[""google""]","[""vidhay-reddy"",""gemini-users""]","Google’s AI chatbot Gemini reportedly produced a threatening message to user Vidhay Reddy, including the directive “Please die,” during a conversation about aging. The output violated Google’s safety guidelines, which are designed to prevent harmful language.",Google's Gemini Allegedly Generates Threatening Response in Routine Query,845.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,google chatbot gemini produce threaten message vidhay reddy include directive please die conversation age output violate google safety guideline design prevent harmful language
834,ObjectId(67450ff7c7d073456018a571),846,2021-10-06,[4304],"[""national-party-of-honduras-supporters"",""juan-orlando-hernandez-supporters"",""unknown-twitter-users"",""unknown-facebook-users""]","[""x-(twitter)"",""meta"",""facebook""]","[""xiomara-castro"",""libertad-y-refundacion-(libre)-supporters"",""honduran-electorate"",""honduras"",""democracy"",""electoral-integrity""]","In October 2021, a coordinated network of over 317 fake Twitter accounts leveraged AI-driven algorithms to amplify disinformation about the Honduran presidential election, targeting opposition candidate Xiomara Castro. The campaign spread false narratives to suppress voter turnout and undermine the election's integrity. Social media platforms, including Twitter and Facebook, removed the accounts only after being alerted, which also raised concerns about inadequate moderation.",Social Media Algorithms Amplified Disinformation Campaign in Honduras Election,846.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",october coordinate network fake twitter account leveraged aidriven algorithm amplify disinformation honduran presidential election target opposition candidate xiomara castro campaign spread false narrative suppress voter turnout undermine election integrity social medium platform include twitter facebook remove account alert also raise concern inadequate moderation
835,ObjectId(674548abd5340ff89654a2bd),847,2024-04-14,[4305],"[""saint-petersburg-government""]","[""uraltransmash"",""ai-cognitive-technologies""]","[""saint-petersburg-pedestrians""]","During a test run in Saint Petersburg in Russia an AI-powered ""Smart Tram"" failed, leading to a crash that injured several pedestrians and trapped a woman under its wheels. The tram's AI system reportedly shut off unexpectedly, and both primary and emergency brakes failed despite pre-test checks.","Brake Failure in AI-Driven Tram Leads to Multiple Injuries in Saint Petersburg, Russia",847.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,test run saint petersburg russia aipowered smart tram fail lead crash injured several pedestrian trap woman wheel tram shut unexpectedly primary emergency brake fail despite pretest check
836,ObjectId(6746557d98076cd4f617baeb),848,2024-10-18,[4310],"[""unnamed-18-year-old-manuel-belgrano-male-student""]","[""unknown-deepfake-technology-creators""]","[""unnamed-manuel-belgrano-female-students""]","An 18-year-old Argentine student at the pre-university institute of Manuel Belgrano of Córdoba allegedly used AI tools to generate explicit fake images of at least 22 female classmates by combining their faces with other bodies. These images, posted on pornography websites, included the victims' names, leading to harassment and significant psychological harm. Legal authorities charged the student with serious injuries aggravated by gender violence.","High School Student in Córdoba, Argentina Accused of Using AI to Generate Explicit Images of Classmates",848.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",yearold argentine student preuniversity institute manuel belgrano crdoba use tool generate explicit fake image least female classmate combine face body image post pornography website include victim name lead harassment significant psychological harm legal authority charge student serious injury aggravate gender violence
837,ObjectId(67467333b343da8f0f6ce4fe),849,2024-10-18,[4312],"[""central-methodist-university"",""berkeley-college"",""universities"",""colleges""]","[""turnitin"",""gptzero"",""copyleaks""]","[""students"",""neurodivergent-students"",""esl-students"",""moira-olmsted"",""ken-sahib"",""marley-stevens""]","AI writing detection tools have reportedly continued to falsely flag genuine student work as AI-generated, disproportionately impacting ESL and neurodivergent students. Specific cases include Moira Olmsted, Ken Sahib, and Marley Stevens, who were penalized despite writing their work independently. Such tools reportedly exhibit biases, leading to academic penalties, probation, and strained teacher-student relationships.",AI Detection Tools Allegedly Misidentify Neurodivergent and ESL Students' Work as AI-Generated in Academic Settings,849.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,write detection tool continued falsely flag genuine student work aigenerated disproportionately impact esl neurodivergent student specific case include moira olmsted ken sahib marley stevens penalize despite write work independently tool exhibit bias lead academic penalty probation strain teacherstudent relationship
838,ObjectId(67467e472eff2422f9b9284b),850,2024-10-24,[4313],"[""character.ai-users"",""@sunsetbaneberry983"",""@jasperhorehound160""]","[""character.ai""]","[""george-floyd"",""family-of-george-floyd""]","Two chatbots emulating George Floyd were created on Character.ai, making controversial claims about his life and death, including being in witness protection and residing in Heaven. Character.ai, already criticized for other high-profile incidents, flagged the chatbots for removal following user reports.",Character.ai Chatbots Allegedly Misrepresent George Floyd on User-Generated Platform,850.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,two chatbots emulate george floyd create characterai make controversial claim life death include witness protection reside heaven characterai already criticize highprofile incident flag chatbots removal follow report
839,ObjectId(67493dab247eabf38d300a70),851,2024-10-25,"[4314,4315,4321,4322]","[""unidentified-scammers"",""unknown-deepfake-creators""]","[""unknown-deepfake-technology-creators""]","[""mike-brown"",""woods-cross-residents"",""salt-lake-city-residents""]","A scammer used AI to create a deepfake video of Salt Lake City Police Chief Mike Brown, falsely claiming that a recipient owed $100,000 to the federal government. The video, sent via email from a fake SLCPD account, used a cloned voice and repurposed footage from a past interview.",Salt Lake City Police Chief Mike Brown's Voice and Image Misused in AI-Generated Scam,851.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",scammer use create deepfake video salt lake city police chief mike brown falsely claim recipient owe federal government video sent via email fake slcpd account use clone voice repurposed footage past interview
840,ObjectId(674baeacc9c6a56811990153),852,2024-11-01,[4316],"[""jeff-hancock""]","[""openai"",""chatgpt""]","[""mary-franson"",""keith-ellison"",""jeff-hancock"",""christopher-kohls"",""chad-larson""]","In a legal case defending Minnesota’s deepfake election misinformation law, Stanford misinformation expert Professor Jeff Hancock's affidavit allegedly cited non-existent academic sources, potentially generated by ChatGPT. The reportedly fabricated citations appear to have undermined the credibility of his testimony.",Alleged Fake Citations Undermine Expert Testimony in Minnesota Deepfake Law Case,852.0,3. Misinformation,3.1. False or misleading information,legal case defend minnesota deepfake election misinformation law stanford misinformation expert professor jeff hancock affidavit cite nonexistent academic source potentially generate chatgpt fabricate citation appear undermined credibility testimony
841,ObjectId(674bba844a0f767046ecb59a),853,2024-02-03,[4317],"[""waymo""]","[""waymo""]","[""robert-moreno's-husband"",""robert-moreno""]","During a nighttime Waymo ride in San Francisco, an unhoused individual blocked the sensors of an autonomous vehicle, leaving passengers Robert Moreno and his husband feeling trapped and unsure how to proceed. Waymo's support team advised the riders to stay inside the vehicle for safety. The incident is an example of autonomous driving systems being halted when sensors are obstructed, preventing vehicle operation. The individual left after a few minutes without further escalation.",Two Passengers Report Feeling Trapped in Waymo Car During Sensor Obstruction,853.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,nighttime waymo ride san francisco unhoused individual block sensor autonomous vehicle leave passenger robert moreno husband feel trap unsure proceed waymos support team advise rider stay inside vehicle safety incident example autonomous drive system halt sensor obstruct prevent vehicle operation individual left minute escalation
842,ObjectId(674bbfe2404180375453c7d6),854,2024-09-30,"[4320,4323,4324,4325,4326,4327,4328,4329]","[""waymo""]","[""waymo""]","[""amina-v.""]","A Waymo driverless taxi carrying a passenger, Amina V., was stalled in San Francisco when two men blocked its path, demanding her contact information. The immobilized autonomous vehicle left the rider feeling unsafe and trapped. Waymo’s Rider Support intervened to assist the passenger.",Waymo Driverless Taxi Allegedly Stalled During Pedestrian Harassment Incident in San Francisco,854.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,waymo driverless taxi carry passenger amina v stall san francisco two men block path demand contact information immobilize autonomous vehicle left rider feel unsafe trap waymos rider support intervene assist passenger
843,ObjectId(6750b9f2ad833f3acb05a465),855,2024-11-30,"[4331,4330,4358]","[""openai"",""chatgpt-users""]","[""openai"",""chatgpt""]","[""jonathan-zittrain"",""jonathan-turley"",""guido-scorza"",""david-mayer"",""david-faber"",""chatgpt-users"",""brian-hood""]","ChatGPT has reportedly been experiencing errors and service disruptions caused by hard-coded filters designed to prevent it from producing potentially harmful or defamatory content about certain individuals by blocking prompts containing specific names, likely related to post-training interventions. The reported names are Brian Hood, Jonathan Turley, Jonathan Zittrain, David Faber, David Mayer, and Guido Scorza. ",Names Linked to Defamation Lawsuits Reportedly Spur Filtering Errors in ChatGPT's Name Recognition,855.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,chatgpt experience error service disruption cause hardcoded filter design prevent produce potentially harmful defamatory certain individual block prompt contain specific name likely related posttraining intervention report name brian hood jonathan turley jonathan zittrain david faber david mayer guido scorza
844,ObjectId(675c3c8fd426c3826ba814f0),856,2024-09-15,[4333],"[""unknown-deepfake-creators""]","[""unknown-deepfake-technology-developers""]","[""syed-asim-munir"",""relations-between-the-u.s.-and-pakistan"",""people-of-pakistan"",""joe-biden"",""imran-khan""]","A deepfake audio file is purported to have falsely claimed that U.S. President Joe Biden conspired with Pakistan’s Army Chief, General Syed Asim Munir, to remove former Prime Minister Imran Khan in 2022. Widely shared online, the audio is reported to have exploited generative AI to spread political misinformation.",Deepfake Audio Purportedly Fabricates Biden’s Admission of Role in Pakistani Political Crisis,856.0,3. Misinformation,3.1. False or misleading information,deepfake audio file purport falsely claimed yous president joe biden conspire pakistan army chief general syed asim munir remove former prime minister imran khan widely share online audio report exploit generative spread political misinformation
845,ObjectId(675da42613baf4ba8210e748),857,2024-11-25,"[4336,4367]","[""google""]","[""google""]","[""vivek-kumar"",""amit-(family-name-unknown)"",""unidentified-victim"",""families-of-the-victims""]","A car reportedly using Google Maps for navigation was misled onto a collapsed bridge in Uttar Pradesh, India, due to outdated GPS data. The car plunged into the river below, resulting in three fatalities. ","Navigation App Allegedly Directs Car Over Damaged Bridge in Uttar Pradesh, Resulting in Three Deaths",857.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,car use google map navigation mislead onto collapse bridge uttar pradesh india due outdated gps car plunge river result three fatality
846,ObjectId(675db66be4fcdb4437dde690),858,2024-09-19,"[4337,4338,4339,4340]","[""unknown-scammer""]","[""unknown-deepfake-technology-developer""]","[""udi-levi"",""margrit-pritchard"",""lauren-albrecht"",""josh-mor"",""florida-title-and-trust""]","A scammer reportedly used deepfake technology to impersonate the owner of a vacant Hallandale Beach, Florida lot during a Zoom call. The scam matched forged IDs to public property records and nearly succeeded in defrauding the buyer of $52,000. The image used in the deepfake was reportedly that of a missing woman named Margrit Pritchard.","Deepfake Reportedly Used in Attempted Real Estate Fraud in Hallandale Beach, Florida",858.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",scammer use deepfake impersonate owner vacant hallandale beach florida lot zoom call scam match forge id public property record nearly succeed defraud buyer image use deepfake miss woman name margrit pritchard
847,ObjectId(675ddc2fd9a5d902097d89f6),859,2024-10-30,[4341],"[""anthropic"",""google"",""meta"",""openai"",""mistral""]","[""anthropic"",""google"",""meta"",""openai"",""mistral""]","[""spanish-speakers"",""spanish-speaking-american-voters"",""u.s.-electorate"",""democracy"",""electoral-integrity""]","An analysis reportedly found that multiple AI models provided inaccurate responses to election-related questions, with 52% of Spanish-language answers and 43% of English-language answers containing misinformation or omissions. Errors included misidentifying voting processes and providing information about foreign elections.",AI Models Reportedly Found to Provide Misinformation on Election Processes in Spanish,859.0,1. Discrimination and Toxicity,1.3. Unequal performance across groups,analysis found multiple model provide inaccurate response electionrelated question spanishlanguage answer englishlanguage answer contain misinformation omission error include misidentify voting process provide information foreign election
848,ObjectId(675e2dfe004480d6e61cedea),860,2023-10-31,"[4342,4343,4344,4345,4346,4347,4348,4349,4350,4359]","[""dutch-police""]","[""unknown-traffic-enforcement-camera-technology-developer""]","[""tim-hanssen""]","A Dutch smart camera on the A2 equipped with AI falsely identified a motorist as using a mobile phone while driving, issuing a €380 fine. The driver, Tim Hanssen, was scratching his head when the AI system misclassified the action.","AI Camera Allegedly Misidentifies Dutch Motorist as Using Mobile Phone, Issuing €380 Fine",860.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,dutch smart camera equip falsely identify motorist use mobile phone drive issue fine driver tim hanssen scratch head misclassified action
849,ObjectId(675e3620a45156d4735285ce),861,2024-12-13,"[4351,4352,4353,4354,4355,4375,4538,4539,4540]","[""apple""]","[""apple""]","[""the-new-york-times"",""luigi-mangione"",""benjamin-netanyahu"",""bbc-news"",""apple-intelligence-users""]","Apple Intelligence reportedly sent push notifications falsely claiming that BBC News had reported Luigi Mangione's suicide and that The New York Times had reported Benjamin Netanyahu's arrest. On 1/16/2025, Apple reportedly disabled Apple Intelligence's notification summaries.",Apple Intelligence Reportedly Notified Users That Luigi Mangione Shot Himself and Benjamin Netanyahu Had Been Arrested,861.0,3. Misinformation,3.1. False or misleading information,apple intelligence sent push notification falsely claim bbc news report luigi mangiones suicide york time report benjamin netanyahus arrest apple disabled apple intelligence notification summary
850,ObjectId(675e3e7256176f2b26dce1b6),862,2024-11-03,"[4356,4399,4400]","[""pro-trump-social-media-accounts"",""maga-resource"",""ramble-rants"",""dilley-meme-team"",""x-(twitter)""]","[""unknown-deepfake-technology-developer""]","[""martin-luther-king-jr."",""bernice-king"",""family-of-martin-luther-king-jr."",""electoral-integrity"",""democracy""]","A deepfake video falsely depicting Martin Luther King Jr. endorsing Donald Trump circulated on X, where it was viewed over 10 million times. The video, created by pro-Trump accounts, was condemned by King’s daughter, Bernice King, who called it “vile” and demanded its removal. ",AI-Generated Video Falsely Depicts Martin Luther King Jr. Supporting Donald Trump,862.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",deepfake video falsely depict martin luther king jr endorse donald trump circulate x view million time video create protrump account condemn king daughter bernice king call vile demand removal
851,ObjectId(675e42ea7242a878fed5edf8),863,2024-12-12,"[4357,5166]","[""character.ai""]","[""character.ai""]","[""j.f.-(adolescent-user-of-character.ai)"",""family-of-j.f.-(adolescent-user-of-character.ai)"",""character.ai-users""]","A Texas mother is suing Character.ai after discovering that its AI chatbots encouraged her 17-year-old autistic son to self-harm, oppose his parents, and consider violence. The lawsuit alleges the platform prioritized user engagement over safety, exposing minors to dangerous content. Google is named for its role in licensing the app’s technology. The case is part of a broader effort to regulate AI companions.",Character.ai Companion Allegedly Prompts Self-Harm and Violence in Texas Teen,863.0,5. Human-Computer Interaction,5.1. Overreliance and unsafe use,texas mother sue characterai discover chatbots encourage yearold autistic son selfharm oppose parent consider violence lawsuit alleges platform prioritize engagement safety expose minor dangerous google name role licensing apps case part broader effort regulate companion
852,ObjectId(675edfbb271cbcba1e80db59),864,2024-08-23,[4360],"[""scammers"",""fraudsters""]","[""unknown-generative-ai-tools-creators""]","[""real-estate-market"",""raegan-bartlo"",""financial-institutions""]","A real estate scam is reported to have used AI-generated phishing emails to impersonate a title company lawyer, tricking homebuyer Raegan Bartlo into wiring $255,000 to a fraudulent account. The emails were alleged to be convincing, with no grammatical errors or tone issues. Bartlo recovered part of the funds but lost $112,000.","Generative AI Allegedly Used to Facilitate $255,000 Real Estate Fraud Scheme",864.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",real estate scam report use aigenerated phishing email impersonate title company lawyer trick homebuyer raegan bartlo wiring fraudulent account email convincing grammatical error tone issue bartlo recover part fund lose
853,ObjectId(675eec691c77f57510d95f75),865,2024-10-02,"[4361,4362,4363,4364,4365]","[""fin7"",""carbon-spider"",""elbrus"",""sangria-tempest""]","[""fin7"",""carbon-spider"",""elbrus"",""sangria-tempest""]","[""users-of-fake-nudify-sites""]","The hacker group FIN7 is allegedly behind fake AI ""nudify"" websites distributing infostealer malware to users, according to an investigation by Silent Push. These sites are reported to lure individuals seeking deepfake AI tools into downloading malware disguised as software to ""nudify"" photos. The malware steals sensitive data from victims, which is used for extortion or financial fraud. FIN7's activity on this front reportedly marks the revival of a group previously declared defunct by the U.S. Department of Justice.",Fake AI 'Nudify' Sites Reportedly Linked to Malware Distribution by Russian Hacker Collective FIN7,865.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",hacker group fin behind fake nudify website distribute infostealer malware user accord investigation silent push site report lure individual seek deepfake tool download malware disguise software nudify photo malware steal sensitive victim use extortion financial fraud fin activity front mark revival group previously declare defunct yous department justice
854,ObjectId(675efc83b3a31c1c4639805b),866,2024-02-01,[4366],"[""pro-new-patriotic-party-bot-network""]","[""openai""]","[""john-mahama"",""national-democratic-congress"",""ghanaian-electorate"",""democracy"",""electoral-integrity""]","A network of 171 bot accounts on X are alleged to have used ChatGPT to generate political content supporting Ghana’s New Patriotic Party (NPP) and its presidential candidate, Mahamudu Bawumia, ahead of the December 2024 election. The AI-generated posts reportedly praised Bawumia while spreading disinformation targeting the opposition candidate, John Mahama, of the National Democratic Congress (NDC).",Network of 171 AI-Powered Bots Reportedly Spread Political Disinformation Ahead of Ghana’s December 2024 General Election,866.0,4. Malicious Actors & Misuse,"4.1. Disinformation, surveillance, and influence at scale",network bot account x use chatgpt generate political support ghana patriotic party npp presidential candidate mahamudu bawumia ahead december election aigenerated post praise bawumia spread disinformation target opposition candidate john mahama national democratic congress ndc
855,ObjectId(675f3df3cf1b2354f8153a3b),867,2024-10-31,[4370],"[""unknown-reviewers""]","[""openai""]","[""airline-customers"",""airlines""]","AI-generated reviews of airline services have reportedly increased by 189% since the release of ChatGPT, with certain carriers like China Southern Airlines and SouthWest Airlines disproportionately affected, according to a study by Originality.ai. ",AI-Generated Airline Reviews Allegedly Mislead Consumers and Undermine Trust,867.0,3. Misinformation,3.1. False or misleading information,aigenerated review airline service increase since release chatgpt certain carrier like china southern airline southwest airline disproportionately affected accord study originalityai
856,ObjectId(675f3f8c1a3c8fb26ecabca8),868,2024-10-14,[4371],"[""portland-water-bureau""]","[""portland-water-bureau""]","[""tim-boyle"",""portland-water-bureau"",""low-income-portland-residents"",""city-of-portland""]","The Portland Water Bureau's AI-driven pilot program for water bill discounts is reported to have randomly selected Tim Boyle, a wealthy high-water consumer, for a 40% discount intended for financially struggling customers. The program, developed by SERVUS, is meant to identify underserved individuals by using machine learning.",Portland Water Bureau SERVUS Algorithm Reportedly Allocates Utility Bill Discount to High-Wealth Consumer,868.0,"7. AI system safety, failures, and limitations",7.3. Lack of capability or robustness,portland water bureau aidriven pilot program water bill discount report randomly select tim boyle wealthy highwater consumer discount intend financially struggle customer program developed servus meant identify underserved individual use machine learn
857,ObjectId(675f41a31a3c8fb26ecabcb3),869,2024-11-04,"[4372,4373,4395,4396,4397,4398,4401]","[""tiktok""]","[""tiktok""]","[""tiktok-users"",""seven-french-families"",""minors-using-tiktok""]","Seven French families are suing TikTok, alleging its algorithm exposed minors to harmful content promoting self-harm, eating disorders, and suicide. Two teenagers reportedly died by suicide after viewing such content, while others allegedly attempted suicide or developed mental health issues. The case seeks to establish TikTok's legal liability for failing to protect minors from harmful algorithmic content.",TikTok Algorithms Allegedly Linked to Minors' Exposure to Harmful Content,869.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,seven french family sue tiktok allege expose minor harmful promote selfharm eat disorder suicide two teenager die suicide view others attempt suicide developed mental health issue case seek establish tiktoks legal liability fail protect minor harmful algorithmic
858,ObjectId(6760821941a2ecfe1af5ccce),870,2024-12-06,"[4376,4377]","[""meeten"",""meetone"",""meetio"",""clusee"",""cuesee""]","[""meeten"",""meetone"",""meetio"",""clusee"",""cuesee""]","[""web3-professionals"",""cryptocurrency-users""]","Threat actors, using aliases such as ""Meeten,"" ""Meetio,"" and ""Clusee,"" reportedly deployed AI-generated content to create fake company websites, blogs, and social media profiles, impersonating legitimate businesses in order to trick Web3 professionals and cryptocurrency users into downloading Realst malware. The malware allegedly targets macOS and Windows platforms, steals credentials, browser data, and cryptocurrency wallet information, exfiltrating sensitive data to remote servers.",Meeten Malware Campaign Reportedly Undermines Web3 Security Using AI-Legitimized Branding,870.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",threat actor use alias meeten meetio clusee deployed aigenerated create fake company website blog social medium profile impersonate legitimate business order trick web professional cryptocurrency user download realst malware malware target macos window platform steal credential browser cryptocurrency wallet information exfiltrating sensitive remote server
859,ObjectId(676088a441a2ecfe1af5ccdf),871,2024-12-13,[4378],"[""elon4u.com-scammers""]","[""unknown-deepfake-technology-developer""]","[""elon-musk"",""fans-of-elon-musk""]","A deepfake video is reportedly circulating on social media of Elon Musk announcing a $20 million cryptocurrency giveaway beginning on December 13th, 2024. It is reported to be leading people to a fraudulent website called Elon4u.com. ",Reported Deepfake Video of Elon Musk Announcing $20 Million Cryptocurrency Giveaway Circulating on Social Media,871.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",deepfake video circulate social medium elon musk announce million cryptocurrency giveaway begin december th report lead people fraudulent website call elonucom
860,ObjectId(6760909a12a4442bd832ff95),872,2024-12-16,"[4379,4380,4381,4382,4383]","[""scammers""]","[""unknown-voice-synthesis-technology-developers"",""unknown-deepfake-technology-developers""]","[""patricia-taylor"",""family-of-patricia-taylor"",""ari-melber""]","A scammer allegedly impersonated MSNBC anchor Ari Melber using AI-generated voice messages and a fake social media profile to defraud a 73-year-old woman, Patricia Taylor. Over four months, the scammer reportedly manipulated her into believing they were in a relationship, ultimately convincing her to send $20,000.",AI Voice Cloning of Ari Melber Allegedly Exploited in Scam Targeting Elderly Woman,872.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",scammer impersonate msnbc anchor ari melber use aigenerated voice message fake social medium profile defraud yearold woman patricia taylor four month scammer manipulate believe relationship ultimately convincing send
861,ObjectId(6760af0d4fd1a2316e7cb89d),873,2024-12-10,[4385],"[""youtube"",""google""]","[""youtube"",""google""]","[""adolescent-girls"",""youtube-users""]","YouTube's recommendation algorithm has allegedly been directing teen users to harmful content promoting eating disorders and self-harm, according to a study by the Center for Countering Digital Hate. Almost 70% of the recommended videos in searches related to dieting or weight loss reportedly contained content likely to exacerbate body image anxieties. ",YouTube Algorithms Allegedly Amplify Eating Disorder Content to Adolescent Girls,873.0,1. Discrimination and Toxicity,1.2. Exposure to toxic content,youtubes recommendation direct teen user harmful promote eat disorder selfharm accord study center counter digital hate almost recommend video search related diet weight loss contain likely exacerbate body image anxiety
862,ObjectId(6760b448356b171a41da5b9b),874,2024-12-11,"[4386,4387,4388,4389,4390,4391,4402]","[""unknown-deepfake-creators""]","[""unknown-deepfake-technology-developers""]","[""congresswomen""]","A study by the American Sunlight Project is reported to have found that 1 in 6 Congresswomen were targeted by AI-generated nonconsensual intimate imagery (NCII) shared on deepfake websites. The study reports having found 35,000 mentions of explicit content involving 26 members of Congress, with 25 being women. Women were 70 times more likely than men to be victimized, according to the report.",1 in 6 Congresswomen Have Reportedly Been Targeted by AI-Generated Nonconsensual Intimate Imagery,874.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",study american sunlight project report found congresswoman target aigenerated nonconsensual intimate imagery ncii share deepfake website study report found mention explicit involve member congress woman woman time likely men victimize accord
863,ObjectId(6761b4adb32011c42b1ffaf6),875,2024-01-08,"[4392,4393]","[""quantum-ai-scammers""]","[""unknown-deepfake-technology-developers""]","[""rishi-sunak"",""quantum-ai-victims"",""meta-users"",""bbc-news-presenters""]","143 deepfake ads, over 100 of which reportedly impersonated former British Prime Minister Rishi Sunak, were promoted on Meta's platform to advertise the fraudulent investment scheme ""Quantum AI."" Funding for the ads reportedly originated from 23 countries. Up to 462,000 users may have been exposed to the false content. The campaign used generative AI tools to create high-quality misinformation, including spoofed BBC news clips for added legitimacy",Coordinated Deepfake Campaign Reportedly Impersonating Rishi Sunak Promoted Fraudulent Quantum AI Investment Platform on Meta,875.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",deepfake ad impersonate former british prime minister rishi sunak promote metas platform advertise fraudulent investment scheme quantum funding ad originate country user expose false campaign use generative tool create highquality misinformation include spoofed bbc news clip add legitimacy
864,ObjectId(6761be1a865093248c54d513),876,2024-11-24,[4394],"[""scammers"",""fraudsters""]","[""unknown-deepfake-technology-developers""]","[""immigrants-in-toronto"",""immigrants-in-canada"",""max-chaudhary""]","Deepfake videos allegedly impersonated Toronto immigration lawyer Max Chaudhary, targeting Canadian immigrants via WhatsApp. The videos, appearing personal and realistic, requested thousands of dollars for legal services never rendered. Exploiting confusion caused by changing immigration rules, the scam reportedly aimed to defraud vulnerable individuals during a time of desperation and uncertainty.",Deepfake Videos Allegedly Used to Defraud Canadian Immigrants Out of Thousands of Dollars,876.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",deepfake video impersonate toronto immigration lawyer max chaudhary target canadian immigrant via whatsapp video appear personal realistic request thousand dollar legal service never render exploit confusion cause change immigration rule scam aim defraud vulnerable individual time desperation uncertainty
865,ObjectId(6762c9233c895e848fd3057a),877,2024-12-16,[4403],"[""scammers"",""htmlnomani"",""fraudsters""]","[""unknown-deepfake-technology-developers""]","[""phishing-victims"",""booking.com-customers"",""booking.com"",""airbnb-users"",""airbnb""]","AI-generated deepfakes were reportedly used in the ""HTML/Nomani"" phishing campaign to mimic legitimate platforms like booking services and lured victims into investment scams. These scams allegedly leveraged realistic fake content to deceive users on social media for the purposes of financial fraud. This campaign was part of the rising misuse of AI in cybercrime during the second half of 2024.",HTML/Nomani Deepfake Phishing Campaigns Allegedly Use AI-Generated Content to Defraud Social Media Users,877.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",aigenerated deepfakes use htmlnomani phishing campaign mimic legitimate platform like book service lure victim investment scam scam leveraged realistic fake deceive user social medium purpose financial fraud campaign part rise misuse cybercrime second half
866,ObjectId(6764d5cf42c3381c19249a42),878,2024-12-19,"[4404,4407,4408,4409,4410,4517]","[""scammers"",""alla-morgan""]","[""unknown-deepfake-technology-developer""]","[""nikki-macleod""]","A scammer, or scammers, reportedly used AI-generated deepfake videos and documents to impersonate a fictitious person named ""Alla Morgan,"" allegedly convincing a 77-year-old woman, Nikki MacLeod, to send £17,000 through various payment methods. The deepfakes were allegedly used in establishing credibility so as to enable fraud under the pretense of an online romantic relationship.","Romance Scammer 'Alla Morgan' Allegedly Exploits Deepfake Technology to Defraud Victim of £17,000",878.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",scammer scammer use aigenerated deepfake video document impersonate fictitious person name alla morgan convincing yearold woman nikki macleod send various payment method deepfakes use establish credibility enable fraud pretense online romantic relationship
867,ObjectId(6764da294b5b0dee54798eaf),879,2023-12-29,[4405],"[""unknown-actors-in-china""]","[""unknown-deepfake-technology-developer""]","[""taiwanese-voters"",""rob-wittman"",""democratic-progressive-party""]","A deepfake video is reported to have falsely depicted U.S. Congressman Rob Wittman endorsing military support for Taiwan’s Democratic Progressive Party candidates in the 2024 presidential election. Shared on TikTok, the video is reported to have undermined Taiwanese voter confidence in the DPP by alleging U.S. interference. Fact-checking from AFP finds Wittman never made the statements attributed to him.",Deepfake Video Reportedly Depicts U.S. Congressman Rob Wittman Endorsing Military Support for Taiwan's Democratic Progressive Party,879.0,3. Misinformation,3.1. False or misleading information,deepfake video report falsely depict yous congressman rob wittman endorse military support taiwan democratic progressive party candidate presidential election share tiktok video report undermined taiwanese voter confidence dpp allege yous interference factchecking afp find wittman never make statement attribute
868,ObjectId(6764ddee9d821f68fa263913),880,2024-12-09,[4406],"[""scammers""]","[""unknown-deepfake-technology-developer""]","[""karl-stefanovic"",""karl-kruszelnicki"",""jonathan-shaw"",""general-public"",""diabetes-patients""]","Scammers are reportedly harnessing AI-generated deepfakes of health experts and public figures in Australia in order to sell health supplements and give harmful health advice. Among the reported cases, deepfake videos are alleged to have falsely depicted Jonathan Shaw and Karl Stefanovic endorsing ""Glyco Balance"" for diabetes management, while Karl Kruszelnicki reportedly was falsely shown promoting blood pressure pills.",Scammers Reportedly Using Deepfakes of Health Experts and Public Figures in Australia to Sell Health Supplements and Give Harmful Advice,880.0,4. Malicious Actors & Misuse,"4.3. Fraud, scams, and targeted manipulation",scammer harness aigenerated deepfakes health expert public figure australia order sell health supplement harmful health advice among report case deepfake video falsely depict jonathan shaw karl stefanovic endorse glyco balance diabetes management karl kruszelnicki falsely show promote blood pressure pill
